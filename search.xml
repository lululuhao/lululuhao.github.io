<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[L·H]]></title>
    <url>%2F2019%2F09%2F24%2FL%C2%B7H%2F</url>
    <content type="text"><![CDATA[如果痴痴的等某日，终可等到一生中最爱。]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F03%2F22%2Fzabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[安装操作系统：最小化安装操作系统:安装以下常用依赖包： yum install vim iotop bc gcc gcc-c++ glibc g-develpcrepcre-developensslopenssl-libc-devel pcre pcre-devel openssl openssl-devel zip unzip zlib-develnet-tools lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel -y 安装数据库数据库安装ZabbixServer端与数据库使用脚本自动安装数据库： ln-sv/var/lib/mysql/mysql.sock/tmp/mysql.sock max_connections=10000 #my.cnf 配置文件更改最大链接数 1.安装Zabbix server 安装依赖包： yum install gcc libxml2-devel net-snmp net-snmp-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb- devel –y 准备数据库： [root@zabbix-web1 ~]# mysql mysql&gt; create database zabbix character set utf8 collate utf8_bin; Query OK, 1 row affected (0.00 sec) mysql&gt; grant all privileges on zabbix.* to zabbix@&quot;identified by &apos;123456&apos;; Query OK, 0 rows affected (0.00 sec) 编译安装: [root@zabbix-server ~]# cd /usr/local/src/ [root@zabbix-server src]# zabbix-4.0.1.tar.gz [root@zabbix-server zabbix-4.0.1]# useradd zabbix -s /sbin/nologin # ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with- libxml2 –enable-java​ # make &amp;&amp; make install​ 导入数据库：​ #先导入此文件，如果做zabbix代理服务器，则只导入此文件即可​ mysql -uzabbix -p123456 -h192.168.15.203 zabbix &lt; database/mysql/schema.sql​ mysql -uzabbix -p123456 -h192.168.15.203 zabbix &lt; database/mysql/images.sql​ mysql -uzabbix -p123456 -h192.168.15.203 zabbix &lt; database/mysql/data.sql​ 复制启动脚本：​ cp /usr/local/src/zabbix-4.0.1/misc/init.d/fedora/core/zabbix_server /etc/init.d/​ cp /usr/local/src/zabbix-4.0.1/misc/init.d/fedora/core/zabbix_agentd /etc/init.d/​ 更改启动脚本：​ vim /etc/init.d/zabbix_server​ vim /etc/init.d/zabbix_agent​ 21 # Zabbix-Directory​ 22 BASEDIR=/usr/local/zabbix​ 编辑zabbix_server.con配置文件：​ #mkdir /var/log/zabbix &amp;&amp; chown zabbix.zabbix /var/log/zabbix –R​ [root@zabbix-server ~]# grep “^[a-Z]” /usr/local/zabbix/etc/zabbix_server.conf​ LogFile=/var/log/zabbix/zabbix_server.log​ DBHost=192.168.10.103​ DBName=zabbix​ DBUser=zabbix​ DBPassword=123456​ DBPort=3306​ Timeout=30​ LogSlowQueries=3000 安装zabbix​ 配置web界面：​ 安装httpd：​ #yum install httpd -y​ #mkdir /var/www/html/zabbix​ #cp -a /usr/local/src/zabbix-4.0.1/frontends/php/* /var/www/html/zabbix​ # systemctl restart httpd 访问web 解决报错： yum install php-gettext php-session php-ctype php-xmlreader php-xmlwriter php-xml php-net-socket php- gd php-mysql 如下更改vim /etc/php.ini： post_max_size = 8M 改为 post_max_size = 16M max_execution_time = 30 改为 max_execution_time = 300 max_input_time = 60 改为 max_input_time = 300 ;date.timezone = 改 为 date.timezone = date.timezone = Asia/Shanghai 重启http再次访问web # systemctl restart httpd]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F03%2F15%2FDevOps%20%E4%B9%8B%E5%9F%BA%E4%BA%8EJenkins%E5%AE%9E%E7%8E%B0%E7%9A%84CI%E4%B8%8ECD%2F</url>
    <content type="text"><![CDATA[DevOps 之基于Jenkins实现的CI与CDDevOps简介： DevOps 是Development和Operations的组合，也就是开发和运维的简写。 DevOps 是针对企业中的研发人员、运维人员和测试人员的工作理念，是他们在应用开发、代码部署和质量测试等整条生命周期中协作和沟通的最佳实践，DevOps 强调整个组织的合作以及交付和基础设施变更的自动化、从而实现持续集成、持续部署和持续交付。 DevOps 四大平台：代码托管(gitlab/svn)、项目管理(jira)、运维平台(腾讯蓝鲸/开源平台)、持续交付(Jenkins/gitlab) 1.1：什么是DevOps：​ 1.2：为什么要推广DevOps？DevOps 强调团队协作、相互协助、持续发展，然而传统的模式是开发人员只顾开发程序，运维只负责基础环境管理和代码部署及监控等，其并不是为了一个共同的目标而共同实现最终的目的，而DevOps 则实现团队作战，即无论是开发、运维还是测试，都为了最终的代码发布、持续部署和业务稳定而付出各自的努力，从而实现产品设计、开发、测试和部署的良性循环，实现产品的最终持续交付。 1.3：传统技术团队： 1.4：DevOps技术团队：​ ​ 戴明环 1.5：什么是持续集成(CI-Continuous integration)：持续集成是指多名开发者在开发不同功能代码的过程当中，可以频繁的将代码行合并到一起并切相互不影响工作。 1.6：什么是持续部署(CD-continuous deployment)：是基于某种工具或平台实现代码自动化的构建、测试和部署到线上环境以实现交付高质量的产品,持续部署在某种程度上代表了一个开发团队的更新迭代速率。 1.7：什么是持续交付(Continuous Delivery)：持续交付是在持续部署的基础之上，将产品交付到线上环境，因此持续交付是产品价值的一种交付，是产品价值的一种盈利的实现。 1.8：常见的部署方式：开发自己上传–最原始的方案 开发给运维手动上传–运维自己手动部署 运维使用脚本复制–半自动化 结合web界面一键部署–自动化 1.9：常见的持续集成开源工具：在公司的服务器安装某种程序，该程序用于按照特定格式和方式记录和保存公司多名开发人员不定期提交的源代码，且后期可以按照某种标记及方式对用户提交的数据进行还原。 1.9.1：CVS(Concurrent Version System)：早期的集中式版本控制系统，现已基本淘汰 会出现数据提交后不完整的情况 1.9.2：SVN(Subversion)–集中式版本控制系统2000年开始开发，目标就是替代CVS集中式管理，依赖于网络，一台服务器集中管理目前依然有部分公司在使用。 1.9.3：Gitlib—分布式版本控制系统Linus在1991年创建了开源的Linux内核，从此Linux便不断快速发展，不过 Linux的壮大是离不开全世界的开发者的参与，这么多人在世界各地为Linux编写代码，那Linux内核的代码是如何管理的呢？事实是，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码！你也许会想，为什么Linus不把Linux代码放到版本控制系统里呢？不是有CVS、SVN这些免费的版本控制系统吗？因为Linus坚定地反对CVS和SVN，这些集中式的版本控制系统不但速度慢，且必须联网才能使用，但是也有一些商用的版本控制系统，虽然比CVS、SVN好用，但那是付费的，和Linux的开源精神不符,不过，到了2002年，Linux系统已经发展了十年了，代码库之大让Linus很难继续通过手工方式管理了，社区的弟兄们也对这种方式表达了强烈不满，于是Linus选择了一个商业的版本控制系统BitKeeper，BitKeeper的东家BitMover公司出于人道主义精神，授权Linux社区免费使用这个版本控制系统,但是安定团结的大好局面在2005年就被打破了，原因是Linux社区牛人聚集，不免沾染了一些梁山好汉的江湖习气，开发Samba的Andrew试图破解BitKeeper的协议（这么干的其实也不只他一个），被BitMover公司发现了（监控工作做得不错！），于是BitMover公司怒了，要收回Linux社区的免费使用权,这时候其实Linus可以向BitMover公司道个歉，保证以后严格管教弟兄们，但这是不可能的，而且实际情况是Linus自己花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！一个月之内，Linux内核的源码已经由Git管理了！牛是怎么定义的呢？大家可以体会一下,然后Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，包括jQuery，PHP，Ruby等等。 ​ 1.10：版本控制系统分类：1.10.1：集中式版本控制系统：任何的提交和回滚都依赖于连接服务器服务器是单点 1.10.2：分布式版本控制系统：​ ​ http/https/ssh/git Git在每个用户都有一个完整的服务器，然后在有一个中央服务器，用户可以先将代码提交到本地，没有网络也可以先提交到本地，然后在有网络的时候再提交到中央服务器，这样就大大方便了开发者，而相比CVS和SVN都是集中式的版本控制系统，工作的时候需要先从中央服务器获取最新的代码，改完之后需要提交，如果是一个比较大的文件则需要足够快的网络才能快速提交完成，而使用分布式的版本控制系统，每个用户都是一个完整的版本库，即使没有中央服务器也可以提交代码或者回滚，最终再把改好的代码提交至中央服务器进行合并即可。 二：Gitlab部署与使用：2.1：下载并部署gitlab：2.1.1：Ubuntu 系统环境准备：2.1.1.1：配置ubuntu 远程连接：1234567jack@ubuntu:~$ sudo su - root[sudo] password for jack:root@ubuntu:~# passwd Enter new UNIX password: Retype new UNIX password: passwd: password updated successfullyroot@ubuntu:~# vim /etc/ssh/sshd_config 2.1.1.2：配置ubuntu网卡和主机名：12345678910111213141516171819root@ubuntu:~# cat /etc/netplan/01-netcfg.yaml \# This file describes the network interfaces available on your system\# For more information, see netplan(5).network: version: 2 renderer: networkd ethernets: eth0: dhcp4: no addresses: [192.168.8.2/21] gateway4: 192.168.15.254 nameservers: addresses: [192.168.15.254]root@ubuntu:~# cat /etc/hostname jenkins.example.comroot@ubuntu:~# reboot 2.1.1.3：配置ubuntu 仓库：123456789101112131415root@ubuntu:~#vim /etc/apt/sources.listdeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverseroot@jenkins:~# apt updateroot@jenkins:~# apt install iproute2 ntpdate tcpdump telnet traceroute nfs-kernel-server nfs-common lrzsz tree openssl libssl-dev libpcre3 libpcre3-dev zlib1g-dev ntpdate tcpdump telnet traceroute gcc openssh-server lrzsz tree openssl libssl-dev libpcre3 libpcre3-dev zlib1g-dev ntpdate tcpdump telnet traceroute iotop unzip zip ipmitool 2.1.2：Centos 系统环境在准备： 1 gitlab-server 172.20.102.205 2 jenkins-server 172.20.102.222 3 tomcat-web1 172.20.102.228 4 tomcat-web2 172.20.102.240 5 keepalived+haproxy1 172.20.102.216 6 keepalived+haproxy2 172.20.102.253 最小化服务器安装，配置如下： 1\# yum install vim gcc gcc-c++ wget net-tools lrzsz iotop lsof iotop bash-completion -y` # yum install curl policycoreutils openssh-server openssh-clients postfix -y# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# systemctl disable firewalld# sed -i ‘/SELINUX/s/enforcing/disabled/‘ /etc/sysconfig/selinux# hostnamectl set-hostname gitlab.example.com# reboot1234567891011 ### 2.1.3：gitlab安装及使用：```bash安装包下载地址：https://packages.gitlab.com/gitlab/gitlab-ce rpm包国内下载地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/ 本次安装版本为gitlab-ce-11.3.11-ce.0.el7.x86_64.rpm# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-11.3.11-ce.0.el7.x86_64.rpm# rpm -ivh gitlab-ce-11.3.11-ce.0.el7.x86_64.rpm 2.1.3.1：gitlab配置：12345678910111213[root@gitlab ~]#grep "^[a-Z]" /etc/gitlab/gitlab.rbexternal_url 'http://192.168.245.17'gitlab_rails['smtp_enable'] = truegitlab_rails['smtp_address'] = "smtp.163.com"gitlab_rails['smtp_port'] = 25gitlab_rails['smtp_user_name'] = "htluhao@163.com"gitlab_rails['smtp_password'] = "luhao111"gitlab_rails['smtp_domain'] = "163.com"gitlab_rails['smtp_authentication'] = :logingitlab_rails['smtp_enable_starttls_auto'] = truegitlab_rails['smtp_tls'] = falsegitlab_rails['gitlab_email_from'] = "htluhao@163.com"user["git_user_email"] = [htluhao@163.com 2.1.3.2：初始化服务：执行配置并启动服务： `# gitlab-ctl reconfigure #修改完配置文件要执行此操作` 12345\# gitlab-ctl start\# gitlab-ctl stop\# gitlab-ctl restar 2.1.3.3：验证gitlab启动完成： 2.1.3.4：验证端口及状态：80端口是在初始化gitlib的时候启动的，因此如果之前的有程序占用会导致初始 化失败或无法访问！ lsof -i:80 2.1.3.5：登录gitlab web界面：http://192.168.245.17/ 登录web页面并设置密码,最少8位： 2.1.3.6：登录gitlab：登录，默认用户为root： 2.1.3.7：默认首页： 2.1.3.8：关闭账号注册：默认情况下可以直接注册账号，因此一般都关闭次功能： 取消账户注册功能之后点save 2.1.3.9：验证是否还有注册选项： 2.1.3.10：创建git账户： 2.1.3.11：重新设置密码：使用第一次使用新账号登录要设置密码： ​ 通过邮件重置用户密码： 在收件箱打开邮件设置密码： ​ 设置密码： 或者管理员创建账号时指定密码 2.1.3.12：创建组：使用管理员root创建组，一个组里面可以有多个项目分支，可以将开发添加到组里面进行设置权限，不同的组就是公司不同的开发项目或者服务模块，不同的组添加不同的开发即可实现对开发设置权限的管理。 2.1.3.13：使用管理员创建项目： 使用管理员创建项目： 创建后的项目效果： 2.1.3.14：将用户添加到组：https://docs.gitlab.com/ee/user/permissions.html (更多权限) 2.1.3.15：创建一个测试页 添加一个页面： 2.1.3.15：git客户端测试clone项目：1234567891011121314151617[root@gitlab ~]#git clone http://192.168.245.17/test-service/test-project.gitCloning into 'test-project'...Username for 'http://192.168.245.17': luhaoPassword for 'http://luhao@192.168.245.17': remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3/3), done.[root@gitlab ~]#cat test-project/index.html 123432432411 编辑文件并测试提交： 1[root@gitlab ~]#cd test-project/` [root@gitlab test-project]#git config –global user.name “luhao” [root@gitlab test-project]#git config –global user.email htluhao@163.com123456789101112131415```bash[root@gitlab test-project]#vim index.html &lt;h1&gt;123432432411&lt;/h1&gt;&lt;h1&gt;123432432411&lt;/h1&gt;&lt;h1&gt;123432432411&lt;/h1&gt;&lt;h1&gt;123432432411&lt;/h1&gt;&lt;h1&gt;123432432411&lt;/h1&gt; [root@gitlab test-project]#git add index.html 12345[root@gitlab test-project]#git commit -m "v1"[master 5ccda6e] v1 1 file changed, 5 insertions(+), 1 deletion(-)` 2.1.3.16:git web端验证数据： 2.1.3.17：git常用命令：12345678910111213141516git config --global user.name “name“ #设置全局用户名git config --global user.email [xxx@xx.com ](mailto:xxx@xx.com)#设置全局邮箱git config --global –list #列出用户全局设置git add index.html / . #添加指定文件、目录或当前目录下所有数据到暂存区git commit -m “11“ #提交文件到工作区git status #查看工作区的状态git push #提交代码到服务器git pull #获取代码到本地git log #查看操作日志vim .gitignore #定义忽略文件git reset --hard HEAD^^ #git版本回滚， HEAD为当前版本，加一个^为上一个，^^为上上一个版本git reflog # #获取每次提交的ID，可以使用--hard根据提交的ID进行版本回退git reset --hard 5ae4b06 #回退到指定id的版本git branch #查看当前所处的分支git checkout -b develop #创建并切换到一个新分支git checkout develop #切换分支 三：部署web服务器环境：3.1 部署tomcat环境各wenb服务器准备tomcat运行环境： 12345678910111213141516171819202122[root@tomcat-web1 /]# useradd www -u 2000[root@tomcat-web1 /]# mkdir /apps &amp;&amp; cd /apps[root@tomcat-web1 apps]# tar xvf jdk-8u192-linux-x64.tar.gz [root@tomcat-web1 /]# ln -sv /apps/jdk1.8.0_192/ /apps/jdk[root@tomcat-web1 /]# vim /etc/profileexport HISTTIMEFORMAT="%F %T whoami "export export LANG="en_US.utf-8"export JAVA_HOME=/apps/jdkexport CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin[root@tomcat-web1 apps]# ln -sv /apps/jdk1.8.0_192/ /apps/jdk‘/apps/jdk’ -&gt; ‘/apps/jdk1.8.0_192/’[root@tomcat-web1 apps]# source /etc/profile[root@tomcat-web1 apps]# java -versionjava version "1.8.0_192"Java(TM) SE Runtime Environment (build 1.8.0_192-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode)\# tar xvf apache-tomcat-8.5.37.tar.gz\# ln -sv /apps/apache-tomcat-8.5.37 /apps/tomcat[root@tomcat-web2 apps]# mkdir /data/tomcat_webdir /data/tomcat_appdir -pv 12345678vim /apps/apache-tomcat-8.5.37/conf/server.xml#配置tomcat配置文件：appBase=&quot;/data/tomcat_webdir/&quot; unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot;cd /data/tomcat_webdir/mkdir myappvim myapp/index.html写入[root@tomcat-web1 ~]# cat /data/tomcat_webdir/myapp/index.html &lt;!DOCTYPE html&gt; dsadasdtomcat1L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false}); 12345678cp /apps/tomcat/webapps/* /data/tomcat_webdir/ -r -arz上传脚本 tomcatcp /root/tomcat /etc/init.d/chmod a+x /etc/init.d/tomcat useradd tomcat -u 2001passwd tomcatsu - tomcat/etc/init.d/tomcat start 打开172.20.102.228:8080/myapp/确认各web服务器访问正常： ​ 3.2 部署keepalived1# yum install libnfnetlink-devel libnfnetlink ipvsadm libnl libnl-devel libnl3 libnl3-devel lm_sensors-libs net-snmp-agent-libs net-snmp-libs open server openssh-clients openssl openssl-devel automake iproute 1234567891011121314151617181920212223242526272829303132333435#编译安装\# cd keepalived-2.0.7 &amp;&amp; ./configure --prefix=/usr/local/keepalived --disable-fwmark\# make &amp;&amp; amke install\# # mkdir /usr/local/keepalived/etc/sysconfig –p &amp;&amp; cp keepalived/etc/init.d/keepalived.rh.init /usr/local/keepalived/etc/sysconfig/keepalived\# cp keepalived/keepalived.service /usr/lib/systemd/system/\# mkdir /usr/local/keepalived/sbin &amp;&amp; cp bin/keepalived /usr/local/keepalived/sbin/keepalived\# mkdir /etc/keepalived#本次采用yum安装yum install keepalived -yhaproxy1 上的keepalived为MASTERhaproxy2 上的keepalived为BACKUP地址都为172.20.102.248做keepalived高可用，使用ifconfig可是两个keepalived存活性是否生效两台只允许有一个eth0:1，停掉一台，另一台开始服务\# vim /etc/keepalived/keepalived.confvrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.20.102.248 dev eth0 label eth0:1 &#125;&#125;[root@haproxy2 ~]# systemctl restart keepalived[root@haproxy2 ~]# systemctl enable keepalived haproxy2 3.3部署haproxy：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#编译安装# tar xvf haproxy-1.8.13.tar.gz# cd haproxy-1.8.13# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy# make install PREFIX=/usr/local/haproxy# vim /usr/lib/systemd/system/haproxy.service[Unit]Description=HAProxy Load BalancerAfter=syslog.target network.target[Service]#支持多配置文件读取，类似于从侧面是实现配置文件的include功能。ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf -c -qExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf -p /run/haproxy.pidExecReload=/bin/kill -USR2 $MAINPID[Install]WantedBy=multi-user.target# mkdir /etc/haproxy本次采用yum 安装yum install haproxy -yvim /etc/haproxy/haproxy.cfgglobal # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the &apos;-r&apos; option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------#此处需要app或者官网访问入口listen myapp bind 172.20.102.248：80 balance roundrobin server 172.20.102.228 172.20.102.228:8080 check server 172.20.102.216 172.20.102.240:8080 check [root@haproxy2 ~]# systemctl restart haproxy[root@haproxy2 ~]# systemctl enable haproxy 注释： 1 gitlab-server 172.20.102.2052 jenkins-server 172.20.102.2223 tomcat-web1 172.20.102.2284 tomcat-web2 172.20.102.2405 haproxy1 172.20.102.2166 haproxy2 172.20.102.253 3.3.1: 测试haproxy反向代理web服务器：编辑本机hosts文件，将myapp.web.com解析到对应的IP负载IP： C:\Windows\System32\drivers\etc\hosts 172.20.102.101 myapp.web.com 3.3.2: 记录HAProxy访问日志：# vim /etc/rsyslog.conf： 14 # Provides UDP syslog reception 15 $ModLoad imudp #去掉注释 16 $UDPServerRun 514 #去掉注释 18 # Provides TCP syslog reception 19 $ModLoad imtcp #去掉注释 20 $InputTCPServerRun 514 #去掉注释 93 local3.* /var/log/haproxy.log # systemctl restart rsyslog log 127.0.0.1 local3 info #global部分 listen web_port bind 0.0.0.0:80 mode http log global option httplog server 192.168.7.103 192.168.7.103:8080 check inter 3000 fall 2 rise 5 server 192.168.7.104 192.168.7.104:8080 check inter 3000 fall 2 rise 5 ​ 重启rsyslog和haproxy服务，验证/var/log/haproxy.log可以记录日志： 3.3.3: 验证HAProxy统计页面：http://myapp.web.com:9009/haproxy-status ​ 3.3.4.: 验证haproxy代理web服务器：http://myapp.web.com/myapp/ 四：Jenkins部署与基础配置：4.1：配置java环境并部署jenkins：4.1.1：java环境配置：1234567891011121314151617181920212223[root@localhost src]# tar xvf jdk-8u192-linux-x64.tar.gz[root@localhost src]#ln -sv /usr/local/src/jdk1.8.0_192/ /usr/local/jdk[root@localhost src]# vim /etc/profileexport JAVA_HOME=/usr/local/jdkexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATHexport CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar [root@localhost src]#source /etc/profile[root@localhost src]#java -versionjava version &quot;1.8.0_192&quot;Java(TM) SE Runtime Environment (build 1.8.0_192-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode) 4.1.2：启动Jenkins4.1.2.1：通过jar包直接启动jenkins：123456789101112131415# java \-Dcom.sun.management.jmxremote \-Dcom.sun.management.jmxremote.port=12345 \-Dcom.sun.management.jmxremote.authenticate=false \-Dcom.sun.management.jmxremote.ssl=false \-Djava.rmi.server.hostname=&quot;192.168.245.27 &quot; \-jar jenkins-2.138.3.war &amp;此方法失败了，所以通过安装rpm包安装了 4.1.2.2：rpm包安装jenkins配置：rzrpm -ivh jenkins-2.138.3-1.1.noarch.rpmgrep -v “#” /etc/sysconfig/jenkins | grep -v “^$”vim /etc/sysconfig/jenkins JENKINS_HOME=”/var/lib/jenkins”JENKINS_JAVA_CMD=””JENKINS_USER=”jenkins”JENKINS_JAVA_OPTIONS=”-Djava.awt.headless=true”JENKINS_PORT=”8080”JENKINS_LISTEN_ADDRESS=””JENKINS_HTTPS_PORT=””JENKINS_HTTPS_KEYSTORE=””JENKINS_HTTPS_KEYSTORE_PASSWORD=””JENKINS_HTTPS_LISTEN_ADDRESS=””JENKINS_DEBUG_LEVEL=”5”JENKINS_ENABLE_ACCESS_LOG=”no”JENKINS_HANDLER_MAX=”100”JENKINS_HANDLER_IDLE=”20”JENKINS_ARGS=”” systemctl restart jenkins 1234567891011121314151617181920212223[root@s1 ~]# grep -v "#" /etc/sysconfig/jenkins | grep -v "^$"JENKINS_HOME="/var/lib/jenkins"JENKINS_JAVA_CMD=""JENKINS_USER="root"JENKINS_JAVA_OPTIONS="-Djava.awt.headless=true \-Dcom.sun.management.jmxremote \-Dcom.sun.management.jmxremote.port=12345 \-Dcom.sun.management.jmxremote.authenticate=false \-Dcom.sun.management.jmxremote.ssl=false \-Djava.rmi.server.hostname="192.168.245.27" "JENKINS_PORT="8080"JENKINS_LISTEN_ADDRESS=""JENKINS_HTTPS_PORT=""JENKINS_HTTPS_KEYSTORE=""JENKINS_HTTPS_KEYSTORE_PASSWORD=""JENKINS_HTTPS_LISTEN_ADDRESS=""JENKINS_DEBUG_LEVEL="5"JENKINS_ENABLE_ACCESS_LOG="no"JENKINS_HANDLER_MAX="100"JENKINS_HANDLER_IDLE="20"JENKINS_ARGS="" 4.1.3:Jenkins 启动过程：​ 4.1.4：访问jenkins 页面 4.1.5：选择安装jenkins插件：​ 4.1.6：插件安装过程中：插件安装过程中。。，如果因为某种原因导致有有安装失败的插件，没有关系，可以后期再单独安装 4.1.7：创建jenkins管理员： 4.1.8：配置jenkins URL： 4.1.9：配置完成并登陆jenkins： 4.1.10：登陆jenkins界面： 4.1.11：jenkins插件管理及安装：4.1.11.1：插件安装目录：插件下载地址：http://updates.jenkins-ci.org/download/plugins/ 4.1.11.2：安装插件：搜索需要gitlab的插件并安装： gitlab和Blue Ocean 4.1.12：配置jenkins 权限管理：基于角色的权限管理，先创建角色和用户，给角色授权，然后把用户管理到角色。 4.1.12.1：安装插件： Role-based 4.1.12.2：创建新用户：Jenkins—系统管理—管理用户： 4.1.12.3：更改认证方式：Jenkins—系统管理—全局安全配置 默认创建的用户登录后可以做任何操作，取决于默认的认证授权方式。 设置角色认证后，在进行角色授权之后才能退出浏览器，否则会导致账号登陆不上 4.1.12.4：创建角色：Jenkins—系统管理–Manage and Assign Roles 4.1.12.5：添加规则组： 4.1.12.6：对组分配权限： 4.1.12.7：将用户关联到规则组： 4.1.12.8：测试普通用户登录： 登录成功之的界面，没有系统管理权限，只能执行被授权过的job且没有了管理员权限。 4.1.13：jenkins 邮箱配置：4.1.13.1：生成QQ邮箱登录授权码： 4.1.13.2：配置jenkins管理员邮箱：Jenkins—系统管理—系统设置： 4.1.13.3：发件配置： 4.1.13.4：测试发送邮件： 4.2：基于ssh key拉取代码：4.2.1：添加ssh key： ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3niuTNTXCA4zoltRTu+qDMOyF0xglYFxIIZMolCH2+Ma3L4v/D72WascVBD4LrkJM3S6KTSLn4M4+7l+9fe5LaZu0WSD2Se2N0FVcPFsYOK5ZwPoWiL83R5T2bN4j69G7cAtHM5X5WOAuJs6ArSBSxsSnyeFnUFNw3rbmkCCt2TvrsmqTzEMA1PDQno/7wB3n8JfxjaKp5oHNPQrwN0p0lGuUMSxGSNjCEIiexxqpyrJ0DPShs+XximSOO7noWbZq2nMhsH7yWdwKN3qD00U52ACDijeAyKVa4ByQntDIPeCr8gdUZiT8rbfXtix2MhR2cCgZJAKYDQNAwltVVOCf root@jenkins.example.com 4.2.2：添加ssh key： 4.2.3：创建ssh key：ssh key**只用于免认证获取代码** gitlab**和jenkins分别位于 两个 服务器** 分别生成公钥私钥 ssh-keygen 回车三次 cat /root/.ssh/id_rsa cat /root/.ssh/id_rsa.pub gitlab**网页添加jenkins服务器端生成的公钥**id_rsa.pub jenkins**网页添加凭证要jenkins服务器端生成的私钥**id_rsa 4.2.4：测试ssh key：测试可以不使用用户名密码后直接获取代码 4.3：配置jenkins自动拉取代码：4.3.1：jenkins 服务器添加证书：Jenkins-凭据-jenkins—全局凭据—添加凭据 4.3.2：jenkins创建project： 构建一个shell 4.3.3：配置git项目地址和用户：添加完成的证书没有报错表示认证通过 4.3.4：测试构建项目：4.3.4.1：点击立即构建： 4.3.4.2：验证构建结果： 4.3.4.3：服务器验证数据： 4.3.4.4：将代码部署至后端服务器：123 jenkins服务器先对后端tomcat服务器做基于tomcat的免密钥登陆ssh-copy-id -i /root/.ssh/id_rsa.pub tomcat@172.20.102.228ssh-copy-id -i /root/.ssh/id_rsa.pub tomcat@172.20.102.240 将下列脚本写到Jenkins的web端的代码构建中 脚本内容： ###git clone -b master git@172.20.102.205:myapp/test-project.gitcd /var/lib/jenkins/workspace/demo1/test-project/ssh tomcat@172.20.102.228 “/etc/init.d/tomcat stop”ssh tomcat@172.20.102.240 “/etc/init.d/tomcat stop”scp index.html tomcat@172.20.102.228:/data/tomcat_webdir/myapp/scp index.html tomcat@172.20.102.240:/data/tomcat_webdir/myapp/ssh tomcat@172.20.102.228 “/etc/init.d/tomcat start”ssh tomcat@172.20.102.240 “/etc/init.d/tomcat start” 构建之前 在gitlib上更新index.html文件并上传 1234567 255 2019-03-15 20:51:41 root vim index.html 256 2019-03-15 20:53:10 root git add index.html 257 2019-03-15 20:53:21 root git commit -m "v1" 258 2019-03-15 20:53:27 root git push 259 2019-03-15 20:54:01 root cat index.html 260 2019-03-15 20:54:53 root history [root@gitlab-server test-project]# cat index.html 上传完成后点击立即构建 刷新页面，可以看到jenkins已经从gitlab上拉取代码并传到了后端的tomcat服务器上 4.3：pipline：官方介绍；https://jenkins.io/2.0/ pipline是帮助Jenkins实现CI到CD转变的重要角色，是运行在jenkins 2.X版本的核心插件，简单来说Pipline就是一套运行于Jenkins上的工作流框架，将原本独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂发布流程，从而实现单个任务很难实现的复杂流程编排和任务可视化，Pipeline的实现方式是一套Groovy DSL，任何发布流程都可以表述为一段Groovy脚本。 4.3.1：pipline优势：可持续性：jenkins的重启或者中断后不影响已经执行的Pipline Job 支持暂停：pipline可以选择停止并等待人工输入或批准后再继续执行。 可扩展：通过groovy的编程更容易的扩展插件。 并行执行：通过groovy脚本可以实现step，stage间的并行执行，和更复杂的相互依赖关系。 4.3.2：pipline 语法：Stage：阶段，一个pipline可以划分为若干个stage，每个stage都是一个操作，比如clone代码、代码编译、代码测试和代码部署，阶段是一个逻辑分组，可以跨多个node执行。 Node：节点，每个node都是一个jenkins节点，可以是jenkins master也可以是jenkins agent，node是执行step的具体服务器。 Step：步骤，step是jenkins pipline最基本的操作单元，从在服务器创建目录到构建容器镜像，由各类 Jenkins 插件提供实现，例如： sh “make” 4.3.2：pipline job测试：4.3.2.1：创建pipline job：4.3.2.2：测试简单pipline job运行：node { ​ stage(“clone 代码”){ ​ echo “代码clone” ​ } ​ stage(“代码构建”){ ​ echo “代码构建” ​ } stage(“代码测试”){ ​ echo “代码测试” } stage(“代码部署”){ ​ echo “代码部署” } } 4.3.2.3：执行pipline job：4.3.2.4：生成拉取代码的pipline脚本：4.3.2.5：更改pipline job：node { stage(“code clone”){ ​ echo “git clone” ​ git credentialsId: ‘b695c060-6a99-4ee3-bd4c-730bd4dd36ec’, url: &#39;git@192.168.8.3:test-service/test-project.git’ } stage(“code build”){ ​ echo “code build” } stage(“code test”){ ​ echo “code test” } stage(“code deploy”){ ​ echo “code deploy” } } 4.3.2.6：执行jenkins job：4.3.2.7：验证git clone日志：4.3.2.8：服务器验证数据：4.3.2.9：pipline中执行shell 命令：node { stage(“code clone”){ ​ echo “git clone” ​ git credentialsId: ‘b695c060-6a99-4ee3-bd4c-730bd4dd36ec’, url: &#39;git@192.168.8.3:test-service/test-project.git’ ​ sh “cd /root/.jenkins/workspace/pipline-test &amp;&amp; tar czvf code.tar.gz ./*” } stage(“code build”){ ​ echo “code build” } stage(“code test”){ ​ echo “code test” } stage(“code deploy”){ ​ echo “code deploy” } } 4.3.3：jenkins 分布式构建：4.3.3.1：添加slave节点：Jenkins—系统管理—节点管理—新建节点： 添加slave节点： 4.3.3.2：配置slave节点：Slave服务器创建工作目录，如果slave需要执行编译job，则也需要配置java环境： [root@jenkins-slave ~]# yum install java-1.8.0-openjdk –y [root@jenkins-slave ~]# mkdir /data/jenkins/slave -pv mkdir: created directory ‘/data’ mkdir: created directory ‘/data/jenkins’ mkdir: created directory ‘/data/jenkins/slave’ 4.3.3.3：添加slave认证凭据：4.3.3.：添加slave节点：4.3.4：jenkins slave创建日志：4.3.5：如果slave java报错如下：4.3.6：验证slave 状态：正常状态： 时间不同步状态 4.3.7：slave 状态：4.3.8：配置slave执行job：Slave的公钥也要同步到各个web服务器 node(‘slave-node1’){ stage(“code clone”){ ​ echo “git clone” ​ sh “cd /data/jenkins/slave/workspace/pipline-test &amp;&amp; rm -rf ./*” ​ git credentialsId: ‘b695c060-6a99-4ee3-bd4c-730bd4dd36ec’, url: &#39;git@192.168.8.3:test-service/test-project.git’ ​ sh “cd /data/jenkins/slave/workspace/pipline-test &amp;&amp; tar czvf code.tar.gz ./*” } stage(“code build”){ ​ echo “code build” } stage(“code test”){ ​ echo “code test” } stage(“code deploy”){ ​ echo “code deploy” } } 4.3.9：验证slave执行构建：]]></content>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2019%2F03%2F12%2Ftest%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql]]></title>
    <url>%2F2018%2F12%2F09%2Fmysql%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[装centos系统后必须要做的几件事！！！]]></title>
    <url>%2F2018%2F12%2F03%2F%E6%96%B0%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%90%8E%E5%BF%85%E9%A1%BB%E5%81%9A%E7%9A%84%E5%87%A0%E4%BB%B6%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[定义习惯用的别名12345vim .bashrcalias rm='rm -i'alias cp='cp -i'alias mv='mv -i'alias yy='yum install -y' 修改网卡信息,配置固定ip1234567vim /etc/sysconfig/network-scripts/ifcfg-ens33PREFIX=24BOOTPROTO=staticIPADDR=192.168.245.7NAME=ens33DEVICE=ens33ONBOOT=yes 修改默认颜色12vim /etc/profile.d/env.shPS1="\[\e[1;32m\][\u@\h \W]\\$\[\e[0m\]" 修改欢迎界面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647vim /etc/motd #打开配置文件,复制下面的字符 /*[*/#include&lt;stdio.h&gt;// #include&lt;stdlib.h&gt;//]++++[-&gt;++[-&gt;+&gt;++++&lt;&lt;]&lt;][(c)2013] #ifndef e//[o #include&lt;string.h&gt;//]![misaka.c,size=3808,crc=d0ec3b36][ #define e 0x1// typedef struct&#123;int d,b,o,P;char*q,*p;&#125;f;int p,q,d,b,_=0//| #include __FILE__//]&gt;&gt;&gt;[-&gt;+&gt;++&lt;&lt;]&lt;[-&lt;&lt;+&gt;&gt;&gt;++&lt;]&gt;&gt;+MISAKA*IMOUTO #undef e//[-&gt;[-&lt;&lt;+&lt;+&lt;+&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;&lt;++[-&gt;&gt;+&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;]&gt;+&gt;+++&gt;+++[&gt;]]b #define e(c)/**/if((_!=__LINE__?(_=__LINE__):0))&#123;c;&#125;//[20002,+[-.+] ,O,i=0,Q=sizeof(f);static f*P;static FILE*t;static const char*o[]=&#123;// "\n\40\"8oCan\40not\40open %s\n\0aaFbfeccdeaEbgecbbcda6bcedd#e(bbed$bbd", "a6bgcdbbccd#ead$c%bcdea7bccde*b$eebbdda9bsdbeccdbbecdcbbcceed#eaa&amp;bae$cbe", "e&amp;cbdd$eldbdeedbbdede)bdcdea&amp;bbde1bedbbcc&amp;b#ccdee&amp;bdcdea'bbcd)e'bad(bae&amp;bccd", "e&amp;bbda1bdcdee$bbce#b$c&amp;bdedcd%ecdca4bhcdeebbcd#e$b#ecdcc$bccda7bbcc#e#d%c*bbda", "&gt;bad/bbda"&#125;;static int S()&#123;return(o[p][q]);&#125;static/**/int/**/Z=0 ;void/**/z(int// l)&#123;if(/**/Z-l)&#123;Z=l;q++;if(p&lt;b*5&amp;&amp;!S())&#123;p+=b;q=0;&#125;&#125;&#125;int main(int I, /**/char**l)&#123;// d=sizeof(f*);if(1&lt;(O=_))&#123;b=((sizeof(o)/sizeof(char*))-1)/4;q=22; p= 0;while(p&lt;b*5)&#123; /*&lt;*/if(Z-1)&#123;d=S()&gt;96;i=S()-(d?96:32) ;q++;if(p&lt;b*5&amp;&amp;!S())&#123;p+=b; q= 0;&#125;Z=1;&#125;/*[[*/ while(i)&#123;_=o[0][S()-97];I=_-10?b:1; for( ;I--;)putchar(_ );if (! --i||d)z(~i );&#125; if(p==b*5&amp;&amp;O)&#123;p-=b;O--;&#125;&#125;return 0U; &#125;if(! (P=( f*)calloc /*]*/ (Q ,I)))return 1; &#123;;&#125;for(_=p=1;p&lt;I;p++)&#123;e(q=1);while (q&lt; p&amp;&amp; strcmp( l[p ] ,l[(q)]))++ q; t=stdin;if(q&lt;p)&#123;(void)memcpy/* " */ (&amp;P [p],&amp;P [q ] ,Q);continue ;&#125;if(strcmp(l[p],"-"))&#123;t=fopen(l [ p] ,"rb" ) ;if(!t )&#123;&#123;;&#125; ;printf(05+*o,l[p ]);return+1; &#123;;&#125; &#125;&#125;_=b= 1&lt;&lt;16 ;*&amp;O=5;do&#123;if(!(P[p].q=realloc (P[p].q,(P[p].P += b)+1)))&#123;return 01;&#125;O &amp;=72 /6/*][*/;P[p].o+=d=fread(P[p] .q +P[ p ]. o, 1,b,t) ;&#125;// while(d==b) ;P [p].q[ P[ p] .o ]= 012;d =0; e(fclose(t ) );P [p] .p =P[ p] .q;if (O) &#123;for(;d&lt;P[ p] .o ;d= q+ 1) &#123;q= d; while(q&lt;P[ p].o&amp;&amp;P[ p].q[q]- 10 )&#123; q++;&#125;b=q-d; _=P [p]. d ; if(b&gt;_)&#123;/*]b */ P[p].d=b;&#125;&#123;; &#125; #undef/*pqdz'.*/ e// ; #define/*s8qdb]*/e/**/0 // //&lt;&lt;.&lt;&lt;.----.&gt;.&lt;&lt;.&gt;++.++&lt; .[&gt;] /*P[*/P[p].b++;continue;&#125;&#125;&#125;t= stdout; for (p=1;p&lt;I;p++)&#123;/**/if(P[p].b&gt;i )&#123;i=P[p].b;&#125;&#125; if (O)&#123;for(p=0;p&lt;i;p++)&#123;q=0;/*[*/while(I &gt;++q)&#123;_=P[q].p-P[q ].q;b= 0;if(_&lt;P[q ].o)&#123;while(012-*P[q].p) &#123;putchar(*(P[q].p++));b++;&#125;P[q]. p++;&#125; ;while (P[ q].d&gt;b++)putchar(040);&#125; putchar(10);&#125;return 0;&#125;p =1; for(; p&lt;I ;p++)fwrite(P[p] .q,P[ p].o,1,t);return 0 ;&#125;// #/*] ]&lt;. [-]&lt;[-]&lt;[- ]&lt;[ -]&lt; [- ]&lt;;*/elif e //b |(1 &lt;&lt; ( __LINE__ /* &gt;&gt; `*//45)) | 01U # /* */ endif // 修改vim编辑器提示信息12345678910111213141516171819202122232425262728vim /etc/vimrchi comment ctermfg=6 #注释变为淡蓝色set nu #vim编辑器里出现行号syntax on #语法高亮set ignorecase #搜索模式里忽略大小写vim .vimrc #优先生效set ignorecase set cursorline #设置下划线set autoindentautocmd BufNewFile *.sh exec ":call SetTitle()"func SetTitle() if expand("%:e") == 'sh' call setline(1,"#!/bin/bash") call setline(2,"#") call setline(3,"#********************************************************************") call setline(4,"#Author: LH") call setline(5,"#QQ: 501962149") call setline(6,"#Date: ".strftime("%Y-%m-%d")) call setline(7,"#FileName： ".expand("%")) call setline(8,"#URL: https://blog.csdn.net/weixin_43551152") call setline(9,"#Description： 今晚打老虎") call setline(10,"#Copyright (C): ".strftime("%Y")." All rights reserved") call setline(11,"#********************************************************************") call setline(12,"") endif endfuncautocmd BufNewFile * normal G 指定yum源，base源和epel源ctneos6 base源12345678yum install -y autofs #设置/misc/cd神奇目录自动挂载chkconfig autofs on #设置autofs服务开机启动vim /etc/yum.repos.d/Centos-6.repo #base源[base]name=CentOS- Base-cdrom failovermethod=prioritybaseurl=file:///misc/cdgpgcheck=0 ctneos6 epel源 123456789vim /etc/yum.repos.d/epel.repo #epel源 [epel]name=Extra Packages for Enterprise Linux 6 - $basearchbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/6/$basearch#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6 ctneos7 base源12345678yum install -y autofs #设置/misc/cd神奇目录自动挂载systemctl enable autofs #设置autofs服务开机启动vim /etc/yum.repos.d/Centos-7.repo #base源[base]name=CentOS-$releasever - Base -sr0--failovermethod=prioritybaseurl=file:///data/cdromgpgcheck=0 ctneos7 epel源12345678910vim /etc/yum.repos.d/epel.repo #epel源[epel]name=Extra Packages for Enterprise Linux 7 - $basearchbaseurl=https://mirrors.tuna.tsinghua.edu.cn/epel/7/$basearch#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7~ 修改ssh协议默认端口1234vim /etc/ssh/sshd_config #Port 22 Port 10086 # 修改默认端口 systemctl restart sshd.service 安装防火墙12yum install firewalldsystemctl start firewalld 计划任务设置自动更新12345yum -y install yum-cron vim /etc/yum/yum-cron.confapply_updates = yes #no改为yessystemctl start crondsystemctl start yum-cron 安装py3.61234567891011yum install python36 cd /usr/bin/ rm python ln -s python3.6 python 将yum的解析器改为Python2.7vim /usr/bin/yum#!/usr/bin/python2.7 #改第一行vim /usr/libexec/urlgrabber-ext-down#!/usr/bin/python2.7 #改第一行 yum install python36-pip]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种小工具和小玩意，小火车，黑客代码，国际象棋盘，三角形]]></title>
    <url>%2F2018%2F11%2F11%2F%E5%90%84%E7%A7%8D%E5%B0%8F%E5%B7%A5%E5%85%B7%E5%92%8C%E5%B0%8F%E7%8E%A9%E6%84%8F%EF%BC%8C%E5%B0%8F%E7%81%AB%E8%BD%A6%EF%BC%8C%E9%BB%91%E5%AE%A2%E4%BB%A3%E7%A0%81%EF%BC%8C%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B%E7%9B%98%EF%BC%8C%E4%B8%89%E8%A7%92%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[笔记本电脑查询已连接WIFI密码###本方法适用于忘了WiFi密码或者通过其他手段连上WiFi却不知道密码的12345#按Windows+R，输入cmd启动命令行#命令行中输入netsh wlan show profiles #列出已保存WiFinetsh wlan show profiles name=12345 key=clear #即可查询WiFi名称为12345的密码，在安全设置中，密码即为下方关键内容 Linux下取出指定位的随机密码1cat /dev/urandom |tr -dc 'a-zA-Z0-9_' |head -c12 #取出12位的随机密码，尾数改变改为8即取8位 Linux命令颜色和欢迎界面！在全局设置中写入配置 字体颜色和背景设置123vim /etc/profile.d/env.sh #打开配置文件PS1="\[\e[1;32m\][\u@\h \W]\\$\[\e[0m\]"#按esc，然后输入wq保存，重新登陆客户端即可 如图可以看到上面两图命令颜色变成了绿色那么欢迎界面怎么设置呢？ 欢迎界面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849vim /etc/motd #打开配置文件,复制下面的字符 /*[*/#include&lt;stdio.h&gt;// #include&lt;stdlib.h&gt;//]++++[-&gt;++[-&gt;+&gt;++++&lt;&lt;]&lt;][(c)2013] #ifndef e//[o #include&lt;string.h&gt;//]![misaka.c,size=3808,crc=d0ec3b36][ #define e 0x1// typedef struct&#123;int d,b,o,P;char*q,*p;&#125;f;int p,q,d,b,_=0//| #include __FILE__//]&gt;&gt;&gt;[-&gt;+&gt;++&lt;&lt;]&lt;[-&lt;&lt;+&gt;&gt;&gt;++&lt;]&gt;&gt;+MISAKA*IMOUTO #undef e//[-&gt;[-&lt;&lt;+&lt;+&lt;+&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;&lt;++[-&gt;&gt;+&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;]&gt;+&gt;+++&gt;+++[&gt;]]b #define e(c)/**/if((_!=__LINE__?(_=__LINE__):0))&#123;c;&#125;//[20002,+[-.+] ,O,i=0,Q=sizeof(f);static f*P;static FILE*t;static const char*o[]=&#123;// "\n\40\"8oCan\40not\40open %s\n\0aaFbfeccdeaEbgecbbcda6bcedd#e(bbed$bbd", "a6bgcdbbccd#ead$c%bcdea7bccde*b$eebbdda9bsdbeccdbbecdcbbcceed#eaa&amp;bae$cbe", "e&amp;cbdd$eldbdeedbbdede)bdcdea&amp;bbde1bedbbcc&amp;b#ccdee&amp;bdcdea'bbcd)e'bad(bae&amp;bccd", "e&amp;bbda1bdcdee$bbce#b$c&amp;bdedcd%ecdca4bhcdeebbcd#e$b#ecdcc$bccda7bbcc#e#d%c*bbda", "&gt;bad/bbda"&#125;;static int S()&#123;return(o[p][q]);&#125;static/**/int/**/Z=0 ;void/**/z(int// l)&#123;if(/**/Z-l)&#123;Z=l;q++;if(p&lt;b*5&amp;&amp;!S())&#123;p+=b;q=0;&#125;&#125;&#125;int main(int I, /**/char**l)&#123;// d=sizeof(f*);if(1&lt;(O=_))&#123;b=((sizeof(o)/sizeof(char*))-1)/4;q=22; p= 0;while(p&lt;b*5)&#123; /*&lt;*/if(Z-1)&#123;d=S()&gt;96;i=S()-(d?96:32) ;q++;if(p&lt;b*5&amp;&amp;!S())&#123;p+=b; q= 0;&#125;Z=1;&#125;/*[[*/ while(i)&#123;_=o[0][S()-97];I=_-10?b:1; for( ;I--;)putchar(_ );if (! --i||d)z(~i );&#125; if(p==b*5&amp;&amp;O)&#123;p-=b;O--;&#125;&#125;return 0U; &#125;if(! (P=( f*)calloc /*]*/ (Q ,I)))return 1; &#123;;&#125;for(_=p=1;p&lt;I;p++)&#123;e(q=1);while (q&lt; p&amp;&amp; strcmp( l[p ] ,l[(q)]))++ q; t=stdin;if(q&lt;p)&#123;(void)memcpy/* " */ (&amp;P [p],&amp;P [q ] ,Q);continue ;&#125;if(strcmp(l[p],"-"))&#123;t=fopen(l [ p] ,"rb" ) ;if(!t )&#123;&#123;;&#125; ;printf(05+*o,l[p ]);return+1; &#123;;&#125; &#125;&#125;_=b= 1&lt;&lt;16 ;*&amp;O=5;do&#123;if(!(P[p].q=realloc (P[p].q,(P[p].P += b)+1)))&#123;return 01;&#125;O &amp;=72 /6/*][*/;P[p].o+=d=fread(P[p] .q +P[ p ]. o, 1,b,t) ;&#125;// while(d==b) ;P [p].q[ P[ p] .o ]= 012;d =0; e(fclose(t ) );P [p] .p =P[ p] .q;if (O) &#123;for(;d&lt;P[ p] .o ;d= q+ 1) &#123;q= d; while(q&lt;P[ p].o&amp;&amp;P[ p].q[q]- 10 )&#123; q++;&#125;b=q-d; _=P [p]. d ; if(b&gt;_)&#123;/*]b */ P[p].d=b;&#125;&#123;; &#125; #undef/*pqdz'.*/ e// ; #define/*s8qdb]*/e/**/0 // //&lt;&lt;.&lt;&lt;.----.&gt;.&lt;&lt;.&gt;++.++&lt; .[&gt;] /*P[*/P[p].b++;continue;&#125;&#125;&#125;t= stdout; for (p=1;p&lt;I;p++)&#123;/**/if(P[p].b&gt;i )&#123;i=P[p].b;&#125;&#125; if (O)&#123;for(p=0;p&lt;i;p++)&#123;q=0;/*[*/while(I &gt;++q)&#123;_=P[q].p-P[q ].q;b= 0;if(_&lt;P[q ].o)&#123;while(012-*P[q].p) &#123;putchar(*(P[q].p++));b++;&#125;P[q]. p++;&#125; ;while (P[ q].d&gt;b++)putchar(040);&#125; putchar(10);&#125;return 0;&#125;p =1; for(; p&lt;I ;p++)fwrite(P[p] .q,P[ p].o,1,t);return 0 ;&#125;// #/*] ]&lt;. [-]&lt;[-]&lt;[- ]&lt;[ -]&lt; [- ]&lt;;*/elif e //b |(1 &lt;&lt; ( __LINE__ /* &gt;&gt; `*//45)) | 01U # /* */ endif //#按esc，然后输入wq保存，重新登陆客户端即可 或者复制这个12345678910111213141516171819202122232425262728▽ _.._ ,------------. ,&apos; `. ( I want you! ) / __) __` \ `-,----------&apos; ( (`-`(-&apos;) ) _.-&apos; /) \ = / ( /&apos; |--&apos; . \ ( ,---| `-.)__` )( `-.,--&apos; _`-. &apos;/,&apos; ( Uu&quot;, (_ , `/,-&apos; ) `.__, : `-&apos;/ /`--&apos; | `--&apos; | ` `-._ / \ ( /\ . \. / |` \ ,-\ / \| .) / \ ( ,&apos;|\ ,&apos; : | \,`.`--&quot;/ &#125; `,&apos; \ |,&apos; / / &quot;-._ `-/ | &quot;-. &quot;-.,&apos;| ; / _/[&quot;---&apos;&quot;&quot;] : / |&quot;- &apos; &apos; | / ` |~ 在centos下用cmatrix做出×××屏幕代码雨效果文章出处： http://blog.51cto.com/5232821/2146115 作者：hubbywen01、下载cmatrix-1.2a.tar.gz文件1234567891011[root@localhost ~]# wget https://jaist.dl.sourceforge.net/project/cmatrix/cmatrix/1.2a/cmatrix-1.2a.tar.gz #centos 下载不了此安装包，需自行下载到本地，rz上传到Linux系统--2018-07-17 15:06:03-- https://jaist.dl.sourceforge.net/project/cmatrix/cmatrix/1.2a/cmatrix-1.2a.tar.gzResolving jaist.dl.sourceforge.net (jaist.dl.sourceforge.net)... 150.65.7.130, 2001:df0:2ed:feed::feedConnecting to jaist.dl.sourceforge.net (jaist.dl.sourceforge.net)|150.65.7.130|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 74376 (73K) [application/x-gzip]Saving to: ‘cmatrix-1.2a.tar.gz’100%[=====================================================&gt;] 74,376 4.68KB/s in 16s 2018-07-17 15:06:20 (4.68 KB/s) - ‘cmatrix-1.2a.tar.gz’ saved [74376/74376] 2、解压缩cmatrix-1.2a.tar.gz文件123456789101112131415161718192021222324252627282930[root@localhost ~]# tar xvf cmatrix-1.2a.tar.gzcmatrix-1.2a/cmatrix-1.2a/NEWScmatrix-1.2a/TODOcmatrix-1.2a/aclocal.m4cmatrix-1.2a/READMEcmatrix-1.2a/configurecmatrix-1.2a/configure.incmatrix-1.2a/cmatrix.1cmatrix-1.2a/cmatrix.ccmatrix-1.2a/config.guesscmatrix-1.2a/install-shcmatrix-1.2a/cmatrix.speccmatrix-1.2a/cmatrix.spec.incmatrix-1.2a/matrix.fntcmatrix-1.2a/config.subcmatrix-1.2a/missingcmatrix-1.2a/mkinstalldirscmatrix-1.2a/Makefile.amcmatrix-1.2a/Makefile.incmatrix-1.2a/mtx.pcfcmatrix-1.2a/config.h.incmatrix-1.2a/matrix.psf.gzcmatrix-1.2a/stamp-h.incmatrix-1.2a/AUTHORScmatrix-1.2a/INSTALLcmatrix-1.2a/ChangeLogcmatrix-1.2a/acconfig.hcmatrix-1.2a/COPYING 123[root@localhost ~]# cd cmatrix-1.2a[root@localhost cmatrix-1.2a]# yum install ncurses-deve 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105[root@bogon cmatrix-1.2a]# ./configure &amp;&amp; make &amp;&amp; make installloading cache ./config.cachechecking for a BSD compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking whether make sets $&#123;MAKE&#125;... yeschecking for working aclocal... missingchecking for working autoconf... missingchecking for working automake... missingchecking for working autoheader... missingchecking for working makeinfo... missingchecking for gcc... nochecking for cc... noconfigure: error: no acceptable cc found in $PATH当执行“./configure &amp;&amp; make &amp;&amp; make install ”命令出现如上信息时，表示没有安装gcc，gcc安装过程如下[root@bogon cmatrix-1.2a]# yum -y install gcc[root@bogon cmatrix-1.2a]# yum -y install gcc-c++[root@bogon cmatrix-1.2a]# yum install make安装完后再运行“./configure &amp;&amp; make &amp;&amp; make install ”命令，如下：[root@localhost cmatrix-1.2a]# ./configure &amp;&amp; make &amp;&amp; make installcreating cache ./config.cachechecking for a BSD compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking whether make sets $&#123;MAKE&#125;... yeschecking for working aclocal... missingchecking for working autoconf... missingchecking for working automake... missingchecking for working autoheader... missingchecking for working makeinfo... missingchecking for gcc... gccchecking whether the C compiler (gcc ) works... yeschecking whether the C compiler (gcc ) is a cross-compiler... nochecking whether we are using GNU C... yeschecking whether gcc accepts -g... yeschecking for a BSD compatible install... /usr/bin/install -cchecking whether make sets $&#123;MAKE&#125;... (cached) yeschecking for main in -lncurses... yeschecking how to run the C preprocessor... gcc -Echecking for ANSI C header files... yeschecking for fcntl.h... yeschecking for sys/ioctl.h... yeschecking for unistd.h... yeschecking for termios.h... yeschecking for termio.h... yeschecking return type of signal handlers... voidchecking for putenv... yeschecking for curses.h... yeschecking for ncurses.h... yeschecking for tgetent in -lncurses... yesUsing ncurses as the termcap librarychecking for use_default_colors in -lncurses... yeschecking for resizeterm in -lncurses... yeschecking for wresize in -lncurses... yeschecking for consolechars... nochecking for setfont... /usr/bin/setfontchecking for /usr/lib/kbd/consolefonts... yeschecking for /usr/share/consolefonts... nochecking for mkfontdir... nochecking for /usr/lib/X11/fonts/misc... nochecking for /usr/X11R6/lib/X11/fonts/misc... noconfigure: warning: *** You do not appear to have an X window fonts directory in the standard*** locations (/usr/lib/X11/fonts/misc or /usr/X11R6/lib/X11/fonts/misc). The*** mtx.pcf font will not be installed. This means you will probably not*** be able to use the mtx fonts in your x terminals, and hence be unable*** to use the -x command line switch. Sorry about that...updating cache ./config.cachecreating ./config.statuscreating Makefilecreating cmatrix.speccreating config.hgcc -DHAVE_CONFIG_H -I. -I. -I. -g -O2 -Wall -Wno-comment -c cmatrix.cgcc -g -O2 -Wall -Wno-comment -o cmatrix cmatrix.o -lncurses -lncursesmake[1]: Entering directory `/root/cmatrix-1.2a'/bin/sh ./mkinstalldirs /usr/local/bin /usr/bin/install -c cmatrix /usr/local/bin/cmatrixmake install-man1make[2]: Entering directory `/root/cmatrix-1.2a'/bin/sh ./mkinstalldirs /usr/local/man/man1mkdir /usr/local/manmkdir /usr/local/man/man1/usr/bin/install -c -m 644 ./cmatrix.1 /usr/local/man/man1/cmatrix.1make[2]: Leaving directory `/root/cmatrix-1.2a'Installing matrix fonts in /usr/lib/kbd/consolefonts...make[1]: Leaving directory `/root/cmatrix-1.2a'**到此，cmatrix安装完成，任意路径，输入cmatrix运行，按q退出。效果如下**[root@localhost cmatrix-1.2a]# cmatrix![](http://i2.51cto.com/images/blog/201807/17/abaa3c9ee4b6cf559c3db8173c2cd2bc.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)cmatrix常用命令如下:-a :异步滚动（默认）-b :随机粗体-B :全部粗体-o :使用旧风格滚动-x :X window 模式-V :显示版本信息-u :刷新频率，0-9，也就是滚动的快慢（值越小越快）-C :显示的颜色，支持green(默认),red,blue,white,yellow,cyan,magenta and black[root@localhost ~]# cmatrix -b -u 3 -C yellow![](http://i2.51cto.com/images/blog/201807/17/4a2e39f2aa2889910d633b6bfb92d18f.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=) Linux上sl工具安装（小火车）centos7上跑火车代码1234wget http://mirror.centos.org/centos/7/extras/x86_64/Packages/epel-release-7-9.noarch.rpmyum install -y epel-release-7-9.noarch.rpmyum install -y slsl #运行程序 centos6上跑火车代码1234wget http://mirror.centos.org/centos-6/6.10/extras/x86_64/Packages/epel-release-6-8.noarch.rpmyum install -y epel-release-6-8.noarch.rpmyum install -y slsl 结果如图： 打出一个指定行与列的矩形，并使其边框闪烁如图： 1234567891011121314151617181920212223242526272829303132#!/bin/bash#********************************************************************read -p "please input colume: " colread -p "please input line: " linefor i in `seq $line`;do for j in `seq $col`;do #if [ $i -eq 1 -o $i -eq $line -o $j -eq 1 -o $j -eq $col ];then #如果当前行等于1或者等于行号line，或者当前列等于1或者等于列号col，则 # COLOR=$[RANDOM%7+31] # echo -e "\033[1;5;$&#123;COLOR&#125;m*\033[0m\c" #else # echo -e "*\c" #fi 以上方法为if语句，下面为case语句，都可实现 case $i in 1|$line) COLOR=$[RANDOM%7+31] echo -e "\033[1;5;$&#123;COLOR&#125;m*\033[0m\c" ;; *) case $j in 1|$col) COLOR=$[RANDOM%7+31] echo -e "\033[1;5;$&#123;COLOR&#125;m*\033[0m\c" ;; *) echo -e "*\c" esac esac done echo done 实验：输入一个行号，打印一个等腰三角形如图： 1234567891011121314#!/bin/bash#********************************************************************read -p "Please input line: " linefor i in `seq $line`;do let star=$i*2-1 let space=$line-$i for j in `seq $space`;do echo -n " " done for k in `seq $star`;do echo -n "*" done echodone 选菜菜单PS3=”Please input a number:”select MENU in lamian huimian gaifan jiaozi baozi quit;do case $REPLY in 1|2) echo “The price is 15元” ;; 3|5) echo “The price is 20元” ;; 4) echo “The price is 25元” ;; 6) echo “bye” break ;; *) echo “Input false” esacdone 九九乘法表打印出九九乘法表例如123456for i in &#123;1..9&#125;;do for j in $(seq $i);do echo -en "$&#123;i&#125;X$&#123;j&#125;=$[$i*$j]\t" done echodone 打印出国际象棋棋盘123456789101112#！bin/bashfor i in &#123;1..8&#125;;do for j in &#123;1..8&#125;;do flag=$[(j+i)%2] if [ $flag -eq 0 ];then echo -e "\033[47m \033[0m\c" else echo -e " \c" fi done echodone]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌chrome浏览器自动启用flash]]></title>
    <url>%2F2018%2F11%2F08%2F%E8%B0%B7%E6%AD%8Cchrome%E6%B5%8F%E8%A7%88%E5%99%A8%E8%87%AA%E5%8A%A8%E5%90%AF%E7%94%A8flash%2F</url>
    <content type="text"><![CDATA[新版的chrome浏览器不支持启用flash插件了，这也导致有时候打开视频或者微博上传图片时，浏览器提示你flash未启用或者版本过低，这时就算你再下载安装Adobe Flash Player也是不管用的。 这时我们先去chrome实验室界面在地址栏输入：1chrome://flags/#enable-ephemeral-flash-permission 选择取消Disabled。取消该实验室选项，如下图： 然后去在地址栏输入：1chrome://settings/content/flash 在下面的允许选项添加12http://*https://* 如图：并且退出浏览器之后不会不保存，Flash选项。此时重启浏览器，你就发现微博上传图片就可以正常使用了]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell防止黑客攻击]]></title>
    <url>%2F2018%2F10%2F21%2Fshell%E9%98%B2%E6%AD%A2%E9%BB%91%E5%AE%A2%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[shell防止黑客攻击1234567891011#!bin/bash#********************************************************************while : ;do iplist=`who | sed -rn '/^cracker/s/.*\((.*)\)/\1/p'` #取出以cracker开头的黑客IP地址 if [ "$iplist" ] ;then pkill -9 -U cracker echo "cracker is killed" echo sshd:$iplist &gt;&gt; /etc/hosts.deny #将拦截的IP放到配置文件中，禁止下次连接 fi sleep 10done]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量ping IP脚本]]></title>
    <url>%2F2018%2F10%2F20%2F%E6%89%B9%E9%87%8Fping%20IP%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[批量ping一个网络ID中的254个IP地址，并把能够Ping通的地址放到：/tmp/iplist.log例如ping百度的IP：123.125.115.110bash scanip00.sh 输入正确格式的IP地址cat /tmp/iplist.log结果 1234567891011121314151617#********************************************************************#scanip00.sh # 脚本名&gt; /tmp/iplist.log #每次运行前清空该文件内容read -p "Please input a netid:(eg:192.168.34.0) " netid #输入IPnetid=`echo $netid | sed -nr 's#(.*)\..*#\1#p'`echo netid=$netidfor id in &#123;1..254&#125;;do &#123; if ping -c1 -w1 $netid.$id &amp;&gt;/dev/null ;then echo "$netid.$id" &gt;&gt; /tmp/iplist.log #ping通的放入文件 echo $netid.$id is up else echo $netid.$id is down fi &#125;&amp; #并行执行donewait]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables防火墙]]></title>
    <url>%2F2018%2F10%2F20%2Fiptables%2F</url>
    <content type="text"><![CDATA[1. Linux防火墙 防火墙的概念 iptables的基本认识 iptables的组成 iptables的基本语法 iptables之forward的概念 iptables之地址转换法则 SNAT源地址转换的具体实现 DNAT目标地址转换的具体实现 1.1. 安全技术 入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主，提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式。 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式。 防火墙（FireWall ）：隔离功能， 工作在网络或主机边缘，对进出网络或主机的数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略。 1.2. 防火墙的分类 主机防火墙：服务范围为当前主机。网络防火墙：服务范围为防火墙一侧的局域网。 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件实现， Checkpoint,NetScreen。软件防火墙：运行于通用硬件平台之上的防火墙的应用软件。 网络层防火墙： OSI模型下四层。应用层防火墙/代理服务器：代理网关， OSI模型七层。 1.3. 网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议状态等因素，或他们的组合来确定是否允许该数据包通过。 优点：对用户来说透明，处理速度快且易于维护。 缺点：无法检查应用层数据，如病毒等。 1.4. 应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段。 内外网用户的访问都是通过代理服务器上的“链接”来实现。 优点： 在应用层对数据进行检查，比较安全。 缺点：增加防火墙的负载。 现实生产环境中所使用的防火墙一般都是二者结合体。即先检查网络数据，通过之后再送到应用层去检查。 2. iptables的基本知识Netfilter组件 内核空间，集成在linux内核中。 扩展各种网络服务的结构化底层框架。 内核中选取五个位置放了五个hook(勾子) function（INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING），而这五个hook function向用户开放，用户可以通过一个命令工具（iptables）向其写入规则。 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上。 三种报文流向： 流入本机：PREROUTING –&gt; INPUT –&gt; 用户空间进程 流出本机：用户空间进程 –&gt; OUTPUT –&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING 防火墙工具 iptables命令行工具，工作在用户空间。用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包。 firewalldCentOS 7 引入了新的前端管理工具。管理工具：firewall-cmd 命令行firewall-config 图形 3. iptables的组成iptables由五个表和五个链以及一些规则组成。 3.1. 五个表table：filter、nat、mangle、raw、security table 说明 filter 过滤规则表，根据预定义的规则过滤符合条件的数据包。 nat network address translation 地址转换规则表。 mangle 修改数据标记位规则表。 raw 关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度。 security 用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现。 优先级由高到低的顺序为:security –&gt; raw –&gt; mangle –&gt; nat –&gt; filter 3.2. 五个内置链chain，对应5个钩子hook INPUT OUTPUT FORWARD PREROUTING POSTROUTING 3.3. Netfilter表和链对应关系 filter：INPUT, FORWARD, OUTPUT nat：PREROUTING, INPUT, OUTPUT, POSTROUTING mangle：5个都有 raw：PREROUTING, OUTPUT 4. IPTABLES和路由4.1. 路由功能发生的时间点报文进入本机后 判断目标主机是否为本机 是：INPUT 否：FORWARD 报文离开本机之前 判断由哪个接口送往下一跳 内核中数据包的传输过程 4.2. 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 如果数据包就是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过OUTPUT链，然后到达POSTROUTING链输出。 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到达POSTROUTING链输出。 5. iptables规则规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动作作出处理。 匹配条件：默认为与条件，同时满足 基本匹配： IP，端口， TCP的Flags（SYN，ACK等） 扩展匹配：通过复杂高级功能匹配 处理动作：称为target，跳转目标 内建处理动作： ACCEPT，DROP，REJECT，SNAT，DNAT，MASQUERADE，MARK，LOG… 自定义处理动作：自定义chain，利用分类管理复杂情形。 规则要添加在链上，才生效；添加在自定义上不会自动生效 链chain： 内置链：每个内置链对应于一个钩子函数。 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制；只有Hook钩子调用自定义链时，才生效。 6. iptables添加要点iptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 链上规则的次序，即为检查的次序，因此隐含一定的法则 同类规则(访问同一应用)，匹配范围小的放上面不同类规则(访问不同应用)，匹配到报文频率较大的放上面将那些可由一条规则描述的多个规则合并为一个 iptables 规则优化 安全放行所有入站和出站的状态为ESTABLISHED状态连接 谨慎放行入站的新请求 有特殊目的限制访问功能，要在放行规则之前加以拒绝 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 不同类的规则（访问不同应用），匹配范围大的放在前面 应该将那些可由一条规则能够描述的多个规则合并为一条 设置默认策略，建议白名单（只放行特定连接） ​ iptables -P，不建议 ​ 建议在规则的最后定义规则做为默认策略 语法：iptables [-t table] 子命令 chain [-m 匹配条件 [模块选项]] -j 处理动作 [模块选项] table: raw, mangle, nat, [filter]默认 实验环境准备：Centos7： 12systemctl stop firewalld.servicesystemctl disable firewalld.service Centos6： 12service iptables stopchkconfig iptables off 7. iptables命令1234567891011121314man 8 iptablesiptables [-t table] &#123;-A|-C|-D&#125; chain rule-specificationiptables [-t table] -I chain [rulenum] rule-specificationiptables [-t table] -R chain rulenum rule-specificationiptables [-t table] -D chain rulenumiptables [-t table] -S [chain [rulenum]]iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...]iptables [-t table] -N chainiptables [-t table] -X [chain]iptables [-t table] -P chain targetiptables [-t table] -E old-chain-name new-chain-namerule-specification = [matches...] [target]match = -m matchname [per-match-options]target = -j targetname [per-target-options] 8. 用法：1iptables [-t table] SUBCOMMAND chain [-m matchname [per-match-options]] -j targetname [per-target-options] 9. 选项9.1. 表table，需要实现的功能 123-t tabletable的值：raw, mangle, nat, [filter]默认 9.2. SUBCOMMAND：1、 链管理： 1234567891011121314151617181920212223242526272829303132-P Policy，设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃-N chain_name new, 自定义一条新的规则链。-X chain_name delete，删除自定义的、空的、规则链。-E old_name new_name 重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除。示例：一、默认策略1. 黑名单# iptables -P INPUT ACCEPT# iptables -P OUTPUT ACCEPT2. 白名单2.1 白名单 之DROP# iptables -P INPUT DROP# iptables -P OUTPUT DROP2.2 白名单 之REJECT# iptables -P INPUT DROP# iptables -P OUTPUT DROP二、自定义链# iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT# iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT# iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT# iptables -A cifs_rules -j RETURN# iptables -I INPUT 5 -s 172.18.0.0/16 -j cifs_rules# iptable -D INPUT 5 //删除引用# iptable -F cifs_rules //清空链规则# iptable -X cifs_rules //删除链 2、查看： 12345678910-L list, 列出指定链上的所有规则，本选项须置后。-n numberic，以数字格式显示地址和端口号。-v verbose，详细信息。-vv 更详细。-x exactly，显示计数器结果的精确值，而非单位转换后的易读值。--line-numbers 显示规则的序号。-S selected，以iptables-save 命令格式显示链上规则。常用组合：-vnL-vvnxL --line-numbers 3、规则管理： 1234567891011-A append，追加-I insert, 插入，要指明插入至的规则编号，默认为第一条。-D delete，删除 (1) 指明规则序号。 (2) 指明规则本身。-R replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换-F flush，清空指定的规则链。-Z zero，置零。 iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数。 (2) 匹配到的所有报文的大小之和。 9.3. chain：PREROUTING， INPUT， FORWARD， OUTPUT， POSTROUTING自定义链 9.4. 匹配条件 基本：通用的， PARAMETERS 扩展：需加载模块， MATCH EXTENTIONS 9.5. 基本匹配条件：无需加载模块，由iptables/netfilter自行提供。 1234567[!] -s, --source address[/mask][,...] 源IP地址或范围。不能是离散值。[!] -d, --destination address[/mask][,...] 目标IP地址或范围。[!] -p, --protocol protocol 指定协议，可使用数字如0（all）。 protocol: tcp, udp, icmp, icmpv6, udplite, esp, ah, sctp, mh or “all“ 参看： /etc/protocols[!] -i, --in-interface name 报文流入的接口；只能应用于数据报文流入环节，只应用于INPUT、 FORWARD、 PREROUTING链。[!] -o, --out-interface name 报文流出的接口；只能应用于数据报文流出的环节，只应用于FORWARD、 OUTPUT、 POSTROUTING链。 9.6. 扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效。 查看帮助 1man iptables-extensions 9.6.1. 隐式扩展：在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展机制，不需要手动加载扩展模块。 1、tcp协议的扩展选项-p tcp：隐含了-m tcp 12345678910111213[!] --source-port, --sport port[:port] 匹配报文源端口，可为端口范围。[!] --destination-port,--dport port[:port] 匹配报文目标端口，可为范围。[!] --tcp-flags mask comp mask 需检查的标志位列表，用分号（,）分隔 例如 SYN,ACK,FIN,RST comp 在mask列表中必须为1的标志位列表，无指定则必须为0，用分号（,）分隔 示例： --tcp-flags SYN,ACK,FIN,RST SYN 表示要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0 --tcp-flags SYN,ACK,FIN,RST SYN,ACK --tcp-flags ALL ALL --tcp_flags ALL NONE[!] --syn 用于匹配第一次握手。 相当于： --tcp-flags SYN,ACK,FIN,RST SYN 2、udp扩展-p udp：隐含了-m udp 12[!] --source-port, --sport port[:port] 匹配报文的源端口或端口范围。[!] --destination-port,--dport port[:port] 匹配报文的目标端口或端口范围。 3、icmp-p icmp：隐含了-m icmp 1234[!] --icmp-type &#123;type[/code]|typename&#125; type/code 0/0 echo-reply icmp应答 8/0 echo-request icmp请求 9.6.2. 显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载扩展模块。 1[-m matchname [per-match-options]] 显式扩展：必须显式地指明使用的扩展模块进行的扩展。 使用帮助： 12CentOS 6: man iptablesCentOS 7: man iptables-extensions 1、multiport扩展以离散方式定义多端口匹配，最多指定15个端口。 123456789101112[!] --source-ports,--sports port[,port|,port:port]...指定多个源端口[!] --destination-ports,--dports port[,port|,port:port]...指定多个目标端口[!] --ports port[,port|,port:port]...多个源或目标端口示例：iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp -m multiport --dports 20:22,80 -j ACCEPT 2、iprange扩展指明连续的（但一般不是整个网络）ip地址范围。 123456[!] --src-range from[-to] 源IP地址范围。[!] --dst-range from[-to] 目标IP地址范围。示例：iptables -A INPUT -d 172.16.1.100 -p tcp --dport 80 -m iprange --src-range 172.16.1.5-172.16.1.10 -j DROP 3、mac扩展指明源MAC地址适用于： PREROUTING，FORWARD，INPUT chains 123456[!] --mac-source XX:XX:XX:XX:XX:XX示例：iptables -A INPUT -s 172.16.0.100 -m mac --mac-source 00:50:56:12:34:56 -j ACCEPTiptables -A INPUT -s 172.16.0.100 -j REJECT 3、set扩展依赖于ipset命令行工具；set存在类型，常用的有两个： 12hash:net 网络地址的集合hash:ip IP地址的集合 使用方式： 1234567891011121314//先创建集合：ipset create NAME TYPE//向集合添加元素：ipset add NAME ELEMENT示例：yum install ipsetipset create allowpinghosts hash:ip //如果是网段用hash:netipset listipset add allowpinghosts 172.18.0.100ipset add allowpinghosts 172.18.0.200ipset list iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPTiptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT 4、string扩展对报文中的应用层数据做字符串模式匹配检测 123456789101112--algo &#123;bm|kmp&#125; 字符串匹配检测算法 bm： Boyer-Moore kmp： Knuth-Pratt-Morris --from offset 开始偏移--to offset 结束偏移[!] --string pattern 要检测的字符串模式[!] --hex-string pattern 要检测字符串模式， 16进制格式示例：iptables -I INPUT -m string --string "sex" --algo bm -j REJECTiptables -I OUTPUT -m string --string "sex" --algo bm -j REJECT 5、time扩展根据将报文到达的时间与指定的时间范围进行匹配。 123456789101112--datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期--datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]--timestart hh:mm[:ss] 时间--timestop hh:mm[:ss][!] --monthdays day[,day...] 每个月的几号。[!] --weekdays day[,day...] 星期几， 1 – 7 分别表示星期一到星期日。--kerneltz 内核时区，不建议使用，CentOS7系统默认为UTC。 注意：centos6 不支持kerneltz ，--localtz指定本地时区(默认)示例：iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.10 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP 6、connlimit扩展根据每客户端IP做并发连接数数量匹配。可防止CC(Challenge Collapsar挑战黑洞)攻击。 1234567--connlimit-upto # 连接的数量小于等于#时匹配--connlimit-above # 连接的数量大于#时匹配上述二个选线通常分别与默认的拒绝或允许策略配合使用。示例：iptables -A INPUT -d 172.16.100.10 -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT 7、limit扩展基于收发报文的速率做匹配。令牌桶过滤器，令牌桶（bucket），突发尖峰 1234567--limit #[/second|/minute|/hour|/day]--limit-burst number示例：iptables -I INPUT -d 172.16.100.10 -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 5 -j ACCEPTiptables -I INPUT 2 -p icmp -j REJECT 8、state扩展根据“连接追踪机制”去检查连接的状态。较耗资源，消耗cpu，消耗内核空间的内存。 conntrack机制：追踪本机上的请求和响应之间的关系。 状态有如下几种： NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求。 ESTABLISHED： NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通信状态。 RELATED：新发起的但与已有连接相关联的连接，如： ftp协议中的数据连接与命令连接之间的关系。 INVALID：无效的连接，如flag标记不正确。 UNTRACKED：未进行追踪的连接，如raw表中关闭追踪。 123456789101112131415161718192021222324[!] --state state示例：iptables -F入栈方向:已建立的连接都放行22,21,139,445,80 NEWiptables -A INPUT -m state --state ESTABLISHED -j ACCEPTiptables -A INPUT -p tcp -m multiport --dports 21:22,80,139,445 -m state --state NEW -j ACCEPTiptables -I INPUT 3 -p tcp -m state --state RELATED -j ACCEPT出栈方向:已建立的连接都放行iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT默认策略iptables -A INPUT ! -i lo -j REJECTiptables -A OUTPUT ! -i lo -j REJECT可以合并iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 1/proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 1/proc/sys/net/nf_conntrack_max 不同的协议的连接追踪时长 1/proc/sys/net/netfilter/ 注意：CentOS7 需要加载模块： 1modprobe nf_conntrack iptables的链接跟踪表最大容量为 12/proc/sys/net/nf_conntrack_max各种状态的超时链接会从表中删除；当模板满载时，后续连接可能会超时。 解决方法两个： (1) 加大nf_conntrack_max 值 12345678vi /etc/sysctl.confnet.nf_conntrack_max = 393216net.netfilter.nf_conntrack_max = 393216//不修改/etc/sysctl.conf文件内容，而是在/etc/sysctl.d/下单独创建一个配置文件nf_conntrack_max.confvim /etc/sysctl.d/nf_conntrack_max.confnet.nf_conntrack_max = 1000000sysctl -p (2) 降低 nf_conntrack timeout时间 123456vi /etc/sysctl.confnet.netfilter.nf_conntrack_tcp_timeout_established = 300net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120iptables -t nat -L -n 开放被动模式的ftp服务 (1) 装载ftp连接追踪的专用模块：跟踪模块路径：/lib/modules/kernelversion/kernel/net/netfilter 12345678910vim /etc/sysconfig/iptables-config 配置文件IPTABLES_MODULES="nf_conntrack_ftp"vim /etc/sysconfig/modules/nf_conntrack.modules#!/bin/bash/sbin/modprobe nf_conntrack_ftpmodproble nf_conntrack_ftpmodinfo nf_conntrack_ftplsmod | grep nf_conntrack_ftp (2) 放行请求报文：命令连接： NEW, ESTABLISHED数据连接： RELATED, ESTABLISHED 12iptables –I INPUT -d LocalIP -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -d LocalIP -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行响应报文： 1iptables -I OUTPUT -s LocalIP -p tcp -m state --state ESTABLISHED -j ACCEPT 开放被动模式的ftp服务示例 12345678910yum install vsftpdsystemctl start vsftpdmodprobe nf_conntrack_ftpiptables -Fiptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -A INPUT -p tcp --dport 21 -m state --state NEW -j ACCEPTiptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPTiptables -P INPUT DROPiptables -P OUTPUT DROPiptables -vnL 9.7. 处理动作：1234567891011121314-j targetname [per-target-options]//targetACCEPT 接受DROP 丢弃REJECT 拒绝。弹回，快速断开。--reject-with:icmp-port-unreachable默认RETURN 返回调用链REDIRECT 端口重定向LOG 记录日志， dmesgMARK 做防火墙标记DNAT 目标地址转换SNAT 源地址转换MASQUERADE 地址伪装...自定义链： Target： 1234567891011LOG：非中断target，本身不拒绝和允许，放在拒绝和允许规则前，并将日志记录在/var/log/messages系统日志中。--log-level level 级别： debug， info， notice, warning, error, crit, alert,emerg--log-prefix prefix 日志前缀，用于区别不同的日志，最多29个字符示例：iptables -I INPUT -s 10.0.1.0/24 -p tcp -m multiport --dports 80,21,22,23 -m state --state NEW -j LOG --log-prefix "new connections: " 10. 规则任何不允许的访问，应该在请求到达时给予拒绝。规则在链接上的次序即为其检查时的生效次序。 基于上述，规则优化 安全放行所有入站和出站的状态为ESTABLISHED状态连接。 谨慎放行入站的新请求。 有特殊目的限制访问功能，要在放行规则之前加以拒绝。 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理。 不同类的规则（访问不同应用），匹配范围大的放在前面。 应该将那些可由一条规则能够描述的多个规则合并为一条。 设置默认策略，建议白名单（只放行特定连接）。1） iptables -P，不建议。2） 建议在规则的最后定义规则做为默认策略。 11. 保存及加载规则规则有效期限：使用iptables命令定义的规则，手动删除之前，其生效期限为kernel存活期限。 11.1. 保存规则保存规则至指定的文件 123456789101112- CentOS 6service iptables save将规则覆盖保存至/etc/sysconfig/iptables文件中。- CentOS 7iptables-save &gt; /PATH/TO/SOME_RULES_FILE也可以保存至/etc/sysconfig/iptables文件中。/usr/libexec/iptables/iptables.init save示例：iptables-save &gt; /etc/sysconfig/iptables 11.2. 载入规则查看iptables.service，里面start时会读取文件/etc/sysconfig/iptables，即自动从/etc/sysconfig/iptables 重新载入规则。 12345678910111213CentOS 6：service iptables restartCentOS 7iptables-restore &lt; /PATH/FROM/SOME_RULES_FILE-n, --noflush 不清除原有规则-t, --test 仅分析生成规则集，但不提交开机自动重载规则示例：iptables-restore &lt; /etc/sysconfig/iptables 开机自动重载规则文件中的规则： (1) 用脚本保存各iptables命令；让此脚本开机后自动运行/etc/rc.d/rc.local文件中添加脚本路径 12vim /etc/rc.d/rc.local/PATH/TO/SOME_SCRIPT_FILE (2) 用规则文件保存各规则，开机时自动载入此规则文件中的规则/etc/rc.d/rc.local文件添加 12vim /etc/rc.d/rc.localiptables-restore &lt; /PATH/FROM/IPTABLES_RULES_FILE (3)自定义Unit File，进行iptables-restore 12. 网络防火墙iptables/netfilter网络防火墙： (1) 充当网关 (2) 使用filter表的FORWARD链 注意的问题： (1) 请求-响应报文均会经由FORWARD链，要注意规则的方向性。 (2) 如果要启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行。 需要启用核心转发功能 12/proc/sys/net/ipv4/ip_forwardsysctl -w net.ipv4.ip_forward=1 示例环境：主机C — （ip0）防火墙F（IP1） — 服务器S 主机 IP 服务，端口 主机C 172.18.0.101 防火墙F ip0：172.18.0.1 ip1：192.168.0.1 服务器S 192.168.0.66 httpd，80端口 dns，53 vsftpd，21，被动模式 示例： 1234567891011121314151617181. 开启核心转发功能# sysctl -w net.ipv4.ip_forward=12. 配置路由# route add -net 192.168.10.0/24 gw 172.18.0.66# route add -net default gw 172.18.0.66注意：其实开启核心转发功能会自动添加接口连接网络的路由。3. 配置转发访问httpd、dns、vsftpd服务器# iptables -A FORWARD -s 172.18.0.0/16 -p tcp -m multiport --dports 80,21,53 -m state --state NEW -j ACCEPT# iptables -A FORWARD -s 172.18.0.0/16 -p udp --dport 53 -m state --state NEW -j ACCEPT# iptables -A FORWARD -s 172.18.0.0./16 -p tcp -m state --state RELATED -j ACCEPT# iptables -A FORWARD -m state --state ESTABLISHED -j ACCEPT# iptables -A FORWARD -j DROP注意：(1) 方向：NEW、RELATED，自左至右。ESTABLISHED，双方向。 13. NATNAT：network address translation 隐藏：设置初衷，用来隐藏请求报文中的地址信息。 解决ip地址不足问题。 请求报文：修改源/目标IP，自定义如何修改。 响应报文：修改源/目标IP，连接跟踪机制自动实现。 SNAT：source NAT 作用于POSTROUTING, INPUT 让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装。 请求报文：修改源IP DNAT：destination NAT 作用于PREROUTING , OUTPUT 把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)，但隐藏真实IP。 请求报文：修改目标IP PNAT：port nat，端口和IP都进行修改。 14. SNAT14.1. SNAT：固定IP1234567--to-source [ipaddr[-ipaddr]][:port[-port]]--randomiptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j SNAT --to-source ExtIP示例：# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j SNAT --to-source 172.18.1.6-172.18.1.9 讲解： 123-s 10.0.1.0/24 对源地址（-s 10.0.1.0/24）进行SNAT。-to-source 172.18.1.6-172.18.1.9 源地址转为（）。! –d 10.0.1.0/24 不对内部网路隐藏源地址。可能有多个内部网络（网络接口）都要去除。 14.2. MASQUERADE：动态IP，如拨号网络地址伪装 1234567--to-ports port[-port]--randomiptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE [--to-ports port[-port]]示例：# iptables -t nat -A POSTROUTING -s 10.0.1.0/24 ! –d 10.0.1.0/24 -j MASQUERADE 15. DNAT12--to-destination [ipaddr[-ipaddr]][:port[-port]]# iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination InterSeverIP[:PORT] 15.1. DNAT123示例：# iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 22 -j DNAT --to-destination 10.0.1.22# iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 80 -j DNAT --to-destination 10.0.1.22 15.2. PAT12345示例：# iptables -t nat -A PREROUTING -s 0/0 -d 172.18.100.6 -p tcp --dport 80 -j DNAT --to-destination 10.0.1.22:8080假设mysql在内网工作在正常服务端口，但告知外面工作在6789端口上# iptables -t nat -A PREROUTING -d 10.0.10.62 -p tcp --dport 6789 -j DNAT --to-destination 192.168.0.110:3306 15.3. REDIRECT可用于： PREROUTING OUTPUT 自定义链通过改变目标IP和端口，将接受的包转发至不同端口。响应报文也是由连接追踪自动修改的。 123--to-ports port[-port]示例：iptables -t nat -A PREROUTING -d 172.16.100.10 -p tcp --dport 80 -j REDIRECT --to-ports 8080 讲解：普通用户不能使用小于1024端口。例如httpd默认端口为80。普通用户可监听在8080端口。当有访问80端口的请求到达时，请求会被重定向到8080端口。 16. 练习12345dns, httpd: ALLnfs, smaba, vsftpd: LOCALNETmysql: LOCALHOSTping: ALL, 10/minutessh: 3conns/IP, worktime 一、禁用selinux和firewalld 1234# setenforce 0# sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config# systemctl stop firewalld# systemctl disable firewalld 二、安装软件 123# yum install -y httpd nfs-utils samba bind mariadb-server vsftpd iptables-services# systemctl start httpd nfs smb named mariadb vsftpd iptables# systemctl enable httpd nfs smb named mariadb vsftpd iptables 三、iptables配置 123# iptables -P INPUT ACCEPT# iptables -P OUTPUT ACCEPT# iptables -F 开始配置 12345678910111213141516171819202122232425262728293031323334353637383940414243441. ssh: 3conns/IP, worktime# iptables -A INPUT -p tcp --dport 22 -m connlimit --connlimit-upto 3 -m time --timestart 8:00 --timestop 18:00 --weekdays 1,2,3,4,5 --kerneltz -j ACCEPT# iptables -A OUTPUT -p tcp --sport 22 -j ACCEPT2. dns, httpd: ALL//dns# iptables -I INPUT -p udp --dport 53 -j ACCEPT# iptables -I OUTPUT -p udp --sport 53 -j ACCEPT//httpd# iptables -I INPUT -p tcp --dport 80 -j ACCEPT# iptables -I OUTPUT -p tcp --sport 80 -j ACCEPT3. nfs, samba, vsftpd: LOCALNET//samba# iptables -I INPUT -p tcp -s 192.168.10.0/24 -m multiport --dports 139,445 -j ACCEPT# iptables -I OUTPUT -p tcp -d 192.168.10.0/24 -m multiport --sports 139,445 -j ACCEPT//nfs# iptables -I INPUT -p tcp -s 192.168.10.0/24 -m multiport --dports 111,2049,875,32803,32769,892,662,2020 -j ACCEPT # iptables -I INPUT -p udp -s 192.168.10.0/24 -m multiport --dports 111,2049 -j ACCEPT //vsftpd# modprobe nf_conntrack_ftp# iptables -I INPUT -p tcp --dport 21 -s 192.168.10.0/24 -m state --state NEW -j ACCEPT# iptables -I INPUT -s 192.168.10.0/24 -m state --state RELATED -j ACCEPT# iptables -I INPUT -s 192.168.10.0/24 -m state --state ESTABLISHED -j ACCEPT# iptables -I OUTPUT -d 192.168.10.0/24 -m state --state ESTABLISHED -j ACCEPT4. mysql: LOCALHOST# iptables -I INPUT -p tcp --dport 3306 -i lo -j ACCEPT# iptables -I OUTPUT -p tcp --sport 3306 -o lo -j ACCEPT5. ping: ALL, 10/minute# iptables -I INPUT -p icmp --icmp-type 8 -m limit --limit 10/minute -j ACCEPT# iptables -I OUTPUT -p icmp --icmp-type 0 -j ACCEPTx. 最后的drop策略# iptables -A INPUT ! -i lo -j DROP# iptables -A OUTPUT ! -o lo -j DROP]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本进阶和条件语句]]></title>
    <url>%2F2018%2F10%2F19%2Fshell%E8%84%9A%E6%9C%AC%E8%BF%9B%E9%98%B6%E5%92%8C%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[if语句单分支if 判断条件;then条件为真的分支代码fi双分支if 判断条件; then条件为真的分支代码else条件为假的分支代码fi多分支if 判断条件1; then条件1为真的分支代码elif 判断条件2; then条件2为真的分支代码elif 判断条件3; then条件3为真的分支代码else以上条件都为假的分支代码fi if示例根据命令的退出状态来执行命令12345678if ping -c1 -W2 station1 &amp;&gt; /dev/null; thenecho 'Station1 is UP'elif grep "station1" ~/maintenance.txt &amp;&gt; /dev/null; thenecho 'Station1 is undergoing maintenance‘elseecho 'Station1 is unexpectedly DOWN!'exit 1fi case语句1234567891011121314151617case 变量引用 inPAT1)分支1;;PAT2)分支2;;...*)默认分支;;esaccase支持glob风格的通配符：*: 任意长度任意字符?: 任意单个字符[]：指定范围内的任意单个字符a|b: a或b 选菜菜单123456789101112131415161718case $number in1|2|3)cmd1;;4|5|6)cmd1;;...*)cmd6esaccase脚本cat &lt;&lt;EOF1:lamian2:gaifan3:jiaozi4:baoziEOF 123456789101112131415161718192021# 选菜菜单 vim xuancai.shPS3="Please input a number:"select MENU in lamian huimian gaifan jiaozi baozi quit;do case $REPLY in 1|2) echo "The price is 15元" ;; 3|5) echo "The price is 20元" ;; 4) echo "The price is 25元" ;; 6) echo "bye" break ;; *) echo "Input false" esacdone 执行命令bash xuancai.sh 12345678910read -p "Please choose menu num: " menucase $menu in1|2） echo "lamian gaifan 15元 ";;3|4) echo "jiaozi baozi 10元";;*)echo "wrong" 例如：123456789101112read -p "Do you agree(yes or no)? " ansans= 'echo "$ans|tr 'a-z' 'A-Z'" 'case $ans iny|yes)echo yes;;n|no)echo no*)echo wrong;;esac 循环for适用于有列表的循环while适合没有列表的循环，比较通用until与while条件相反 for循环for 变量名 in 列表;do循环体done执行机制：依次将列表中的元素赋值给“变量名”; 每次赋值后即执行一次循环体; 直到列表中的元素耗尽，循环结束for特殊格式双小括号方法，即((…))格式，也可以用于算术运算双小括号方法也可以使bash Shell实现C语言风格的变量操作I=10((I++))for循环的特殊格式：for ((控制变量初始化;条件判断表达式;控制变量的修正表达式))do循环体done控制变量初始化：仅在运行到循环代码段时执行一次控制变量的修正表达式：每轮循环结束会先进行控制变量修正运算，而后再做条件判断123456for ;do for ;do if ;then continue,break(默认1,2为退出，执行外层循环) fi done 1234567891011donelastb 查询其他人登陆失败的信息&amp;&gt; /dev/null #将输出结果扔到垃圾箱，不在屏幕显示防止dos攻击，将攻击的ip地址放到/data/cracker_ip.log中netstat -nat|sed -nr '/^tcp /s/.* ([1-9].*):.*/\1/p'|sort |uniq -c |while read iplist ;do linknum=`echo $iplist|cut -d" " -f1` ip=`echo $iplist|cut -d" " -f2` if [ $linknum -ge 2 ];then echo $ip &gt;&gt; /data/cracker_ip.log fidone 123456789101112131415161718#!/bin/bash# 象棋方块for i in &#123;1..8&#125;;do temp1=$[ $i % 2 ] for j in &#123;1..8&#125;;do temp2=$[ $j % 2 ] if [ $temp1 -eq $temp2 ];then echo -e -n "\033[47m \033[0m" else echo -e -n "\033[41m \033[0m" fi done echo done 实验：输入一个行号，打印一个等腰三角形如图： 1234567891011121314#!/bin/bash#********************************************************************read -p "Please input line: " linefor i in `seq $line`;do let star=$i*2-1 let space=$line-$i for j in `seq $space`;do echo -n " " done for k in `seq $star`;do echo -n "*" done echodone 批量ping一个网络ID中的254个IP地址，并把能够Ping通的地址放到：/tmp/iplist.log例如ping百度的IP：123.125.115.110bash scanip00.sh 输入正确格式的IP地址cat /tmp/iplist.log结果代码1234567891011121314151617#********************************************************************#scanip00.sh # 脚本名&gt; /tmp/iplist.log #每次运行前清空该文件内容read -p "Please input a netid:(eg:192.168.34.0) " netid #输入IPnetid=`echo $netid | sed -nr 's#(.*)\..*#\1#p'`echo netid=$netidfor id in &#123;1..254&#125;;do &#123; if ping -c1 -w1 $netid.$id &amp;&gt;/dev/null ;then echo "$netid.$id" &gt;&gt; /tmp/iplist.log #ping通的放入文件 echo $netid.$id is up else echo $netid.$id is down fi &#125;&amp; #并行执行donewait 计算从1加到100echo {1..100}|tr ‘ ‘ +|bc 管道计算得出5050或者写一个脚本sum.shsum=0for i in {1..100};dolet sum=sum+idoneecho sum=$sumbash sum.sh 得出5050 while循环while CONDITION; do循环体doneCONDITION：循环控制条件；进入循环之前，先做一次判断；每一次循环之后会再次做判断；条件为“true”，则执行一次循环；直到条件测试状态为“false”终止循环因此：CONDTION一般应该有循环控制变量；而此变量的值会在循环体不断地被修正进入条件：CONDITION为true退出条件：CONDITION为false 函数调用(function待整理)123456789101112131415version()&#123; sed -nr 's/.* ([0-9]+)\..*/\1/p' /etc/centos-release&#125;sysinfo()&#123; local name=wang echo sysinfo:$name echo Hostname is `hostname` echo OS version is `version`&#125;ipaddr()&#123; ifconfig $1|sed -nr '2s/.*inet (addr:)?([^ ]+).*/\2/p'&#125;is_digit()&#123; [[ "$1" =~ ^[0-9]+$ ]] &amp;&amp; true || false&#125;]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络配置及route路由]]></title>
    <url>%2F2018%2F10%2F18%2F%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%8F%8Aroute%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[修改主机名hostnamecentos6vim /etc/sysconfig/network 写入HOSTNAME=centos666.localdomainhostname centos666.localdomain最后exit退出或者exec bash刷新下缓存 centos7 设置主机名hostnamectl set-hostname centos777.localdomain最后exit退出或者exec bash刷新下缓存 注：修改完成后最好将hosts里的主机名中添加新修改的主机名vim /etc/hosts在127回环地址后将加上修改的新主机名 ip和ifconfig的使用ifconfig,route,netstatip:object{link,addr,route},ss,tcsysttem-config-network-tui,setupip a 查询网卡ip addr add =ip a a 缩写例子：12345ip a a 1.1.1.1/24 dev eth0 #添加网卡地址ipdown ipup 禁用启用网卡ifconfig eth1 172.18.0.55/24ifconfig eth1:2 172.18.0.60/24网卡别名，复制一个网卡，实现一个物理网卡绑定多个IPip addr del 1.1.1.1/24 dev eth0 #删除网卡地址 netstat命令显示网络连接：1234567891011121314151617181920netstat [--tcp|-t] [--udp|-u] [--raw|-w] [--listening|-l] [--all|-a] [--numeric|-n] [--extend|-e[--extend|-e]] [--program|-p]-t: tcp协议相关-u: udp协议相关-w: raw socket相关-l: 处于监听状态-a: 所有状态-n: 以数字显示IP和端口-e：扩展格式-p: 显示相关进程及PID显示路由表：netstat &#123;--route|-r&#125; [--numeric|-n]-r: 显示内核路由表-n: 数字格式显示接口统计数据：netstat &#123;--interfaces|-I|-i&#125; [iface] [--all|-a] [--extend|-e] [--program|-p][--numeric|-n]netstat -inetstat –I=IFACEifconfig -s eth0 123456789101112131415161718192021222324ssss -nt 查询连接的用户ss [OPTION]... [FILTER] netstat通过遍历proc来获取socket信息，ss使用netlink与内核tcp_diag模块通信获取socket信息。选项：-t: tcp协议相关-u: udp协议相关-w: 裸套接字相关-x：unix sock相关-l: listen状态的连接-a: 所有-n: 数字格式-p: 相关的程序及PID-e: 扩展的信息-m：内存用量-o：计时器信息常见用法ss -l 显示本地打开的所有端口ss -pl 显示每个进程具体打开的socketss -t -a 显示所有tcp socketss -u -a 显示所有的UDP Socektss -o state established '( dport = :ssh or sport = :ssh )' 显示所有已建立的ssh连接ss -o state established '( dport = :http or sport = :http )' 显示所有已建立的HTTP连接ss -s 列出当前socket详细信息 网络配置文件IP、MASK、GW、DNS相关配置文件：/etc/sysconfig/network-scripts/ifcfg-IFACE路由相关的配置文件： /etc/sysconfig/network-scripts/route-IFACE/etc/sysconfig/network-scripts/ifcfg-IFACE：DEVICE：此配置文件应用到的设备HWADDR：对应的设备的MAC地址BOOTPROTO：激活此设备时使用的地址配置协议，常用的dhcp, static,none, bootpNM_CONTROLLED：NM是NetworkManager的简写，此网卡是否接受NM控制；建议CentOS6为“no”ONBOOT：在系统引导时是否激活此设备TYPE：接口类型；常见有的Ethernet, BridgeUUID：设备的惟一标识IPADDR：指明IP地址NETMASK：子网掩码GATEWAY: 默认网关DNS1：第一个DNS服务器指向DNS2：第二个DNS服务器指向USERCTL：普通用户是否可控制此设备PEERDNS：如果BOOTPROTO的值为“dhcp”，是否允许dhcp server分配的dns服务器指向信息直接覆盖至/etc/resolv.conf文件中 route路由12345678910route目标：192.168.1.1 网关：172.16.0.1route add -default gw 192.168.1.1 #添加默认路由route add -host 192.168.1.6 gw 172.16.0.1 dev eth0 #添加主机路由route add -net 192.168.1.6 netmask 255.255.255.0 gw 172.16.0.1 dev eth0 #添加网络路由route add -net 192.168.1.6/24 gw 172.16.0.1 dev eth0 #添加网络路由 route del 删除路由，同addtcpdump -nn icmp 抓包（IP地址）tcpdump -e -nn -s0 抓包（基于MAC地址）quagga 动态路由协议管理包 配置路由/etc/sysconfig/network-scripts/route-IFACE两种风格：(1) TARGET via GW如：10.0.0.0/8 via 172.16.0.1(2) 每三行定义一条路由ADDRESS#=TARGETNETMASK#=maskGATEWAY#=GW nmcli命令地址配置工具：nmcli1234567891011121314151617181920212223nmcli [ OPTIONS ] OBJECT &#123; COMMAND | help &#125;device - show and manage network interfacesnmcli device helpconnection - start, stop, and manage network connectionsnmcli connection help修改IP地址等属性：nmcli connection modify IFACE [+|-]setting.property valuesetting.property:ipv4.addresses ipv4.gatewayipv4.dns1 ipv4.method manual | auto修改配置文件执行生效：systemctl restart networknmcli con reloadnmcli命令生效： nmcli con down eth0 ;nmcli con up eth0显示网络接口属性nmcli dev show eth0创建新连接default，IP自动通过dhcp获取nmcli con add con-name default type Ethernet ifname eth0删除连接nmcli con del default创建新连接static ，指定静态IP，不自动连接nmcti con add con-name static ifname eth0 autoconnect no typeEthernet ipv4.addresses 172.25.X.10/24 ipv4.gateway 172.25.X.254修改连接设置 123456nmcli con mod“static” connection.autoconnect nonmcli con mod “static” ipv4.dns 172.25.X.254nmcli con mod “static” +ipv4.dns 8.8.8.8nmcli con mod “static” -ipv4.dns 8.8.8.8nmcli con mod “static” ipv4.addresses “172.25.X.10/24 172.25.X.254”nmcli con mod “static” +ipv4.addresses 10.10.10.10/16 修改网卡的名称vim /etc/udev/rules.d/70-persistent-net.rules修改保存后要卸载网卡驱动才会生效ethtool -i eth1 查询网卡的驱动modprobe -r e1000 从内存中卸载网卡驱动，实际上硬件上的驱动没变化modprobe e1000 装载网卡驱动reboot重启虚拟机生效以上方法只需要在cengos6上修改，centos7不需要原因：克隆虚拟机后MAC地址会被自动修改，与MAC地址对应的网卡名称也就需要修改了 12345scp -r wang@172.18.0.7:/data/script/ /data/ 复制主机上文件ssh wang@172.18.0.7 连接主机 tar -czvf beifen.tar.gz /data/script/* 将/data/script下的文件打包为beifen.tar.gz sz beifen.tar.gz 将备份文件下载到Windows中，路径为C:\Users\Administrator\Downloadstime bash *.sh 可以看出脚本运行需要多少时间]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计划任务]]></title>
    <url>%2F2018%2F10%2F16%2F%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[计划任务Linux任务计划、周期性任务执行• 未来的某时间点执行一次任务at 指定时间点，执行一次性任务batch 系统自行选择空闲时间去执行此处指定的任务• 周期性运行某任务cron at任务 (按ctrl+D保存)包：atat命令：at [option] TIME常用选项： -V 显示版本信息-t time 时间格式 [[CC]YY]MMDDhhmm[.ss]-l 列出指定队列中等待运行的作业；相当于atq-d 删除指定的作业；相当于atrm-c 查看具体作业任务-f /path/file 指定的文件中读取任务-m 当任务被完成之后，将给用户发送邮件，即使没有标准输出注意：作业执行命令的结果中的标准输出和错误以邮件通知给相关用户at时间格式HH:MM 02:00在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务HH:MM YYYY-MM-DD 02:00 2016-09-20规定在某年某月的某一天的特殊时刻进行该项任务HH:MM[am|pm] [Month] [Date]04pm March 1717:20 tomorrowHH:MM[am|pm] + number [minutes|hours|days|weeks]在某个时间点再加几个时间后才进行该项任务now + 5 min02pm + 3 days 计划任务cron放在/var/spool/cron/下crontab -e 创建计划任务 @reboot Run once after reboot@yearly 0 0 1 1 @annually 0 0 1 1 @monthly 0 0 1 @weekly 0 0 0@daily 0 0 @hourly 0 *示例：每3小时echo和wall命令12340 */3 * * * centos /bin/echo “howdy”; wall “welcome to Magedu!”etc/cron.hourly 下0anacron放着关机后未执行的计划任务，会在开机后一个合适的时间自动运行etc/anacrontab记录了每天每周每月因关机未执行的计划任务自动执行的时间设置,配置文件：/etc/anacrontab，负责执行/etc/ cron.daily /etc/cron.weekly/etc/cron.monthly中系统任务 字段1：如果在这些日子里没有运行这些任务……• 字段2：在重新引导后等待这么多分钟后运行它• 字段3：任务识别器，在日志文件中标识• 字段4：要执行的任务crontab命令： crontab [-u user] [-l | -r | -e] [-i]12345-l 列出所有任务-e 编辑任务-r 移除所有任务-I 同-r一同使用，以交互式模式移除指定任务-u user 仅root可运行，指定用户管理cron任务 控制用户执行计划任务：/etc/cron.{allow,deny} at和crontab一次性作业使用 at重复性作业使用crontabCreate at time crontab -eList at -l crontab -lDetails at -c jobnum crontab -lRemove at -d jobnum crontab -rEdit N/A crontab -e没有被重定向的输出会被邮寄给用户root能够修改其它用户的作业]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三次握手及子网划分]]></title>
    <url>%2F2018%2F10%2F16%2F%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%8F%8A%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[三次握手及四次挥手三次握手 （最好能画出图） （一般抓包软件wireshark默认客户端和服务器第一次建立连接，x,y取绝对，为0） 客户端发送SYN=1,seq=x 到服务器（LISTEN状态） 服务器收到后 回发SYN=1,ACK=1,seq,=y,ack=x+1 给客户端，说明收到（同步收到状态） 客户端（同步已发送状态）收到反馈后， 发送ACK=1,seq=x+1,ack=y+1 给服务器，双方建立连接（都为ESTAB-LISHED状态） 四次挥手 (最好能画出图) 客户端(FIN-WAIT-1终止等待1)发送FIN=1,seq=u 服务器收到后回复 ACK=1,seq=v,ack=u+1给客户端（FIN-WAIT-1终止等待2） 等待一会服务器(CLOSE_WAIT关闭等待)发送FIN=1,ack=1,seq=w,ack=u+1给客户端（TIME-WAIT时间等待） 客户端收到后回复ACK=1,seq=u+1,ack=w+1给服务器（LAST-ACK最后确认）最后客户端和服务器断开连接注：抓包软件wireshark中数据最后几行为分开信息分别为:[FIN,ACK][ACK][FIN,ACK][ACK]ss -nt |sed -rn ‘1!s/^([^ ]+).*/\1/p’ |sort 抓取网络连接中有多少状态 服务器和各个协议端口号： FTP:21ssh：22Telnet:20HTTP tcp:80HTTPS tcp：443 和HTTP不是一种协议DNS:53TFTP:69SNMPP:161QQ :udp 8000dhcp 67,68 snmp 161mysql tcp 3306oracle tcp 1521sql server 1433kerberos 88/tcpsmtp 25pop3 110imap 143smb 445 10.00000 000.0.0 10.0.0.0/1610.00001 000.0.0 10.8.0.0/1610.00011 000.0.0 10.24.0.0/1610.00111 000.0.0 10. 10.152.0000 0000 10.152.0.010.152.0000 0000 arp协议IP 逻辑地址，可以查询此IP在网络的哪个位置MAC地址 物理地址1-126.x.y.z A类地址，全球共126个A类网段 以太网 数据链路层以太网帧的数据报文 （和IP的不一样）长度 72-1526 去掉前导信息（8）和FCS（4），有用的数据长度为60-1514MAC地址唯一，前三位标识各个厂商后三位厂商自定义，如34-E1-2D-D0-72-DA，共6个字节，一个字母或数字4位tcpdump -i eth0 -nn -X 抓包工具练习两主机连接前互相询问MAC地址arp -n查看获取的MAC地址 协议类型查询：cat /etc/protocolsTCP 6UDP 17 IP地址类型分类 A类地址1-126.X.Y.Z1600万网络ID位为高8位，主机ID位为240xxxxxxx.X.Y.Z00000000 001111111 127 10.0.0.10010.0.0.010.255.255.255 114.114.114.114 B类地址128-191.x.y.z网络ID位为高16位，主机ID位为1610xxxxxx.X.Y.Z 128 19165534 172.18.0.100 C类地址192-223.x.y.z网络ID位为高24位，主机ID位为8110xxxxx.x.y.z11000000 19211011111 223254 D类地址224-239.x.y.z多播地址1110xxxx.x.y.z E类地址11110xxx.240-254.x.y.z 无类域间路由CIDR:网络id位数不确定,22netmask子网掩码:32bit 二进制,对应于网络ID位为1，对应于主机ID位为0 子网划分10.0.0.100/19 255.255.224.0 203.110.200.199/22 22为网络ID数，主机ID数=32-网络ID数1 主机数?10222 netmask?255.255.252.03 网络ID值? 203.110.200.199 203.110.110010 00.199255.255.111111 00.00000000203.110.110010 00.0/22203.110.200.0/22 192.168.34.6255.255.255.0192.168.34.0/24 0与1=00与0=01与0=01与1=1 A 192.168.1.100 255.255.255.0 B 192.168.2.100 255.255.0.0 A ：172.18.0.100 255.0.0.0 172.18.0.0/16B： 172.18.0.123 255.255.255.0 172.18.0.0/24 例子：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061100.123.199.124/201 主机数 2^12-22 子网掩码 255.255.240.0 3 网络ID:100.123.192.0/204 最小和最大IP:100.123.192.1 --- 100.123.207.254100.123.11000111.124255.255.240.0 100.123.1100 0000.1 100.123.1100 1111.254 123.200.233.100/23 123.200.235.100/23 100.123.1100 0000.000000001100.123.1100 1111.11111111000000000 010000000 12811000000 19211100000 22411110000 24011111000 24811111100 25211111110 25411111111 25500000001 100000010 200000100 400001000 800010000 1600100000 3201000000 6410000000 12810.0.0.1--10.255.255.254 10.00 000000.0.010.00 000000.0.0 10.0.0.0/1010.01 000000.0.0 10.64.0.0/1010.10 000000.0.0 10.128.0.0/1010.11 000000.0.0 10.192.0.0/1010.0 0000000.0.0 10.0.0.0/9 10.1 0000000.0.0 10.128.0.0/910.0.0.0/8 给32省份划分各自子网借5位1 子网子网掩码 255.248.0.0 2 最小子网，最大子网的网络ID10.00000 000.0.0 10.0.0.0/1310.11111 000.0.0 10.248.0.0/133 每个子网主机数？2^19-24 第20个子网分给河南使用，最小IP10.152.0.1，最大IP范围10.159.255.25410.10011 000.0.1 10.10011 111.255.254 子网掩码和网关在一个网段才能上网，/后的数字为网络id位数，从前往后查多少位不变的公式： 一个网络中主机最大数=2^主机ID位数(32-网络ID位数)^-2=2^(32-网络ID位数)^-2 网络数=2^可变网络ID位 CIDR表示法：IP/网络ID位数 网络ID值=IP与子网掩码 划分子网：一个大网划分成多个小网，网络ID位变多，主机ID位才变少，网络ID向主机ID借位N,分成2^N个小网 合并超网：多个小网合并成一个大网，主机ID向网络ID借位 例子 ： 河南省10.152.0.0/13 给15个地市，划分各自子网 2^N^&gt;=15 N=41 子网子网掩码 17 255.255.128.0 2 最小子网，最大子网的网络ID 10.10011 000.0 0000000.0 10.152.0.0/1710.10011 111.1 0000000.0 10.159.128.0/17 3 每个子网主机数？ 2^(32-17)^-2 4 最大子网的最小IP，最大IP范围 10.159.128.1——10.159.255.254 10.10011 111.1 0000000.010.10011 111.1 0000000.1 10.159.128.110.10011 111.1 1111111.254 10.159.255.254 河南省10.152.0.0/13 给87个区县，划分各自子网1 子网子网掩码 21 255.255.248.0 2 最小子网，最大子网的网络ID 10.10011 000.00000 000.0 10.152.0.0/2110.10011 111.11111 000.0 10.159.248.0/21 3 每个子网主机数？ 2^11-2 4 最大子网 的最小IP，最大IP范围 10.10011 111.11111 000.0 10.159.248.110.10011 111.11111 111.254 10.159.255.254 路由表：目标网络ID：目标IP所在网络ID接口：本设备要发送数据包到目标，从哪个接口发送出来，才能到达网关：到达目标网络，需要将数据交给下一个路口哪个接口的对应的IP]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程管理]]></title>
    <url>%2F2018%2F10%2F15%2FLinux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[ps常见选项ps12345678910111213C cmdlist 指定命令，多个命令用，分隔L 显示线程e: 显示所有进程，相当于-Af: 显示完整格式程序信息F: 显示更完整格式的进程信息H: 以进程层级格式显示进程相关信息u userlist 指定有效的用户ID或名称U userlist 指定真正的用户ID或名称g gid或groupname 指定有效的gid或组名称G gid或groupname 指定真正的gid或组名称p pid 显示指pid的进程-ppid pid 显示属于pid的子进程M 显示SELinux信息，相当于Z ps输出属性1234567891011121314VSZ: Virtual memory SiZe，虚拟内存集，线性内存RSS: ReSident Size, 常驻内存集STAT：进程状态R：runningS: interruptable sleepingD: uninterruptable sleepingT: stoppedZ: zombie+: 前台进程l: 多线程进程L：内存分页并带锁N：低优先级进程&lt;: 高优先级进程s: session leader，会话（子进程）发起者 ps示例 询你拥有的所有进程ps -x示指定用户名(RUID)或用户ID的进程ps -fU apacheps -fU 48示指定用户名(EUID)或用户ID的进程ps -fu wangps -fu 1000看以root用户权限（实际和有效ID）运行的每个进程ps -U root -u root出某个组拥有的所有进程（实际组ID：RGID或名称）ps -fG nginx列出有效组名称（或会话）所拥有的所有进程ps -fg mysqlps -fg 27示指定的进程ID对应的进程ps -fp 1234父进程ID来显示其下所有的进程，如显示父进程为1234的所有进程ps -f –ppid 1234示指定PID的多个进程ps -fp 1204,1239,1263按tty显示所属进程ps -ft pts/0自定义格式显示文件系统组,ni值开始时间和进程的时间ps -p 1234 -o pid,ppid,fgroup,ni,lstart,etime用其PID查找进程名称：ps -p 1244 -o comm=以其名称选择特定进程，显示其所有子进程ps -C sshd,bash找指定进程名所有的所属PID，在编写需要从std输出或文件读取PID的脚本时这个参数很有用ps -C httpd,sshd -o pid=查一个进程的执行时间ps -eo comm,etime,user | grep nginx 搜索进程灵活：ps 选项 | 其它命令预定义的模式：pgrep123456789pgrep [options] pattern-u uid: effective user，生效者-U uid: real user，真正发起运行命令者-t terminal: 与指定终端相关的进程-l: 显示进程名-a: 显示完整格式的进程名-P pid: 显示指定进程的子进程确切的程序名称：/sbin/pidofpidof bash 进程管理工具toptop：有许多内置命令排序：P：以占据的CPU百分比,%CPUM：占据内存百分比,%MEMT：累积占据CPU时长,TIME+首部信息显示：uptime信息：l命令tasks及cpu信息：t命令cpu分别显示：1 (数字)memory信息：m命令退出命令：q修改刷新时间间隔：s终止指定进程：k保存文件：Wtop选项：-d # 指定刷新时间间隔，默认为3秒-b 全部显示所有进程-n # 刷新多少次后退出-H 线程模式，示例：top -H -p pidof mysqld htop命令：EPEL源选项：-d #: 指定延迟时间；-u UserName: 仅显示指定用户的进程-s COLUME: 以指定字段进行排序子命令：s：跟踪选定进程的系统调用l：显示选定进程打开的文件列表a：将选定的进程绑定至某指定CPU核心t：显示进程树 内存空间存空间使用状态： free [OPTION]-b 以字节为单位-m 以MB为单位-g 以GB为单位-h 易读格式-o 不显示-/+buffers/cache行-t 显示RAM + swap的总和-s n 刷新间隔为n秒-c n 刷新n次后即退出 内存工具vmstat命令：虚拟内存信息vmstat [options] [delay [count]]vmstat 2 5procs:r：可运行（正运行或等待运行）进程的个数，和核心数有关b：处于不可中断睡眠态的进程个数(被阻塞的队列的长度)memory： swpd: 交换内存的使用总量free：空闲物理内存总量buffer：用于buffer的内存总量cache：用于cache的内存总量swap:si：从磁盘交换进内存的数据速率(kb/s)so：从内存交换至磁盘的数据速率(kb/s) 系统监控工具1234567891011121314151617181920212223glances命令：EPEL源glances [-bdehmnrsvyz1] [-B bind] [-c server] [-C conffile] [-p port] [-P password] [–password] [-t refresh] [-f file] [-o output]内建命令：a Sort processes automatically l Show/hide logsc Sort processes by CPU% b Bytes or bits for network I/Om Sort processes by MEM% w Delete warning logsp Sort processes by name x Delete warning and critical logsi Sort processes by I/O rate 1 Global CPU or per-CPU statsd Show/hide disk I/O stats h Show/hide this help screenf Show/hide file system stats t View network I/O as combinationn Show/hide network stats u View cumulative network I/Os Show/hide sensors stats q Quit (Esc and Ctrl-C also work)y Show/hide hddtemp stats常用选项：-b: 以Byte为单位显示网卡数据速率-d: 关闭磁盘I/O模块-f /path/to/somefile: 设定输入文件位置-o &#123;HTML|CSV&#125;：输出格式-m: 禁用mount模块-n: 禁用网络模块-t #: 延迟时间间隔-1：每个CPU的相关数据单独显示 例子：glances 远程监控远程监控另一台虚拟机需要两台虚拟机同为centos6或者centos7版本，否则不兼容虚拟机A作为服务器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849yum install glances #安装glances 工具glances -s #开启服务虚拟机B作为客户端yum install glances #安装glances 工具glances -c 192.168.34.129 #输入服务器IP地址在虚拟机B上可以看到以下信息Connected to centos7.localdomain (CentOS Linux 7.5.1804 64bit / Linux 3.10.0-862.el7.x86_64) Uptime: 0:07:49CPU [ 4.4%] CPU 4.4% nice: 0.0% MEM 41.7% SWAP 0.0% LOAD 1-coreMEM [ 41.7%] user: 1.3% irq: 0.0% total: 1.78G total: 4.00G 1 min: 0.01SWAP [ 0.0%] system: 2.5% iowait: 0.0% used: 760M used: 0 5 min: 0.15 idle: 96.2% steal: 0.0% free: 1.04G free: 4.00G 15 min: 0.12NETWORK Rx/s Tx/s TASKS 200 (467 thr), 2 run, 198 slp, 0 oth sorted automaticallyens33 3Kb 62Kbens37 1Kb 648b CPU% MEM% VIRT RES PID USER NI S TIME+ IOR/s IOW/s Command lo 0b 0b 9.8 0.8 221M 15.1M 2858 root 0 R 0:00.33 0 0 /usr/bin/python /virbr0 0b 0b 0.0 0.5 548M 9.50M 2430 luhao 19 S 0:00.40 0 0 /usr/libexec/trac_rbr0-nic 0b 0b 0.0 0.3 105M 5.34M 686 root 0 S 0:00.20 0 0 /sbin/dhclient -d 0.0 3.2 1.15G 57.9M 2488 luhao 0 S 0:00.24 0 0 /usr/libexec/evolDISK I/O R/s W/s 0.0 0.0 0 0 438 root -20 S 0:00.00 0 0 xfs-buf/sda1sda1 0 0 0.0 0.0 60.7M 400K 598 avahi 0 S 0:00.00 0 0 avahi-daemon: chrsda2 0 0 0.0 0.0 0 0 448 root -20 S 0:00.00 0 0 xfs-conv/sda3sda3 0 0 0.0 0.3 367M 5.46M 2117 luhao 0 S 0:00.00 0 0 /usr/libexec/ibussda4 0 0 0.0 0.3 410M 6.06M 1752 colord 0 S 0:00.30 0 0 /usr/libexec/colosda5 0 0 0.0 0.4 603M 7.12M 2309 luhao 0 S 0:00.20 0 0 /usr/libexec/gsd-sr0 0 0 0.0 0.2 363M 3.05M 2168 luhao 0 S 0:00.00 0 0 /usr/libexec/gvfs 0.0 0.3 550M 5.48M 2156 luhao 0 S 0:00.20 0 0 /usr/libexec/gvfsFILE SYS Used Total 0.0 0.0 0 0 5 root -20 S 0:00.00 0 0 kworker/0:0H/ (sda2) 3.86G 50.0G 0.0 0.0 0 0 10 root -20 S 0:00.00 0 0 lru-add-drain/boot 165M 1014M 0.0 0.7 677M 13.6M 953 root 0 S 0:00.37 0 0 /usr/sbin/libvirt/data 32.2M 30.0G 0.0 0.2 193M 4.09M 944 root 0 S 0:00.10 0 0 /usr/sbin/cupsd -_7 x86_64 8.75G 8.75G 0.0 0.0 52.6M 372K 1401 root 0 S 0:00.00 0 0 /usr/sbin/dnsmasq 0.0 0.0 0 0 29 root 19 S 0:00.36 0 0 khugepaged 0.0 0.8 708M 13.9M 2254 luhao 0 S 0:00.11 0 0 /usr/libexec/gsd- 0.0 0.0 0 0 41 root -20 S 0:00.00 0 0 kaluad 0.0 0.0 0 0 531 root -20 S 0:00.00 0 0 rpciod 0.0 0.0 0 0 532 root -20 S 0:00.00 0 0 xprtiod 0.0 0.4 1.23G 6.91M 2097 luhao -11 S 0:00.12 0 0 /usr/bin/pulseaud 0.0 0.0 0 0 225 root -20 S 0:00.00 0 0 ata_sff 0.0 0.1 23.9M 2.21M 555 root 0 S 0:00.20 0 0 /usr/sbin/smartd 0.0 0.2 454M 4.44M 2381 luhao 0 S 0:00.30 0 0 /usr/libexec/gvfs 0.0 0.5 625M 10.0M 2416 luhao 19 S 0:00.50 0 0 /usr/libexec/trac 0.0 0.4 597M 6.50M 2284 luhao 0 S 0:00.20 0 0 /usr/libexec/gsd- 0.0 0.0 0 0 444 root -20 S 0:00.00 0 0 xfs-conv/sda1 0.0 0.3 367M 5.25M 2124 luhao 0 S 0:00.10 0 0 /usr/libexec/ibus 系统监控工具dstat命令：系统资源统计,代替vmstat,iostat1234567891011dstat [-afv] [options..] [delay [count]]-c 显示cpu相关信息-C #,#,...,total-d 显示disk相关信息-D total,sda,sdb,...-g 显示page相关统计数据-m 显示memory相关统计数据-n 显示network相关统计数据-p 显示process相关统计数据-r 显示io请求相关的统计数据-s 显示swapped相关的统计数据 iotop常用参数o, –only只显示正在产生I/O的进程或线程，除了传参，可以在运行过程中按o生效b, –batch非交互模式，一般用来记录日志n NUM, –iter=NUM设置监测的次数，默认无限。在非交互模式下很有用d SEC, –delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1p PID, –pid=PID指定监测的进程/线程u USER, –user=USER指定监测某个用户产生的I/OP, –processes仅显示进程，默认iotop显示所有线程a, –accumulated显示累积的I/O，而不是带宽k, –kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用-t, –time 加上时间戳，非交互非模式q, –quiet 禁止头几行，非交互模式，有三种指定方式-q 只在第一次监测时显示列名-qq 永远不显示列名-qqq 永远不显示I/O汇总交互按键left和right方向键：改变排序r：反向排序o：切换至选项–onlyp：切换至–processes选项a：切换至–accumulated选项q：退出i：改变线程的优先级 lsoflsof：list open files查看当前系统文件的工具。在linux环境下，一切皆文件，用户通过文件不仅可以访问常规数据，还可以访问网络连接和硬件如传输控制协议 (TCP) 和用户数据报协议 (UDP)套接字等，系统在后台都为该应用程序分配了一个文件描述符命令参数1234567891011121314151617181920212223242526lsof-a：列出打开文件存在的进程-c&lt;进程名&gt;：列出指定进程所打开的文件-g：列出GID号进程详情-d&lt;文件号&gt;：列出占用该文件号的进程+d&lt;目录&gt;：列出目录下被打开的文件+D&lt;目录&gt;：递归列出目录下被打开的文件-n&lt;目录&gt;：列出使用NFS的文件-i&lt;条件&gt;：列出符合条件的进程(4、6、协议、:端口、 @ip )-p&lt;进程号&gt;：列出指定进程号所打开的文件-u：列出UID号进程详情-h：显示帮助信息-v：显示版本信息。-n: 不反向解析网络名字lsof /dev/pts/0 #查看由系统启动的进程 0改为1是看用户的进程指定进程号，可以查看该进程打开的文件lsof -p 9527文件管理查看指定程序打开的文件lsof -c httpd查看指定用户打开的文件lsof -u root | more查看指定目录下被打开的文件lsof +D /var/log/lsof +d /var/log/参数+D为递归列出目录下被打开的文件，参数+d为列出目录下被打开的文件 例子：123456789101112131415161718[root@centos6 ~]#lsof /dev/pts/0COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbash 27075 root 0u CHR 136,0 0t0 3 /dev/pts/0bash 27075 root 1u CHR 136,0 0t0 3 /dev/pts/0bash 27075 root 2u CHR 136,0 0t0 3 /dev/pts/0bash 27075 root 255u CHR 136,0 0t0 3 /dev/pts/0lsof 37913 root 0u CHR 136,0 0t0 3 /dev/pts/0lsof 37913 root 1u CHR 136,0 0t0 3 /dev/pts/0lsof 37913 root 2u CHR 136,0 0t0 3 /dev/pts/0lsof -i :22 #查询22端口被哪个进程占用例子：lsof -i :22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 1932 root 3u IPv4 12343 0t0 TCP *:ssh (LISTEN)sshd 1932 root 4u IPv6 12345 0t0 TCP *:ssh (LISTEN)sshd 27073 root 3r IPv4 39440 0t0 TCP 192.168.34.128:ssh-&gt;192.168.34.1:54867 (ESTABLISHED) 进程管理工具killkill命令：向进程发送控制信号，以实现对进程管理,每个信号对应一个数字，信号名称以SIG开头（可省略），不区分大小写显示当前系统可用信号： kill –l 或者 trap -l常用信号：man 7 signal SIGHUP 无须关闭进程而让其重读配置文件SIGINT 中止正在运行的进程；相当于Ctrl+cSIGQUIT 相当于ctrl+\SIGKILL 强制杀死正在运行的进程SIGTERM 终止正在运行的进程SIGCONT 继续运行SIGSTOP 后台休眠指定信号的方法 : (1) 信号的数字标识：1, 2, 9(2) 信号完整名称：SIGHUP(3) 信号的简写名称：HUPpidof bc 查看计算器的进程号kill ‘pidof bc’ 停止进程按PID： kill [-SIGNAL] pid …kill –n SIGNAL pidkill –s SIGNAL pid按名称：killall [-SIGNAL] comm…按模式：pkill [options] pattern -SIGNAL-u uid: effective user，生效者-U uid: real user，真正发起运行命令者-t terminal: 与指定终端相关的进程-l: 显示进程名（pgrep可用）-a: 显示完整格式的进程名（pgrep可用）-P pid: 显示指定进程的子进程 并行执行同时运行多个进程，提高效率方法1vi all.sh1234567f1.sh&amp;f2.sh&amp;f3.sh&amp;方法2(f1.sh&amp;);(f2.sh&amp;);(f3.sh&amp;)方法3&#123; f1.sh&amp; f2.sh&amp; f3.sh&amp; &#125; 例子： 同时ping四个地址123456789&#123;ping -c2 127.0.0.1ping 127.0.0.2&#125;&amp;&#123;ping -c2 127.0.0.3ping 127.0.0.4&#125;&amp; 例子：并行ping172.18.133网段的254个IP，并输出结果]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘备份及raid0和raid10的组建]]></title>
    <url>%2F2018%2F10%2F15%2F%E7%A3%81%E7%9B%98%E5%A4%87%E4%BB%BD%E5%8F%8Araid0%E5%92%8Craid10%E7%9A%84%E7%BB%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[blkid 查询各个设备UUID1234567891011121314mount -U 'UUID' 加挂载点 挂载设备umount /mnt/sdb1 卸载挂载设备sdb1（无占用） lsof /mnt/sdb1 有用户占用时，查询sdb1占用进程和用户fuser -km /mnt/sdb1 结束sdb1的所有占用cat /proc/mounts 查询所有的挂载点umount -o remount +挂载点 重新挂载，某些设备不能取消挂载df -P 对其系统信息显示du 显示当前目录每个文件夹的大小du -sh 显示当前目录的总大小du -sh /*查询根目录下每个目录有多大dd 命令**********************dd if= /dev读取的文件 of=/输出的文件，没有则新建该文件 例子1234567891011121314151617f1=abcdefghif2= 123456dd if=f2 of=f1 bs=1 count=2 skip=3 seek=4 一次1块，跳过源文件的3个（123），读取两个（45），f1跳过4个，把ef替代了输出信息为abcd45 备份：dd if=/dev/sdx of=/dev/sdy将本地的/dev/sdx整盘备份到/dev/sdydd if=/dev/sdx of=/path/to/image将/dev/sdx全盘数据备份到指定路径的image文件dd if=/dev/sdx | gzip &gt;/path/to/image.gz备份/dev/sdx全盘数据，并利用gzip压缩，保存到指定路径恢复：dd if=/path/to/image of=/dev/sdx将备份文件恢复到指定盘gzip -dc /path/to/image.gz | dd of=/dev/sdx将压缩的备份文件恢复到指定盘 拷贝内存资料到硬盘123456789dd if=/dev/mem of=/root/mem.bin bs=1024将内存里的数据拷贝到root目录下的mem.bin文件从光盘拷贝iso镜像dd if=/dev/cdrom of=/root/cd.iso拷贝光盘数据到root文件夹下，并保存为cd.iso文件销毁磁盘数据dd if=/dev/urandom of=/dev/sda1利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据，执行此操作以后，/dev/sda1将无法挂载，创建和拷贝操作无法执行 测试硬盘写速度12345dd if=/dev/zero of=/root/1Gb.file bs=1024 count=1000000测试硬盘读速度dd if=/root/1Gb.file bs=64k | dd of=/dev/nullpartx -d --nr 1 /dev/sdb 删除硬盘sdb上的第一个分区删除硬盘上的一个分区 raid 01 容错率3分之1raid 10 容错率3分之2所以一般都用raid 10 或者20.30 简述 raid0，raid1，raid5，raid10 的区别和各自特点： raid0:RAID0 具有低成本、高读写性能、 100% 的高存储空间利用率等优点，但是它不提供数据冗余保护，一旦数据损坏，将无法恢复。 因此， RAID0 一般适用于对性能要求严格但对数据安全性和可靠性不高的应用。raid1:RAID1 称为镜像，它将数据完全一致地分别写到工作磁盘和镜像磁盘，从而达到安全性好、技术简单、管理方便。 RAID1 拥有完全容错的能力，但实现成本高。raid5:RAID5 的磁盘上同时存储数据和校验数据，数据块和对应的校验信息存保存在不同的磁盘上，当一个数据盘损坏时，系统可以根据同一条带的其他数据块和对应的校验数据来重建损坏的数据。与其他 RAID等级一样，重建数据时， RAID5 的性能会受到较大的影响。RAID5 兼顾存储性能、数据安全和存储成本等各方面因素，它可以理解为 RAID0 和 RAID1 的折中方案，是目前综合性能最佳的数据保护解决方案。raid10：RAID10 是先做镜像再作条带化，是对虚拟磁盘实现镜像，保证数据安全性的同时又提高了性能，整体磁盘利用率均仅为 50%。 raid5在视频第12天第三个视频64分钟开始 实验：实现raid0VMware中添加两块200G硬盘，重启虚拟机输入lsblk查看多了一个sdb 硬盘fdisk /dev/sdb12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x25e5fb5c.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won't be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u').Command (m for help): nCommand action e extended p primary partition (1-4)1Invalid partition number for type `1'Command action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-26108, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-26108, default 26108): +50GCommand (m for help): tSelected partition 1Hex code (type L to list codes): fdChanged system type of partition 1 to fd (Linux raid autodetect)Command (m for help): pDisk /dev/sdc: 214.7 GB, 214748364800 bytes255 heads, 63 sectors/track, 26108 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x25e5fb5c Device Boot Start End Blocks Id System/dev/sdc1 1 6528 52436128+ fd Linux raid autodetectCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.然后按w保存分区信息************************** 分区完成若lsblk后没有新建的分区，可以输入partx -a /dev/sdb 来通知内核重新读取分区表或者输入partprobe 进行分区同步 重复以上步骤将sdc也创建一个50G的分区12345678910111213141516171819202122232425262728293031323334353637lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 200G 0 disk ├─sda1 8:1 0 1G 0 part /boot├─sda2 8:2 0 48.8G 0 part /├─sda3 8:3 0 29.3G 0 part /data├─sda4 8:4 0 1K 0 part └─sda5 8:5 0 2G 0 part [SWAP]sdb 8:16 0 200G 0 disk └─sdb1 8:17 0 50G 0 part sdc 8:32 0 200G 0 disk └─sdc1 8:33 0 50G 0 part sr0 11:0 1 3.7G 0 rom 可以看到sdb1和sdc1两个50G的分区将两个分区组成raid0mdadm -C -a yes /dev/md0 -l 0 -n 2 /dev/sd&#123;b,c&#125;1lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 200G 0 disk ├─sda1 8:1 0 1G 0 part /boot├─sda2 8:2 0 48.8G 0 part /├─sda3 8:3 0 29.3G 0 part /data├─sda4 8:4 0 1K 0 part └─sda5 8:5 0 2G 0 part [SWAP]sdb 8:16 0 200G 0 disk └─sdb1 8:17 0 10G 0 part └─md0 9:0 0 20G 0 raid0 /mnt/raidsdc 8:32 0 200G 0 disk └─sdc1 8:33 0 10G 0 part └─md0 9:0 0 20G 0 raid0 /mnt/raidsr0 11:0 1 3.7G 0 rom mkfs.ext4 /dev/md0 给raid0创建文件系统blkidmkdir /mnt/raid 创建挂载点tune2fs -L /mnt/raid /dev/md0 挂载md0 输入partprobe 进行分区同步df -h 可以看到raid0组建完成 测试组建raid前后速度1234567891011121314dd if=/dev/zero of=/mnt/raid/f1 bs=1M count=1024 raid0速度1024+0 records in1024+0 records out1073741824 bytes (1.1 GB) copied, 4.94718 s, 217 MB/sdd if=/dev/zero of=/data/f2 bs=1M count=1024 普通硬盘速度1024+0 records in1024+0 records out1073741824 bytes (1.1 GB) copied, 23.4932 s, 45.7 MB/s********************************************************************8raid0和raid1组建区别mdadm -C -a yes /dev/md0 -l 0 -n 2 /dev/sd&#123;b,c&#125;1 raid0mdadm -C -a yes /dev/md0 -l 1 -n 2 /dev/sd&#123;b,c&#125;1 raid1将-l 后的类别改为1就是raid1 RAID10组建组建raid10就是先组建两个raid0，组合成raid1再次添加两个硬盘sdd,sde重启系统，或者刷新硬件信息12345678910111213mdadm -C -a yes /dev/md0 -l 0 -n 2 /dev/sd&#123;d,e&#125;1umount /dev/md0 取消挂载md0mdadm -C -a yes /dev/md2 -l 1 -n 2 /dev/md&#123;0,1&#125; 将两个raid0组建为raid10lsblk 查看是否有md2df -h看到没有md2mkfs.ext4 /dev/md2 创建文件系统mkdir /mnt/raid111 创建挂载点mount /dev/md2 /mnt/raid111 挂载raid10vim /etc/fstab 写入raid10 信息,重启后raid10不会丢失partprobe 同布信息df -h 可以看到有了md2mdadm -D /dev/md0 删除raid0]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑卷LVM的管理]]></title>
    <url>%2F2018%2F10%2F11%2F%E9%80%BB%E8%BE%91%E5%8D%B7LVM%E7%9A%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[1实验：扩展VG1234pvcreate /dev/sdc 将新加的硬盘创建为物理卷pvs 查询物理卷vgextend vg0 /dev/sdc 扩展vg0，将sdc加进去lvextend 通用扩展命令，6，7都可以用 2实验：缩减 *LVM123456789101 umount /mnt/mysql 卸载逻辑卷2 fsck -f /dev/vg0/lv_mysql 检查系统的完整性3 resize2fs /dev/vg0/lv_mysql 20G 缩减到20G4 lvreduce -L 20 /dev/vg0/lv_mysql 缩减逻辑卷到20G5 mount /dev/vg0/lv_mysql /mnt/mysql 挂载逻辑卷 实验：扩展*LVM12345678910111 vgdisplay 查看VG有空闲空间2 lvextend -l +100%FREE /dev/vg0/lv_mysql3 resize2fs /dev/vg0/lv_mysql2，3合并成lvextendlvextend -r -L 5G /dev/vg0/lv_data 4 df 实验：创建LVM12345678910111213fdisk t 8e /dev/sda6 /dev/sdc 创建分区并t修改格式为8e pvcreate /dev/sda6 /dev/sdc 创建物理卷vgcreate vg0 /dev/sda6 /dev/sdc 添加两个物理卷到卷组vg0lvcreate -n lv_mysql -L 15G vg0 从卷组中分出15G创建逻辑卷mkfs.ext4 /dev/vg0/lv_mysql 创建文件系统mkdir /mnt/mysql 创建挂载点mount /dev/vg0/lv_mysql /mnt/mysql 挂载逻辑卷 实验：迁移逻辑卷LVM中的PE1234pvmove /dev/sda6 将逻辑卷中的被占用PE迁移到其他逻辑卷vgreduce vg0/dev/sda6 将逻辑卷从卷组vg0中删除fdisk /dev/sda6 删除分区sda6vgrename vg0 vg1 将卷组改名为vg1 实验：ext LV的快照,并恢复12345lvcreate -n lv_data_snap -p r -s -L 1G /dev/vg0/lv_datamount -o /dev/vg0/lv_data_snap /mnt/snap/umount /mnt/dataumount /mnt/snap/lvconvert --merge /dev/vg0/lv_data_snap]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：增加一块新硬盘，分区，创建文件系统XFS|EXT4，并挂载]]></title>
    <url>%2F2018%2F10%2F09%2F%E5%AE%9E%E9%AA%8C%EF%BC%9A%E5%A2%9E%E5%8A%A0%E4%B8%80%E5%9D%97%E6%96%B0%E7%A1%AC%E7%9B%98%EF%BC%8C%E5%88%86%E5%8C%BA%EF%BC%8C%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FXFS%2CEXT4%EF%BC%8C%E5%B9%B6%E6%8C%82%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[实验：增加一块新硬盘，分区，创建文件系统XFS|EXT4，并挂载 VMware中添加一块200G硬盘，重启虚拟机输入lsblk查看多了一个sdb 硬盘12345678910111213141516171819202122232425262728293031323334353637383940414243444546fdisk /dev/sdbCommand (m for help): mCommand action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition 删除一个分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition 创建一个分区 o create a new empty DOS partition table p print the partition table 查看分区信息 q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit 保存写入分区操作信息，不按w分区不保存 x extra functionality (experts only)按m进入交互式操作按n新建一个分区，如下Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) 主分区 e extended 扩展分区Select (default p): pPartition number (1-4, default 1): 1 分区编号First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): +50G 分区大小 Partition 1 of type Linux and of size 1 GiB is setCommand (m for help): p 显示分区信息Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x1cc76008 Device Boot Start End Blocks Id System/dev/sdb1 2048 2099199 1048576 83 Linux然后按w保存分区信息************************** 分区完成若lsblk后没有新建的分区，可以输入partx -a /dev/sdb 来通知内核重新读取分区表 或者输入partprobe 进行分区同步]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：迁移/home目录到新分区中]]></title>
    <url>%2F2018%2F10%2F07%2F%E5%AE%9E%E9%AA%8C%EF%BC%9A%E8%BF%81%E7%A7%BBhome%E7%9B%AE%E5%BD%95%E5%88%B0%E6%96%B0%E5%88%86%E5%8C%BA%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[实验：迁移/home目录到新分区中12345678910111213141516#先添加一块新的硬盘，重启虚拟机lsblk看到新硬盘为sdcfdisk /dev/sdc 新建一个分区sdc1blkidmkfs.xfs /dev/sdc1 创建文件系统mkdir /mnt/home 创建新的挂载点mount /dev/sdc1 /mnt/home 将光盘进行挂载cp -av /home/. /mnt/home 将原来home下的所有文件复制到/mnt/home下ll mnt/homedu -sh /mnt/homedu -sh /home 比较两文件夹的大小，看复制是否完整vim /etc/fstab 命令模式下写入:r!blkid /dev/sdc1 修改后按wq保存退出mount -a 使挂载生效df -h 查看占用umount /home 取消挂载rm -rf /home/* 删除home中的文件]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘及文件系统分区]]></title>
    <url>%2F2018%2F10%2F06%2F%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[磁盘储存设备类型：块设备：block，存取单位“块”，磁盘字符设备：char，存取单位“字符”，键盘 机械硬盘和固态硬盘机械硬盘（HDD）：&emsp;Hard Disk Drive，即是传统普通硬盘，主要由：盘片，磁头，盘片转轴及控制电机，磁头控制器，数据转换器，接口，缓存等几个部分组成。机械硬盘中所有的盘片都装在一个旋转轴上，每张盘片之间是平行的，在每个盘片的存储面上有一个磁头，磁头与盘片之间的距离比头发丝的直径还小，所有的磁头联在一个磁头控制器上，由磁头控制器负责各个磁头的运动。磁头可沿盘片的半径方向运动，加上盘片每分钟几千转的高速旋转，磁头就可以定位在盘片的指定位置上进行数据的读写操作。数据通过磁头由电磁流来改变极性方式被电磁流写到磁盘上，也可以通过相反方式读取。硬盘为精密设备，进入硬盘的空气必须过滤固态硬盘（SSD）：&emsp;Solid State Drive，用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上也与普通硬盘一致相较于HDD，SSD在防震抗摔、传输速率、功耗、重量、噪音上有明显优势，SSD传输速率性能是HDD的2倍相较于SSD，HDD在价格、容量、使用寿命上占有绝对优势硬盘有价，数据无价，目前SSD不能完全取代HHD 设备文件磁盘设备的设备文件命名： /dev/DEV_FILESCSI, SATA, SAS,IDE,USB: /dev/sd虚拟磁盘：/dev/vd不同磁盘标识：a-z,aa,ab…/dev/sda, /dev/sdb, …同一设备上的不同分区：1,2, …/dev/sda1, /dev/sda5硬盘存储术语head：磁头track：磁道cylinder: 柱面sector: 扇区，512bytes 分区两种分区方式：MBR，GPT MBR: Master Boot Record，1982年，使用32位表示扇区数，分区不超过2T如何分区：按柱面0磁道0扇区：512bytes446bytes: boot loader64bytes：分区表，其中每16bytes标识一个分区2bytes: 55AA4个主分区；3主分区+1扩展(N个逻辑分区) MBR分区结构 &emsp;硬盘主引导记录MBR由4个部分组成: 主引导程序（偏移地址0000H–0088H），它负责从活动分区中装载，并运行系统引导程序 出错信息数据区，偏移地址0089H–00E1H为出错信息，00E2H–01BDH全为0字节 分区表（DPT,Disk Partition Table）含4个分区项，偏移地址01BEH–01FDH,每个分区表项长16个字节，共64字节为分区项1、分区项2、分区项3、分区项4 结束标志字，偏移地址01FE–01FF的2个字节值为结束标志55AA GPT分区 GPT:GUID（Globals Unique Identifiers）partition table 支持128个分区，使用64位，支持8Z（512Byte/block ）64Z （4096Byte/block）使用128位UUID(Universally Unique Identifier) 表示磁盘和分区GPT分区表自动备份在头和尾两份，并有CRC校验位UEFI (统一扩展固件接口)硬件支持GPT，使操作系统启动 管理分区12345678列出块设备•lsblk创建分区使用：•fdisk创建MBR分区•gdisk创建GPT分区•parted高级分区操作重新设置内存中的内核分区表版本•partprobe parted命令 parted的操作都是实时生效的，小心使用用法：123456parted [选项]... [设备[命令[参数]...]...]parted /dev/sdbmklabelgpt|msdosparted /dev/sdbprintparted /dev/sdbmkpartprimary 1 200 （默认M）parted /dev/sdbrm1parted –l 列出分区信息 分区工具fdisk和gdisk123456789101112gdisk/dev/sdb类fdisk的GPT分区工具fdisk-l [-u] [device...] 查看分区fdisk/dev/sdb管理分区子命令：p 分区列表t 更改分区类型n 创建新分区d 删除分区v 校验分区u 转换单位w 保存并退出q 不保存并退出 同步分区表 查看内核是否已经识别新的分区cat /proc/partationscentos6通知内核重新读取硬盘分区表新增分区用12partx -a /dev/DEVICEkpartx -a /dev/DEVICE -f: force 删除分区用123partx-d --nrM-N /dev/DEVICECentOS 5，7: 使用partprobepartprobe[/dev/DEVICE] 文件系统类型Linux文件系统： ext2(Extended file system) :适用于那些分区容量不是太大，更新也不频繁的情况，例如/boot 分区 ext3:是ext2 的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中恢复。它通常被用作通用的文件系统 ext4:是ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使用巨型文件(16TB)、最大1EB的文件系统，以及速度的提升 xfs：SGI，支持最大8EB的文件系统btrfs（Oracle）, reiserfs, jfs（AIX）, swap光盘：iso9660Windows：FAT32, exFAT,NTFSUnix: FFS（fast）, UFS（unix）, JFS2网络文件系统：NFS, CIFS集群文件系统：GFS2, OCFS2（oracle）分布式文件系统：fastdfs,ceph, moosefs, mogilefs, glusterfs, LustreRAW：未经处理或者未经格式化产生的文件系统 文件系统分类根据其是否支持”journal”功能：日志型文件系统: ext3, ext4, xfs, …非日志型文件系统: ext2, vfat文件系统的组成部分：内核中的模块：ext4, xfs, vfat用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfatLinux的虚拟文件系统：VFS查前支持的文件系统：cat /proc/filesystems 创建ext文件系统12345678910111213141516171819mke2fs：ext系列文件系统专用管理工具-t &#123;ext2|ext3|ext4&#125; 指定文件系统类型-b &#123;1024|2048|4096&#125; 指定块大小-L ‘LABEL’ 设置卷标-j相当于-t ext3mkfs.ext3 = mkfs-t ext3 = mke2fs -j = mke2fs -t ext3-i#为数据空间中每多少个字节创建一个inode；不应该小于block大小-N #指定分区中创建多少个inode-I 一个inode记录占用的磁盘空间大小，128---4096-m #默认5%,为管理人员预留空间占总空间的百分比-O FEATURE[,...]启用指定特性-O ^FEATURE关闭指定特性tune2fs -l /dev/sdb1|less 查看文件系统的元数据dumpe2fs /dev/sdb1|less 查看文件系统的元数据Filesystem features: has_journal journal说明该文件系统有日志功能日志型文件系统: ext3, ext4, xfs, ...非日志型文件系统: ext2, vfatFilesystem state: clean noclean 时说明文件系统出问题findfs LABEL=&lt;label&gt;| UUID=&lt;uuid&gt; 如：findfs UUID=6ec4348f-8835-4521-9285-23bc242b6243 查找分区 文件系统标签指向设备的另一种方法与设备无关123456789blkid：块设备属性信息查看blkid[OPTION]... [DEVICE]-U UUID根据指定的UUID来查找对应的设备-L LABEL根据指定的LABEL来查找对应的设备e2label：管理ext系列文件系统的LABELe2label DEVICE [LABEL]findfs：查找分区findfs[options] LABEL=&lt;label&gt;findfs[options] UUID=&lt;uuid&gt; tune2fs1234567891011tune2fs：重新设定ext系列文件系统可调整参数的值-l查看指定文件系统超级块信息；super block-L 'LABEL‘修改卷标-m #修预留给管理员的空间百分比-j将ext2升级为ext3-O文件系统属性启用或禁用,–O ^has_journal-o调整文件系统的默认挂载选项，–o ^acl-U UUID修改UUID号dumpe2fs：块分组管理，32768块-h：查看超级块信息，不显示分组信息 文件系统检测和修复常发生于死机或者非正常关机之后挂载为文件系统标记为“no clean”注意：一定不要在挂载状态下修复fsck: File System Checkfsck.FS_TYPEfsck -t FS_TYPE -p自动修复错误-r交互式修复错误FS_TYPE一定要与分区上已经文件类型相同e2fsck：ext系列文件专用的检测修复工具-y自动回答为yes-f强制修复 实验：增加一块新硬盘，分区，创建文件系统XFS|EXT4，并挂载 VMware中添加一块200G硬盘，重启虚拟机输入lsblk查看多了一个sdb 硬盘12345678910111213141516171819202122232425262728293031323334353637383940414243444546fdisk /dev/sdbCommand (m for help): mCommand action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition 删除一个分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition 创建一个分区 o create a new empty DOS partition table p print the partition table 查看分区信息 q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit 保存写入分区操作信息，不按w分区不保存 x extra functionality (experts only)按m进入交互式操作按n新建一个分区，如下Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) 主分区 e extended 扩展分区Select (default p): pPartition number (1-4, default 1): 1 分区编号First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): +50G 分区大小 Partition 1 of type Linux and of size 1 GiB is setCommand (m for help): p 显示分区信息Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x1cc76008 Device Boot Start End Blocks Id System/dev/sdb1 2048 2099199 1048576 83 Linux然后按w保存分区信息************************** 分区完成若lsblk后没有新建的分区，可以输入partx -a /dev/sdb 来通知内核重新读取分区表 或者输入partprobe 进行分区同步 挂载mount挂载:将额外文件系统与根文件系统某现存的目录建立起关联关系，进而使得此目录做为其它文件访问入口的行为卸载:为解除此关联关系的过程把设备关联挂载点：mount Pointmount卸载时：可使用设备，也可以使用挂载点umount挂载点下原有文件在挂载完成后会被临时隐藏挂载点目录一般为空 用mount命令挂载文件系统1234#挂载方法：mount DEVICE MOUNT_POINTmount 通过查看/etc/mtab文件显示当前已挂载的所有设备mount [-fnrsvw] [-t vfstype] [-o options] device dir device：指明要挂载的设备； (1) 设备文件：例如/dev/sda5(2) 卷标：-L ‘LABEL’, 例如-L ‘MYDATA’(3) UUID, -U ‘UUID’：例如-U ‘0c50523c-43f1-45e7-85c0-a126711d406e’(4) 伪文件系统名称：proc, sysfs, devtmpfs, configfsdir：挂载点事先存在；建议使用空目录进程正在使用中的设备无法被卸载 mount常用命令选项123456789mount-t vsftype指定要挂载的设备上的文件系统类型-rreadonly，只读挂载-wread and write, 读写挂载-n不更新/etc/mtab，mount不可见-a自动挂载所有支持自动挂载的设备(定义在了/etc/fstab文件中，且挂载选项中有auto功能)-L 'LABEL' 以卷标指定挂载设备-U 'UUID' 以UUID指定要挂载的设备-B, --bind绑定目录到另一个目录上 查看内核追踪到的已挂载的所有设备123456789101112131415cat /proc/mounts-o options：(挂载文件系统的选项)，多个选项使用逗号分隔.&gt;async 异步模式sync同步模式,内存更改时，同时写磁盘atime/noatime 包含目录和文件diratime/nodiratime 目录的访问时间戳auto/noauto 是否支持自动挂载,是否支持-a选项exec/noexec 是否支持将文件系统上运行应用程序dev/nodev 是否支持在此文件系统上使用设备文件suid/nosuid 是否支持suid和sgid权限remount 重新挂载ro只读rw读写user/nouser 是否允许普通用户挂载此设备，/etc/fstab使用acl 启用此文件系统上的acl功能loop 使用loop设备defaults：相当于rw, suid, dev, exec, auto, nouser, async 查询设备1234567#blkid 查询各个设备UUIDmount -U 'UUID' 加挂载点 挂载设备umount /mnt/sdb1 卸载挂载设备sdb1（无占用） lsof /mnt/sdb1 有用户占用时，查询sdb1占用进程和用户fuser -km /mnt/sdb1 结束sdb1的所有占用cat /proc/mounts 查询所有的挂载点umount -o remount +挂载点 重新挂载，某些设备不能取消挂载 实验：迁移/home目录到新分区中12345678910111213141516#先添加一块新的硬盘，重启虚拟机lsblk看到新硬盘为sdcfdisk /dev/sdc 新建一个分区sdc1blkidmkfs.xfs /dev/sdc1 创建文件系统mkdir /mnt/home 创建新的挂载点mount /dev/sdc1 /mnt/home 将光盘进行挂载cp -av /home/. /mnt/home 将原来home下的所有文件复制到/mnt/home下ll mnt/homedu -sh /mnt/homedu -sh /home 比较两文件夹的大小，看复制是否完整vim /etc/fstab 命令模式下写入:r!blkid /dev/sdc1 修改后按wq保存退出mount -a 使挂载生效df -h 查看占用umount /home 取消挂载rm -rf /home/* 删除home中的文件]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验 ：源码编译安装httpd-2.4.25.tar.bz2]]></title>
    <url>%2F2018%2F10%2F05%2F%E5%AE%9E%E9%AA%8C%20%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85httpd-2.4.25.tar.bz2%2F</url>
    <content type="text"><![CDATA[实验 ：源码编译安装httpd-2.4.25.tar.bz2123456789101112131415161718191. yum groupinstall "development tools"2. yum install apr-devel apr-util-devel pcre-devel openssl-devel3. useradd -r -u 80 -d /data/www/ -s /sbin/nologin httpd4. mkdir httpd5. cd httpd6. rz 选择httpd-2.4.25.tar.bz27. tar xf httpd-2.4.25.tar.bz28. cd httpd-2.4.25/9. cat README #查看安装介绍10. cat INSTALL #查看功能帮助介绍11. ./configure --prefix=/app/httpd --sysconfdir=/etc/httpd24 --enable-ssl --disable-status12. make &amp;&amp; make install13. echo 'PATH=/app/httpd/bin:$PATH' &gt; /etc/profile.d/httpd.sh14. . /etc/profile.d/httpd.sh15. apachectl start16. #然后查询网卡信息，在浏览器输入桥接地址看是否出现it works!17. #修改it works!，可用vim /root/http/httpd-2.4.25/docs/docroot/index.html，修改index.html18. echo ‘PATH=/app/httpd/bin:$PATH’ &gt; /etc/profile.d/httpd.sh添加将路径添加到PATH变量 编译安装编译安装 .configure **配置(1) 通过选项传递参数，指定启用特性、安装路径等；执行时会参考用户的指定以及Makefile.in文件生成Makefile2、make 根据Makefile文件，构建应用程序 ***编译3、make install 复制文件到相应路径 **安装du -sh 查看当前目录占用空间大小]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软连接和硬链接的区别]]></title>
    <url>%2F2018%2F10%2F04%2F%E8%BD%AF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%A1%AC%E9%93%BE%E6%8E%A5%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[软连接和硬链接的区别: 两个文件若互为对方的硬链接，则这两个文件指向同一个 inode，如果删除了其中一个，对另外一个没有影响。 每增加一个硬链接，inode 节点上的链接数增加一，每删除一个硬链接，inode 节点上的链接数减一，直到为 0，inode 节点和对应的数据块被回收。 若 A 文件是 B 文件的软连接，则 A 和 B 分别是不同的文件，指向的 inode 节点号也不相同，但是 A 文件的 inode指向的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。硬链接的特点：1：不能对目录创建硬链接2：不能对不同的文件系统创建硬链接,即两个文件名要在相同的文件系统下。3：不能对不存在的文件创建硬链接软连接的特点：a.可以对目录创建软链接，遍历操作会忽略目录的软链接。b:可以跨文件系统c:可以对不存在的文件创建软链接]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：实现swap分区]]></title>
    <url>%2F2018%2F10%2F03%2F%E5%AE%9E%E9%AA%8C%EF%BC%9A%E5%AE%9E%E7%8E%B0swap%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[实验：实现swap分区swap 相当于虚拟内存，交换分区本实验为增加swap分区大小123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#新建一个分区[root@CentOS6 ~]#fdisk /dev/sdb 添加硬盘sdbWARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u').Command (m for help): n #新建分区Command action e extended p primary partition (1-4) p #e为逻辑分区，p为主分区Partition number (1-4): 2 #设定分区编号First cylinder (6529-26108, default 6529): #回车Using default value 6529Last cylinder, +cylinders or +size&#123;K,M,G&#125; (6529-26108, default 26108): +4G #分区大小为4GCommand (m for help): pDisk /dev/sdb: 214.7 GB, 214748364800 bytes255 heads, 63 sectors/track, 26108 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x7972ac2c Device Boot Start End Blocks Id System/dev/sdb1 1 6528 52436128+ 83 Linux/dev/sdb2 6529 7051 4200997+ 83 LinuxCommand (m for help): t #修改分区信息Partition number (1-4): 2Hex code (type L to list codes): 82 #改为swap分区Changed system type of partition 2 to 82 (Linux swap / Solaris)Command (m for help): pDisk /dev/sdb: 214.7 GB, 214748364800 bytes255 heads, 63 sectors/track, 26108 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x7972ac2c Device Boot Start End Blocks Id System/dev/sdb1 1 6528 52436128+ 83 Linux/dev/sdb2 6529 7051 4200997+ 82 Linux swap / SolarisCommand (m for help): w #保存分区信息The partition table has been altered!Calling ioctl() to re-read partition table.WARNING: Re-reading the partition table failed with error 16: Device or resource busy.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)Syncing disks.分区已创建好swapon /dev/sdb2 vim /etc/fstab #在其中写入以下信息UUID=f2350b40-9169-4ef7-a4d7-c389217e192f swap swap pri=10 0 0 # 其中pri=10为取代原来的swap的优先级,原swap优先级为-1swapoff #禁用swapswapon -a #启用swapcat /proc/swapsswapon -sfree -h #可以看到swap 又原来的2G变为了6G]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理及文件查找]]></title>
    <url>%2F2018%2F10%2F02%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%8F%8A%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[文本处理及正则表达式文件查看文件查看命令：cat，tac，revcat [OPTION]… [FILE]…-E：显示行结束符$-n：对显示出的每一行进行编号-A：显示所有控制符-b：非空行编号-s：压缩连续的空行成一行tacrev文件查看more: 分页查看文件more [OPTIONS…] FILE…-d: 显示翻页及退出提示less：一页一页地查看文件或STDIN输出查看时有用的命令包括：/文本搜索文本n/N跳到下一个或上一个匹配less命令是man命令使用的分页器 显示文本前或后行内容*head [OPTION]… [FILE]…-c #: 指定获取前#字节-n #: 指定获取前#行-#：指定行数tail [OPTION]… [FILE]…-c #: 指定获取后#字节-n #: 指定获取后#行-#：同上-f: 跟踪显示文件fd新追加的内容,常用日志监控相当于–follow=descriptor-F: 跟踪文件名，相当于–follow=name –retrytailf类似tail –f，当文件不增长时并不访问文件 ###按列抽取文本cut和合并文件paste***CUTcut [OPTION]… [FILE]…-d DELIMITER: 指明分隔符，默认tab-f FILEDS:…#: 第#个字段…#,#[,#]：离散的多个字段，例如1,3,6…#-#：连续的多个字段, 例如1-6混合使用：1-3,7-c按字符切割–output-delimiter=STRING指定输出分隔符cut和paste显示文件或STDIN数据的指定列cut-d:-f1/etc/passwdcat /etc/passwd|cut-d:-f7cut-c2-5/usr/share/dict/wordspaste 合并两个文件同行号的列到一行paste [OPTION]… [FILE]…-d 分隔符：指定分隔符，默认用TAB-s : 所有行合成一行显示示例：paste f1 f2paste -s f1 f2 收集文本统计数据wc*WC计数单词总数、行总数、字节总数和字符总数可以对文件或STDIN中的数据运行wcstory.txt392371901story.txt行数字数字节数常用选项 -l只计数行数-w只计数单词总数-c只计数字节总数-m只计数字符总数-L显示文件中最长行的长度 文本排序sort把整理过的文本显示在STDOUT，不改变原始文件sort[options]file(s)常用选项 -r执行反方向（由上至下）整理-R随机排序-n执行按数字大小整理-f选项忽略（fold）字符串中的字符大小写-u选项（独特，unique）删除输出中的重复行-t c选项使用c做为字段界定符-k X选项按照使用c字符分隔的X列来整理能够使用多次 uniquniq命令：从输入中删除前后相接的重复的行uniq[OPTION]… [FILE]…-c: 显示每行重复出现的次数-d: 仅显示重复过的行-u: 仅显示不曾重复的行注：连续且完全相同方为重复常和sort 命令一起配合使用：sort userlist.txt | uniq-c 比较文件比较两个文件之间的区别difffoo.conffoo2.conf5c5&lt; use_widgets=no.&gt;use_widgets=yes注明第5行有区别（改变） 取出IP地址的几种方法： *（重点） ifconfig | sed -r ‘2!d;s/.inet (addr:)?//;s/ .//‘ 6和7通用的取出IP地址ifconfig eth0 | head -2|tail -1| tr -dc ‘[0-9]. ‘ |tr -s ‘ ‘ |cut -d” “ -f2 6系统上ifconfig eth0|sed -n ‘2p’|sed ‘s@.inet @@’|sed ‘s@ netmask.$@@’ 提取出7上的IP地址，其中@@为分隔符ifconfig ens33|sed -nr ‘2s/.t (.) net./\1/gp’ 扩展的正则表达式取出IP，（）为分组，只有一个括号，所以后面写1ifconfig ens33|sed -nr ‘2s/（.t) (.)( net.)/\2/gp’ 扩展的正则表达式取出IP，（）为分组，有三个括号，所以后面写2留第二个ifconfig | sed -nr “s/.inet (.) netmask./\1/p” | head -n 1 取出7的IPifconfig | sed -nr “s/.inet (.) netmask.*/\1/p” 取出7的三个网卡IP 查询系统信息 ***重点..#RED is content color..#依次显示出..#系统版本..#内核版本..#CPU型号..#内存大小..#最大磁盘利用率..#hostname..#IP地址 RED=”\033[1;31m”COLOREND=”\033[0m”echo -e “OS version is $REDcat /etc/centos-release$COLOREND”echo -e “kernel version $REDuname -r$COLOREND”echo -e “The cpu type is $REDlscpu |egrep -i &#39;model name&#39;|tr -s &#39; &#39;|cut -d: -f2$COLOREND”echo -e “The memory is $REDfree -h|egrep Mem|tr -s &#39; &#39; &#39;:&#39; |cut -d: -f2$COLOREND”echo -e “The max disk used is $REDdf |grep /dev/sd|tr -s &quot; &quot; &quot;:&quot;|cut -d: -f5|sort -nr|head -1$COLOREND”echo -e “The hostname is $RED$(hostname)$COLOREND”echo -e “The ipaddr is $REDifconfig|head -2|tail -1|tr -s &quot; &quot; &quot;:&quot;|cut -d: -f3$COLOREND”unset RED COLOREND Linux文本处理三剑客grep：文本过滤(模式：pattern)工具grep, egrep, fgrep（不支持正则表达式搜索）sed：stream editor，文本编辑工具awk：Linux上的实现gawk，文本报告生成器 grep*(重点)grep: Global search REgularexpression and Print out the line作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行模式：由正则表达式字符及文本字符所编写的过滤条件 grep [OPTIONS] PATTERN [FILE…]grep root /etc/passwdgrep “$USER” /etc/passwdgrep ‘$USER’ /etc/passwdgrep whoami /etc/passwdgrep命令选项–color=auto: 对匹配到的文本着色显示-v: 显示不被pattern匹配到的行-i: 忽略字符大小写-n：显示匹配的行号-c: 统计匹配的行数-o: 仅显示匹配到的字符串-q: 静默模式，不输出任何信息-A #: after, 后#行-B #: before, 前#行-C #：context, 前后各#行-e：实现多个选项间的逻辑or关系grep –e ‘cat ’ -e ‘dog’ file-w：匹配整个单词-E：使用ERE-F：相当于fgrep，不支持正则表达式-ffile: 根据模式文件处理 正则表达式*重点REGEXP：Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能程序支持：grep,sed,awk,vim, less,nginx,varnish等分两类：基本正则表达式：BRE扩展正则表达式：EREgrep -E, egrep正则表达式引擎：采用不同算法，检查处理正则表达式的软件模块PCRE（Perl Compatible Regular Expressions）元字符分类：字符匹配、匹配次数、位置锚定、分组man 7 regex 基本正则表达式元字符字符匹配:. 匹配任意单个字符[] 匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z][^] 匹配指定范围外的任意单个字符[:alnum:] 字母和数字[:alpha:] 代表任何英文大小写字符，亦即A-Z, a-z[:lower:] 小写字母[:upper:] 大写字母[:blank:] 空白字符（空格和制表符）[:space:]水平和垂直的空白字符（比[:blank:]包含的范围广）[:cntrl:] 不可打印的控制字符（退格、删除、警铃…）[:digit:] 十进制数字[:xdigit:]十六进制数字[:graph:] 可打印的非空白字符[:print:] 可打印字符[:punct:] 标点符号 通配符是通配的文件名正则表达式是配的字符串，文件的内容【wang】 匹配这四个字符其中的一个grep “[123]” /etc/passwd查询passwd文件夹里包含123中一个数字的文件grep -v “[123]” /etc/passwd查询passwd文件夹里不包含123中一个数字的文件grep “[^123]” /etc/passwd查询passwd文件夹里除了123中一个数字的文件匹配次数：用在要指定次数的字符后面，用于指定前面的字符要出现的次数‘ 匹配前面的字符任意次，包括0次贪婪模式：尽可能长的匹配.任意长度的任意字符\?匹配其前面的字符0或1次+匹配其前面的字符至少1次{n}匹配前面的字符n次{m,n}匹配前面的字符至少m次，至多n次{,n}匹配前面的字符至多n次{n,}匹配前面的字符至少n次 位置锚定：定位出现的位置^ 行首锚定，用于模式的最左侧 grep “^bash” /etc/passwd$ 行尾锚定，用于模式的最右侧 grep “bash$” /etc/passwd^PATTERN$ 用于模式匹配整行^$ 空行^[[:space:]]$ 空白行\&lt; 或\b词首锚定，用于单词模式的左侧(单词不能包含数字、_、其他字母开头)> 或\b词尾锚定，用于单词模式的右侧\&lt;PATTERN>匹配整个单词** 正则表达式分组：() 将一个或多个字符捆绑在一起，当作一个整体处理，如：(root)+分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为: \1, \2, \3, …\1表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符示例：(string1+(string2))\1 ：string1+(string2)\2 ：string2后向引用：引用前面的分组括号中的模式所匹配字符，而非模式本身或者：|示例：a|b: a或b C|cat: C或cat (C|c)at:Cat或cat元字符 ^ 行首$行尾.任意单一字符[][]内任意单一字符[^]除[]内任意单一字符*前面字符重复不确定次数++前面字符重复一次以上不确定次数\?？前面字符重复0或1次\转义符.任意长度字符{n}前面字符重复n次{n,}前面字符重复n次以上{m,n}前面字符重复m次和n次之间[:alnum:]字母和数字[:alpha:]代表任何英文大小写字符，亦即A-Z, a-z[:lower:]小写字母[:upper:]大写字母[:blank:]水平空白字符（空格和制表符）[:space:]所有水平和垂直的空白字符（比[:blank:]包含的范围广）[:cntrl:]不可打印的控制字符（退格、删除、警铃…）[:digit:]十进制数字[:graph:]可打印的非空白字符[:print:]可打印字符[:punct:]标点符号[:xdigit:]十六进制数字 egrep及扩展的正则表达式egrep= grep -Eegrep[OPTIONS] PATTERN [FILE…]扩展正则表达式的元字符：字符匹配：. 任意单个字符[] 指定范围的字符[^] 不在指定范围的字符次数匹配：*匹配前面字符任意次?0或1次+1次或多次{m}匹配m次{m,n}至少m，至多n次位置锚定：^行首$行尾\&lt;, \b语首>, \b语尾分组：()后向引用：\1, \2, …或者：a|ba或bC|catC或cat(C|c)atCat或cat vim简介*重点见PDF6中第32，68，69页图片vi: Visual Interface，文本编辑器文本：ASCII, Unicode文本编辑种类：行编辑器: sed全屏编辑器：nano, vivim-Vi Improved其他编辑器：gedit一个简单的图形编辑器gvim一个Vim编辑器的图形版本 打开文件vim [OPTION]… FILE…+#打开文件后，让光标处于第#行的行首，+默认行尾+/PATTERN打开文件后，直接让光标处于第一个被PATTERN匹配到的行的行首–b file 二进制方式打开文件–d file1 file2… 比较多个文件-m file 只读打开文件ex file 或vim –e 直接进入ex模式如果该文件存在，文件被打开并显示内容如果该文件不存在，当编辑后第一次存盘时创建它模式转换命令模式–&gt; 插入模式iinsert, 在光标所在处输入I在当前光标所在行的行首输入aappend, 在光标所在处后面输入A在当前光标所在行的行尾输入o在当前光标所在行的下方打开一个新行O在当前光标所在行的上方打开一个新行 插入模式——–&gt; 命令模式ESC命令模式——–&gt; 扩展命令模式:扩展命令模式——–&gt; 命令模式ESC,enter 扩展命令模式：:q退出:q!强制退出，丢弃做出的修改:wq保存退出:x保存退出命令模式ZZ保存退出ZQ不保存退出命令模式光标跳转字符间跳转：h: 左l: 右j: 下k: 上.#COMMAND：跳转由#指定的个数的字符** 单词间跳转：w：下一个单词的词首e：当前或下一单词的词尾b：当前或前一个单词的词首。#COMMAND：由#指定一次跳转的单词数当前页跳转：H：页首M：页中间行L:页底zt：将光标所在当前行移到屏幕顶端zz：将光标所在当前行移到屏幕中间zb：将光标所在当前行移到屏幕底端行首行尾跳转：^: 跳转至行首的第一个非空白字符0: 跳转至行首$: 跳转至行尾行间移动：.#G、扩展命令模式下：# 跳转至由#指定行G：最后一行1G, gg: 第一行句间移动：)：下一句(：上一句段落间移动：}:下一段{：上一段命令模式翻屏操作Ctrl+f: 向文件尾部翻一屏Ctrl+b: 向文件首部翻一屏Ctrl+d: 向文件尾部翻半屏Ctrl+u：向文件首部翻半屏 命令模式操作**重点删除命令：d: 删除命令，可结合光标跳转字符，实现范围删除d$: 删除到行尾d^:删除到非空行首d0:删除到行首dw:de:db:.#COMMANDdd: 删除光标所在的行.#dd：多行删除D：从当前光标位置一直删除到行尾，等同于d$复制命令(y, yank)：y: 复制，行为相似于d命令y$y0y^yeywyb.#COMMANDyy：复制行.#yy: 复制多行Y: 复制整行 命令模式di” 光标在”“之间，则删除”“之间的内容yi( 光标在()之间，则复制()之间的内容vi[ 光标在[]之间，则选中[]之间的内容dtx删除字符直到遇见光标之后的第一个x 字符ytx复制字符直到遇见光标之后的第一个x 字符扩展命令模式：地址定界**按ESC进入命令模式，再按：进入扩展命令模式 地址定界:start_pos,end_pos# 具体第#行，例如2表示第2行#,# 从左侧#表示起始行，到右侧#表示结尾行#,+# 从左侧#表示的起始行，加上右侧#表示的行数 ：2,+3 表示2到5行 . 当前行$最后一行 .,$`-1 当前行到倒数第二行% 全文, 相当于1,$/pat1/,/pat2/从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束 #,/pat//pat/,$使用方式：后跟一个编辑命令dyw file: 将范围内的行另存至指定文件中r file：在指定位置插入指定文件中的所有内容/PATTERN：从当前光标所在处向文件尾部查找?PATTERN：从当前光标所在处向文件首部查找n：与命令同方向N：与命令反方向 s: 在扩展模式下完成查找替换操作**重点格式：s/要查找的内容/替换为的内容/修饰符要查找的内容：可使用模式替换为的内容：不能使用模式，但可以使用\1, \2, …等后向引用符号；还可以使用“&amp;”引用前面查找时查找到的整个内容修饰符：i: 忽略大小写g: 全局替换；默认情况下，每一行只替换第一次出现gc:全局替换，每次替换前询问查找替换中的分隔符/可替换为其它字符，例如s@/etc@/var@gs#/boot#/#i 命令模式：撤消更改u撤销最近的更改 #u撤销之前多次更改U撤消光标落在这行后所有此行的更改按Ctrl-r重做最后的“撤消”更改. 重复前一个操作n.重复前一个操作n次多文件模式vim FILE1 FILE2 FILE3 …:next 下一个:prev前一个:first 第一个:last 最后一个:wall 保存所有:qall退出所有:wqall 定制vim的工作特性配置文件：永久有效全局：/etc/vimrc***个人：~/.vimrc扩展模式：当前vim进程有效(1) 行号显示：set number, 简写为set nu取消显示：set nonumber, 简写为set nonu(2) 忽略字符的大小写启用：set ic不忽略：set noic(3) 自动缩进启用：set ai禁用：set noai(4) 智能缩进启用：smartindent简写set si禁用：set nosi(5) 高亮搜索启用：set hlsearch禁用：set nohlsearch(6) 语法高亮启用：syntax on禁用：syntax off(7) 显示Tab和换行符^I 和$显示启用：set list禁用：set nolist(8) 文件格式启用windows格式：set fileformat=dos启用unix格式：set fileformat=unix简写：set ff=dos|unix(9) 设置文本宽度set textwidth=65 (vimonly)set wrapmargin=15(10) 设置光标所在行的标识线启用：set cursorline，简写cul禁用：set no cursorline(11) 复制保留格式启用：set paste禁用：set nopaste SHELL脚本*重点创建shell脚本第一步：使用文本编辑器来创建文本文件第一行必须包括shell声明序列：#!.#!/bin/bash添加注释注释以#开头第二步：运行脚本给予执行权限，在命令行上指定脚本的绝对或相对路径直接运行解释器，将脚本作为解释器程序的参数运行脚本规范脚本代码开头约定1、第一行一般为调用使用的语言2、程序名，避免更改文件名为无法找到正确的文件3、版本号4、更改后的时间5、作者相关信息6、该程序的作用，及注意事项7、最后是各版本的更新简要说明shell脚本示例 #!/bin/bash #—————————————— #Filename: hello.sh #Revision: 1.1 #Date: 2017/06/01 #Author: wang #Email: wang@gmail.com #Website: www.magedu.com #Description: This is the first script #—————————————— #Copyright: 2017 wang #License: GPLecho “hello world” .vimrc文件在根目录下，修改：vim .vimrc 文件可以修改vim的脚本注释作者等信息*** 局部变量变量赋值：name=‘value’可以使用引用value:(1) 可以是直接字串; name=”root”(2) 变量引用：name=”$USER” (3) 命令引用：name=COMMAND name=$(COMMAND)变量引用：${name} $name“”：弱引用，其中的变量引用会被替换为变量值 ‘’：强引用，其中的变量引用不会被替换为变量值，而保持原字符串显示已定义的所有变量：set删除变量：unset name环境变量变量声明、赋值：export name=VALUEdeclare -x name=VALUE变量引用：$name, ${name}显示所有环境变量：env printenvexportdeclare -x删除变量：unset name退出状态进程使用退出状态来报告成功或失败0 代表成功，1－255代表失败$? 变量保存最近的命令退出状态例如：ping-c1-W1hostdown&amp;&gt;/dev/nullecho$? 退出状态码***8bash自定义退出状态码exit [n]：自定义退出状态码注意：脚本中一旦遇到exit命令，脚本会立即终止；终止退出状态取决于exit命令后面的数字注意：如果未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 算术运算bash中的算术运算:help let+, -, , /, %取模（取余）, **（乘方）实现算术运算：(1) let var=算术表达式(2) var=$[算术表达式](3) var=$((算术表达式))(4) var=$(expr arg1 arg2 arg3 …)(5) declare –ivar= 数值(6) echo ‘算术表达式’ | bc乘法符号有些场景中需要转义，如bash有内建的随机数生成器：$RANDOM（0-32767）echo $[$RANDOM%50] ：0-49之间随机数增强型赋值：+=, -=, =, /=, %=let varOPERvalue例如:let count+=3自加3后自赋值自增，自减：例子：let var+=1let var++let var-=1let var–let n=1+2echo $n3n=$（2+3）2expr 3+4 错误expr 3 + 47expr为命令 3+4为参数之间要有空格**echo $[RANDOM%100+1] 取1-100之间的随机数 RANDOM为随机数，除以100得到的余数为0-99，+1后为1-100 **echo $? 查询命令执行结果 &amp; 与 交集**| 或 并集! 非^ 异或 相同为0 不同为1&amp;&amp; 短路与 两条命令，第一条为真，则执行第二天2条看真假，第一条为假的情况下直接不执行命令|| 短路或 两条命令，第一条为假，则执行第二天2条看真假，第一条为真的情况下直接不执行命令同或 相同为1 不同为0[ “$str1” !=”$str2” ] 判断两个字符串是否相同bash +x 加sh脚本可以看到脚本运行的过程，可以检查哪里出错export +定义的变量可使该变量在子进程中也生效find -name +文件名 查找文件或者安装包 bash的数值测试-v VAR变量VAR是否设置数值测试：-gt是否大于-ge是否大于等于-eq是否等于-ne是否不等于-lt是否小于-le是否小于等于Bash的文件属性测试 文件大小测试：-s FILE: 是否存在且非空文件是否打开：-t fd: fd文件描述符是否在某终端已经打开-N FILE：文件自从上一次被读取之后是否被修改过-O FILE：当前有效用户是否为文件属主-G FILE：当前有效用户是否为文件属组Bash的文件测试 存在性测试-a FILE：同-e-e FILE: 文件存在性测试，存在为真，否则为假存在性及类别测试-b FILE：是否存在且为块设备文件-c FILE：是否存在且为字符设备文件-d FILE：是否存在且为目录文件-f FILE：是否存在且为普通文件-h FILE 或-L FILE：存在且为符号链接文件-p FILE：是否存在且为命名管道文件-S FILE：是否存在且为套接字文件 使用read命令来接受输入使用read来把输入值分配给一个或多个shell变量-p指定要显示的提示-s 静默输入，一般用于密码-n N指定输入的字符长度N-d‘字符’ 输入结束符-t N TIMEOUT为N秒read从标准输入中读取值，给每个单词分配一个变量所有剩余单词都被分配给最后一个变量read -p “Enter a filename:“ FILE bash如何展开命令行*重点把命令行分成单个命令词展开别名展开大括号的声明（{}）展开波浪符声明（~）命令替换$()和）再次把命令行分成命令词展开文件通配（*、?、[abc]等等）准备I/0重导向（&lt;、&gt;）运行命令防止扩展反斜线（\）会使随后的字符按原意解释 $echoYourcost:\$5.00 Yourcost:$5.00加引号来防止扩展单引号（’）防止所有扩展$（美元符号）－变量扩展`（反引号）－命令替换\（反斜线）－禁止单个字符扩展!（叹号）－历史命令替换 Profile类按功能划分，存在两类：profile类和bashrc类profile类：为交互式登录的shell提供配置全局：/etc/profile, /etc/profile.d/*.sh个人：~/.bash_profile功用：(1) 用于定义环境变量(2) 运行命令或脚本Bashrc类bashrc类：为非交互式和交互式登录的shell提供配置全局：/etc/bashrc个人：~/.bashrc功用：(1) 定义命令别名和函数(2) 定义本地变量 locate命令locate KEYWORD有用的选项 -i不区分大小写的搜索-n N只列举前N个匹配项目-r 使用正则表达式示例搜索名称或路径中带有“conf”的文件locate conf使用Regex来搜索以“.conf”结尾的文件locate -r ‘.conf$’ find***重点查找条件指搜索层级-maxdepthlevel 最大搜索目录深度,指定目录为第1级-mindepthlevel 最小搜索目录深度先处理目录内的文件，再处理目录-depth 根据文件名和inode查找：-name “文件名称”：支持使用glob*, ?, [], [^]-iname”文件名称”：不区分字母大小写-inumn 按inode号查找-samefilename 相同inode号的文件-links n 链接数为n的文件-regex“PATTERN”：以PATTERN匹配整个文件路径，而非文件名称 根据属主、属组查找：-user USERNAME：查找属主为指定用户(UID)的文件-group GRPNAME: 查找属组为指定组(GID)的文件-uidUserID：查找属主为指定的UID号的文件-gidGroupID：查找属组为指定的GID号的文件-nouser：查找没有属主的文件-nogroup：查找没有属组的文件 根据文件类型查找： -type TYPE:•f: 普通文件•d: 目录文件•l: 符号链接文件•s：套接字文件•b: 块设备文件•c: 字符设备文件•p: 管道文件空文件或目录-emptyfind /app -type d -empty find示例备份配置文件，添加.orig这个扩展名find -name “*.conf” -exec cp {} {}.orig\;提示删除存在时间超过３天以上的joe的临时文件find/tmp-ctime+3-userjoe-okrm{}\;在主目录中寻找可被其它用户写入的文件find~-perm-002 -execchmodo-w{}\;find /home –type d -ls Find笔记**locate text.sh搜索文件因为是从locate的数据库搜索文件的，速度快不影响服务器性能，适合搜索本来就在内存中的文件，而新建的文件不会马上搜索到，可以输入updatedb更新locate数据库locata +”通配符”搜索文件locata -r “.sh$”搜索以.sh结尾的文件(支持正则表达式)find搜索是实时搜索，在硬盘上搜索，速度慢且影响服务器性能，而且没有权限的文件夹搜索不进去 **（面试常有）find （路径） -name（iname） “text“搜索包含text的文件+i后忽略大小写find -name “.txt” 查找以txt结尾的文件find -empty 搜索空文件或者空目录find / -size 10k 搜索9-10k的文件find / -size -10k 搜索0-10k的文件find / -size +10k 搜索大于10k的文件find / -size +5k -size 10k 搜索5-10K的文件find -name “*.txt” -exec（批量） rm {} \; 查找后缀名为txt的文件并 批量 删除 chmod a+x 文件 给所有人加上此文件的执行权限ll -d 查询当前目录下的权限 ** compresscompress +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.z的压缩文件compress -c +文件 &gt; 文件.gz压缩文件并显示过程 不会丢失源文件，利用重定向保留原文件uncompress +文件【同解压】 等于 compress -d+文件 解压该文件，解压后该文件消失，生成不带.z的原文件 ** gzipgzip +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.gz的压缩文件zcat -c +文件 &gt; 文件.gz压缩文件并显示过程 不会丢失源文件，利用重定向保留原文件gunzip +文件【同解压】 等于 gzip -d+文件 解压该文件，解压后该文件消失，生成不带.gz的原文件 ** bzip2bzip2 +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.bz2的压缩文件bzip2 -k 压缩文件并保留原文件不会丢失源文件，利用重定向保留原文件bzip2 -d+文件 等于bunzip2 解压该文件，解压后该文件消失，生成不带.bz2的原文件bzcat +文件 查看压缩文件而不执行解压 *** xzxz +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.xz的压缩文件zx -k 压缩文件并保留原文件不会丢失源文件，利用重定向保留原文件zx -d+文件 等于unzx 解压该文件，解压后该文件消失，生成不带.zx的原文件xzcat +文件 查看压缩文件而不执行解压处理-开头的文件时前面加–以上压缩只能压缩单个文件，而不能压缩文件夹压缩比 xz &gt; bzip2 &gt; gzip &gt; compress zipzip +生成文件名 +要压缩的文件名 压缩文件zip -r /backup/sysconfig /etc/sysconfig 加-r是压缩文件夹，将etc下的文件夹 sysconfig打包压缩生成sysconfig.zip文件放到backup文件夹unzip sysconfig.zip 解压文件 +p可以保留权限 tartar -cvf etc.tar etc 将整个etc文件夹打包保存为etc.tar ，其中后缀名tar要手动添加，只有打包而没有压缩文件tar -rf etc.tar text 追加text文件到tar.tar xvf etc.tar -C /data 解压文件到data文件夹 例子将data下的文件夹etc先打包再压缩的三种方法，压缩比 xz &gt;bz2 &gt;gztar zcvf etc.tar.gz /data/etctar jcvf etc.tar.bz2 /data/etctar Jcvf etc.tar.xz /data/etctar cvf etc.tar.xz 解压到当前目录tar xf etc.tar.bz2 解压到当前目录split -b 2M -d /data/bigfile.tar.xz bigfile 把大文件bigfile.tar.xz切割为每2M一个的小文件，并以bigfile开头后面加数字，如bigfile1,bigfile2,bigfile3cat bigfile* &gt; bigfile.tar.xz 合并切割的这些文件 处理文本的工具sed *重点sed工具用法：sed[option]… ‘script’ inputfile…常用选项：-n不输出模式空间内容到屏幕，即不自动打印-e多点编辑-f /PATH/SCRIPT_FILE从指定文件中读取编辑脚本-r支持使用扩展正则表达式-i.bak备份文件并原处编辑script:‘地址命令’地址定界：(1) 不给地址：对全文进行处理(2) 单地址：.#: 指定的行，$：最后一行/pattern/：被此处模式所能够匹配到的每一行(3) 地址范围：.#,#.#,+#/pat1/,/pat2/.#,/pat1/(4) ~：步进 编辑命令：d删除模式空间匹配的行，并立即启用下一轮循环p打印当前模式空间内容，追加到默认输出之后a[\]text在指定行后面追加文本，支持使用\n实现多行追加i[\]text在行前面插入文本c[\]text替换行为单行或多行文本w /path/file保存模式匹配的行至指定文件r /path/file读取指定文件的文本至模式空间中匹配到的行后=为模式空间中的行打印行号!模式空间中匹配行取反处理 SED笔记**重点重点重点SED 用法： 不加-i时仅仅是打印到屏幕显示，加-i可以修改文件，一般加-i.bak备份一个.bak文件sed[option]… ‘script’ inputfile…常用选项：-n不输出模式空间内容到屏幕，即不自动打印-e多点编辑-f /PATH/SCRIPT_FILE从指定文件中读取编辑脚本-r支持使用扩展正则表达式-i.bak备份文件并原处编辑编辑命令：d删除模式空间匹配的行，并立即启用下一轮循环p打印当前模式空间内容，追加到默认输出之后a[\]text在指定行后面追加文本，支持使用\n实现多行追加i[\]text在行前面插入文本c [\]text替换行为单行或多行文本w /path/file保存模式匹配的行至指定文件r /path/file读取指定文件的文本至模式空间中匹配到的行后=为模式空间中的行打印行号!模式空间中匹配行取反处理 例子sed‘2p’ /etc/passwdsed–n ‘2p’ /etc/passwd 显示第2行sed–n ‘1,4p’ /etc/passwd 显示1-4行sed–n ‘/root/p’ /etc/passwd 显示带有root的行sed–n ‘2,/root/p’ /etc/passwd 从2行开始sed-n ‘/^$/=’ file 显示空行行号 =代表行号sed–n –e ‘/^$/p’ –e ‘/^$/=’ filesed–n –r ‘/^#|^$/d’ + file 删除该文件中带#注释和空白的行sed‘/root/a\superman’ /etc/passwd行后sed‘/root/i\superman’ /etc/passwd行前sed‘/root/c\superman’ /etc/passwd代替行s///查找替换,支持使用其它分隔符，s@@@，s###替换标记：g行内全局替换p显示替换成功的行w /PATH/FILE将替换成功的行保存至文件中nl 可以显示行号 sed -n ‘/^u/p’ /data/f1 打印出data下的f1文件中以u开头的行sed -n ‘3,9’只显示3-9行sed -n ‘/^ftp/,/^lib/‘ passwd 显示passwd文件中以ftp开头和以lib开头之间的行sed -n ‘1~2p’ 打印奇数行sed -n ‘2~2p’ 打印偶数行sed -i ‘/^SELINUX=/cSELINUX=disabled’ /etc/selinux/config 把config文件中的SELINUX=enforcing改为SELINUX=disabled 禁用selinuxsed -n ‘s/tmpfs/tempfilesystem/g’ /etc/fstab 将文件fstab中的tmpfs替换为 tempfilesystem，并且只显示替换结果，s为查找替换，p为只显示替换的那一行sed -r ‘s/[[:alpha:]]/\u&amp;/g’ +文件 [[:alpha:]]意思为字母，u为大写，&amp;表示搜索到的内容，用u&amp;替换原内容，把所有的字母替换为大写sed -r ‘s/[[:alpha:]]/\l&amp;/g’ +文件 [[:alpha:]]意思为字母，l为小写，&amp;表示搜索到的内容，用u&amp;替换原内容，把所有的字母替换为小写sed -r ‘s/^[^#]/#&amp;’ +文件 将文件中不是#开头的行加上#并显示，其中&amp;代表被搜索出来的内容，等于用#&amp;替换了原来的内容，加-i可以直接修改 ………………………..（重点）sed -nr ‘/.CMDLINE_LINUX./s#(.*)”#\1 net.ifnames=0”#p’ /etc/default/grub 在带有CMDLINE_LINUX的一行后加上net.ifnames=0 仅在7系统需要修改 ………………….修改s///查找替换,支持使用其它分隔符，s@@@，s###替换标记：g行内全局替换p显示替换成功的行w /PATH/FILE将替换成功的行保存至文件中 第三次博客：TXT:10-08–10-14PDF 6开始-PDF9]]></content>
      <tags>
        <tag>VIM</tag>
        <tag>Find</tag>
        <tag>Sed</tag>
        <tag>正则表达式</tag>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下各压缩工具的使用方法]]></title>
    <url>%2F2018%2F10%2F02%2FLinux%E4%B8%8B%E5%90%84%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[压缩工具compress compress +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.z的压缩文件compress -c +文件 &gt; 文件.gz压缩文件并显示过程 不会丢失源文件，利用重定向保留原文件uncompress +文件【同解压】 等于 compress -d+文件 解压该文件，解压后该文件消失，生成不带.z的原文件 gzip gzip +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.gz的压缩文件zcat -c +文件 &gt; 文件.gz压缩文件并显示过程 不会丢失源文件，利用重定向保留原文件gunzip +文件【同解压】 等于 gzip -d+文件 解压该文件，解压后该文件消失，生成不带.gz的原文件 bzip2 bzip2 +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.bz2的压缩文件bzip2 -k 压缩文件并保留原文件不会丢失源文件，利用重定向保留原文件bzip2 -d+文件 等于bunzip2 解压该文件，解压后该文件消失，生成不带.bz2的原文件bzcat +文件 查看压缩文件而不执行解压 xz xz +文件【多个文件时压缩每个文件为单独的压缩文件】 压缩该文件，压缩后该文件消失，生成一个.xz的压缩文件zx -k 压缩文件并保留原文件不会丢失源文件，利用重定向保留原文件zx -d+文件 等于unzx 解压该文件，解压后该文件消失，生成不带.zx的原文件xzcat +文件 查看压缩文件而不执行解压处理-开头的文件时前面加–以上压缩只能压缩单个文件，而不能压缩文件夹压缩比 xz &gt; bzip2 &gt; gzip &gt; compress zipzip +生成文件名 +要压缩的文件名 压缩文件12zip -r /backup/sysconfig /etc/sysconfig 加-r是压缩文件夹，将etc下的文件sysconfig打包压缩生成sysconfig.zip文件放到backup文件夹 unzip sysconfig.zip 解压文件 +p可以保留权限 tar123tar -cvf etc.tar etc 将整个etc文件夹打包保存为etc.tar ，其中后缀名tar要手动添加，只有打包而没有压缩文件 tar -rf etc.tar text 追加text文件到tar. tar xvf etc.tar -C /data 解压文件到data文件夹 例子将data下的文件夹etc先打包再压缩的三种方法，压缩比 xz &gt;bz2 &gt;gz`bashtar zcvf etc.tar.gz /data/etctar jcvf etc.tar.bz2 /data/etctar Jcvf etc.tar.xz /data/etctar cvf etc.tar.xz #解压到当前目录tar xf etc.tar.bz2 #解压到当前目录split -b 2M -d /data/bigfile.tar.xz bigfile #把大文件bigfile.tar.xz切割为每2M一个的小文件，并以bigfile开头后面加数字，如bigfile1,bigfile2,bigfile3cat bigfile* &gt; bigfile.tar.xz #合并切割的这些文件]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验：centos6删除内核并恢复]]></title>
    <url>%2F2018%2F10%2F02%2F%E5%AE%9E%E9%AA%8C%EF%BC%9Acentos6%E5%88%A0%E9%99%A4%E5%86%85%E6%A0%B8%E5%B9%B6%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[实验：centos6 rm -f /boot/vmlinuz-2.6.32-754.el6.x86_64 恢复 rm -f /boot/vmlinuz-2.6.32-754.el6.x86_64重启在进度条时按下esc，只能按一下选择CD-ROM选择Rescue installed system提示根目录被修改为chroot /mnt/sysimage进入shell创建挂载点并挂载光盘因为vmlinuz-2.6.32-754.el6.x86_64在kernel包里，所以安装kernel包，并用—root告诉它根在/mnt/sysimage查看/boot下生成了vmlinuz-2.6.32-754.el6.x86_64文件输入exit退出shellReboot重启]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHELL脚本和Sed等工具的使用]]></title>
    <url>%2F2018%2F10%2F01%2FSHELL%E8%84%9A%E6%9C%AC%E5%92%8CSed%E7%AD%89%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[SHELL脚本(重点 )创建shell脚本第一步：使用文本编辑器来创建文本文件第一行必须包括shell声明序列：#! .#!/bin/bash添加注释注释以#开头第二步：运行脚本给予执行权限，在命令行上指定脚本的绝对或相对路径直接运行解释器，将脚本作为解释器程序的参数运行脚本规范脚本代码开头约定1、第一行一般为调用使用的语言2、程序名，避免更改文件名为无法找到正确的文件3、版本号4、更改后的时间5、作者相关信息6、该程序的作用，及注意事项7、最后是各版本的更新简要说明shell脚本示例12345678910111213#!/bin/bash #------------------------------------------ #Filename: hello.sh #Revision: 1.1 #Date: 2011/06/01 #Author: luhao #Email: luhao2149@vip.qq.com #Website: https://blog.csdn.net/weixin_43551152#Description: This is the first script #------------------------------------------ #Copyright: 2011#License: GPL echo “hello world” .vimrc文件在根目录下，修改：vim .vimrc 文件可以修改vim的脚本注释作者等信息 局部变量变量赋值：name=‘value’可以使用引用value:(1) 可以是直接字串; name=”root”(2) 变量引用：name=”$USER” (3) 命令引用：name=COMMAND name=$(COMMAND)变量引用：${name} $name“”：弱引用，其中的变量引用会被替换为变量值 ‘ ‘：强引用，其中的变量引用不会被替换为变量值，而保持原字符串显示已定义的所有变量：set删除变量：unset name环境变量变量声明、赋值：export name=VALUEdeclare -x name=VALUE变量引用：$name, ${name}显示所有环境变量：env printenvexportdeclare -x删除变量：unset name退出状态进程使用退出状态来报告成功或失败0 代表成功，1－255代表失败$? 变量保存最近的命令退出状态例如：ping-c1-W1hostdown&amp;&gt;/dev/nullecho$? 算术运算bash中的算术运算:help let+, -, , /, %取模（取余）, **（乘方）实现算术运算：(1) let var=算术表达式(2) var=$[算术表达式](3) var=$((算术表达式))(4) var=$(expr arg1 arg2 arg3 …)(5) declare –ivar= 数值(6) echo ‘算术表达式’ | bc乘法符号有些场景中需要转义，如bash有内建的随机数生成器：$RANDOM（0-32767）echo $[$RANDOM%50] ：0-49之间随机数增强型赋值：+=, -=, *=, /=, %=let varOPERvalue例如:let count+=3自加3后自赋值自增，自减：例子：12345678910111213141516let var+=1 let var++ let var-=1 let var-- let n=1+2 echo $n 3 n=$（2+3） 2 expr 3+4 错误 expr 3 + 4 7 expr为命令 3+4为参数之间要有空格************************************ echo $[RANDOM%100+1] 取1-100之间的随机数 ** RANDOM为随机数，除以100得到的余数为0-99，+1后为1-100 ***** echo $? 查询命令执行结果 &amp; 与 交集| 或 并集! 非^ 异或 相同为0 不同为1&amp;&amp; 短路与 两条命令，第一条为真，则执行第二天2条看真假，第一条为假的情况下直接不执行命令|| 短路或 两条命令，第一条为假，则执行第二天2条看真假，第一条为真的情况下直接不执行命令同或 相同为1 不同为0 [ “$str1” !=”$str2” ] 判断两个字符串是否相同bash +x 加sh脚本可以看到脚本运行的过程，可以检查哪里出错export +定义的变量可使该变量在子进程中也生效find -name +文件名 查找文件或者安装包 bash的数值测试12345678910-v VAR 变量VAR是否设置 数值测试： -gt是否大于 -ge是否大于等于 -eq是否等于 -ne是否不等于 -lt是否小于 -le是否小于等于 Bash的文件属性测试 文件大小测试： -s FILE: 是否存在且非空文件是否打开：-t fd: fd文件描述符是否在某终端已经打开-N FILE：文件自从上一次被读取之后是否被修改过-O FILE：当前有效用户是否为文件属主-G FILE：当前有效用户是否为文件属组Bash的文件测试 存在性测试 -a FILE：同-e-e FILE: 文件存在性测试，存在为真，否则为假存在性及类别测试-b FILE：是否存在且为块设备文件-c FILE：是否存在且为字符设备文件-d FILE：是否存在且为目录文件-f FILE：是否存在且为普通文件-h FILE 或-L FILE：存在且为符号链接文件-p FILE：是否存在且为命名管道文件-S FILE：是否存在且为套接字文件 使用read命令来接受输入使用read来把输入值分配给一个或多个shell变量-p指定要显示的提示-s 静默输入，一般用于密码-n N指定输入的字符长度N-d‘字符’ 输入结束符-t N TIMEOUT为N秒read从标准输入中读取值，给每个单词分配一个变量所有剩余单词都被分配给最后一个变量read -p “Enter a filename:“ FILE bash如何展开命令行把命令行分成单个命令词展开别名展开大括号的声明（{}）展开波浪符声明（~）命令替换$()和）再次把命令行分成命令词展开文件通配（*、?、[abc]等等）准备I/0重导向（&lt;、&gt;）运行命令防止扩展反斜线（\）会使随后的字符按原意解释 $echoYourcost:\$5.00 Yourcost:$5.00加引号来防止扩展单引号（’）防止所有扩展$（美元符号）－变量扩展`（反引号）－命令替换\（反斜线）－禁止单个字符扩展!（叹号）－历史命令替换 Profile类按功能划分，存在两类：profile类和bashrc类profile类：为交互式登录的shell提供配置全局：/etc/profile, /etc/profile.d/*.sh个人：~/.bash_profile功用：(1) 用于定义环境变量(2) 运行命令或脚本Bashrc类bashrc类：为非交互式和交互式登录的shell提供配置全局：/etc/bashrc个人：~/.bashrc功用：(1) 定义命令别名和函数(2) 定义本地变量 locate命令locate KEYWORD有用的选项 -i不区分大小写的搜索-n N只列举前N个匹配项目-r 使用正则表达式示例搜索名称或路径中带有“conf”的文件locate conf使用Regex来搜索以“.conf”结尾的文件locate -r ‘.conf$’ find**练习查找条件指搜索层级-maxdepthlevel 最大搜索目录深度,指定目录为第1级-mindepthlevel 最小搜索目录深度先处理目录内的文件，再处理目录-depth 根据文件名和inode查找： -name “文件名称”：支持使用glob*, ?, [], [^]-iname”文件名称”：不区分字母大小写-inumn 按inode号查找-samefilename 相同inode号的文件-links n 链接数为n的文件-regex“PATTERN”：以PATTERN匹配整个文件路径，而非文件名称 根据属主、属组查找： -user USERNAME：查找属主为指定用户(UID)的文件-group GRPNAME: 查找属组为指定组(GID)的文件-uidUserID：查找属主为指定的UID号的文件-gidGroupID：查找属组为指定的GID号的文件-nouser：查找没有属主的文件-nogroup：查找没有属组的文件 根据文件类型查找： -type TYPE:•f: 普通文件•d: 目录文件•l: 符号链接文件•s：套接字文件•b: 块设备文件•c: 字符设备文件•p: 管道文件空文件或目录-emptyfind /app -type d -empty find示例备份配置文件，添加.orig这个扩展名1find -name “*.conf” -exec cp &#123;&#125; &#123;&#125;.orig\; 提示删除存在时间超过３天以上的joe的临时文件1find/tmp-ctime+3-userjoe-okrm&#123;&#125;\; 在主目录中寻找可被其它用户写入的文件12find ~-perm-002 -execchmodo-w&#123;&#125;\; find /home –type d -ls locate text.sh搜索文件因为是从locate的数据库搜索文件的，速度快不影响服务器性能，适合搜索本来就在内存中的文件，而新建的文件不会马上搜索到，可以输入updatedb更新locate数据库locata +”通配符”搜索文件locata -r “.sh$”搜索以.sh结尾的文件(支持正则表达式)find搜索是实时搜索，在硬盘上搜索，速度慢且影响服务器性能，而且没有权限的文件夹搜索不进去 **（面试常有）find （路径） -name（iname） “text“搜索包含text的文件+i后忽略大小写例子1234567find -name "*.txt" 查找以txt结尾的文件 find -empty 搜索空文件或者空目录 find / -size 10k 搜索9-10k的文件 find / -size -10k 搜索0-10k的文件 find / -size +10k 搜索大于10k的文件 find / -size +5k -size 10k 搜索5-10K的文件 find -name "*.txt" -exec（批量） rm &#123;&#125; \; 查找后缀名为txt的文件并 批量 删除 chmod a+x 文件 给所有人加上此文件的执行权限ll -d 查询当前目录下的权限 处理文本的工具sed **重点sed工具用法：1234567sed [option]... 'script' inputfile... 常用选项： -n不输出模式空间内容到屏幕，即不自动打印 -e多点编辑 -f /PATH/SCRIPT_FILE从指定文件中读取编辑脚本 -r支持使用扩展正则表达式 -i.bak备份文件并原处编辑 script:‘地址命令’地址定界：(1) 不给地址：对全文进行处理(2) 单地址：.#: 指定的行，$：最后一行/pattern/：被此处模式所能够匹配到的每一行(3) 地址范围：.#,#.#,+#/pat1/,/pat2/.#,/pat1/(4) ~：步进 编辑命令：d删除模式空间匹配的行，并立即启用下一轮循环p打印当前模式空间内容，追加到默认输出之后a[\]text在指定行后面追加文本，支持使用\n实现多行追加i[\]text在行前面插入文本c[\]text替换行为单行或多行文本w /path/file保存模式匹配的行至指定文件r /path/file读取指定文件的文本至模式空间中匹配到的行后=为模式空间中的行打印行号!模式空间中匹配行取反处理 SED笔记***练习SED 用法： 不加-i时仅仅是打印到屏幕显示，加-i可以修改文件，一般加-i.bak备份一个.bak文件1234567891011121314151617sed[option]... 'script' inputfile... 常用选项： -n不输出模式空间内容到屏幕，即不自动打印 -e多点编辑 -f /PATH/SCRIPT_FILE从指定文件中读取编辑脚本 -r支持使用扩展正则表达式 -i.bak备份文件并原处编辑 编辑命令： d删除模式空间匹配的行，并立即启用下一轮循环 p打印当前模式空间内容，追加到默认输出之后 a` [\]`text在指定行后面追加文本，支持使用\n实现多行追加 `i[\]`text在行前面插入文本 `c [\]`text替换行为单行或多行文本 w /path/file保存模式匹配的行至指定文件 r /path/file读取指定文件的文本至模式空间中匹配到的行后 =为模式空间中的行打印行号 !模式空间中匹配行取反处理 例子123456789101112sed ‘2p’ /etc/passwd sed –n ‘2p’ /etc/passwd 显示第2行 sed –n ‘1,4p’ /etc/passwd 显示1-4行 sed –n ‘/root/p’ /etc/passwd 显示带有root的行 sed –n ‘2,/root/p’ /etc/passwd 从2行开始 sed -n ‘/^`$`/=’ file 显示空行行号 =代表行号 sed –n –e ‘/^$/p’ –e ‘/^$/=’ file sed –n –r '/^#|^$/d' + file 删除该文件中带#注释和空白的行 sed ‘/root/a\superman’ /etc/passwd行后 sed ‘/root/i\superman’ /etc/passwd行前 sed ‘/root/c\superman’ /etc/passwd代替行 s///查找替换,支持使用其它分隔符，s@@@，s### 替换标记：g行内全局替换p显示替换成功的行w /PATH/FILE将替换成功的行保存至文件中nl 可以显示行号 实例123456789101112sed -n '/^u/p' /data/f1 打印出data下的f1文件中以u开头的行 sed -n '3,9'只显示3-9行 sed -n '/^ftp/,/^lib/' passwd 显示passwd文件中以ftp开头和以lib开头之间的行 sed -n '1~2p' 打印奇数行 sed -n '2~2p' 打印偶数行 sed -i '/^SELINUX=/cSELINUX=disabled' /etc/selinux/config 把config文件中的SELINUX=enforcing改为SELINUX=disabled 禁用selinux sed -n 's/tmpfs/tempfilesystem/g' /etc/fstab 将文件fstab中的tmpfs替换为 tempfilesystem，并且只显示替换结果，s为查找替换，p为只显示替换的那一行 sed -r 's/[[:alpha:]]/\u&amp;/g' +文件 [[:alpha:]]意思为字母，u为大写，&amp;表示搜索到的内容，用u&amp;替换原内容，把所有的字母替换为大写 sed -r 's/[[:alpha:]]/\l&amp;/g' +文件 [[:alpha:]]意思为字母，l为小写，&amp;表示搜索到的内容，用u&amp;替换原内容，把所有的字母替换为小写 sed -r 's/^[^#]/#&amp;' +文件 将文件中不是#开头的行加上#并显示，其中&amp;代表被搜索出来的内容，等于用#&amp;替换了原来的内容，加-i可以直接修改 .............................（重点） sed -nr '/.*CMDLINE_LINUX.*/s#(.*)"#\1 net.ifnames=0"#p' /etc/default/grub 在带有CMDLINE_LINUX的一行后加上net.ifnames=0 仅在7系统需要修改 ......................修改 s///查找替换,支持使用其它分隔符，s@@@，s### 替换标记：g行内全局替换p显示替换成功的行w /PATH/FILE将替换成功的行保存至文件中]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理及正则表达式]]></title>
    <url>%2F2018%2F09%2F30%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%8F%8A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[文本处理及正则表达式文件查看文件查看命令：cat，tac，revcat [OPTION]… [FILE]…123456cat-E：显示行结束符$ -n：对显示出的每一行进行编号 -A：显示所有控制符 -b：非空行编号 -s：压缩连续的空行成一行 tac 与cat相反rev文件查看more: 分页查看文件123more [OPTIONS...] FILE... -d: 显示翻页及退出提示 less：一页一页地查看文件或STDIN输出 查看时有用的命令包括：/文本搜索文本n/N跳到下一个或上一个匹配less命令是man命令使用的分页器 显示文本前或后行内容***(重点)head [OPTION]… [FILE]…123456789101112head-c #: 指定获取前#字节 -n #: 指定获取前#行 -#：指定行数 tail [OPTION]... [FILE]... -c #: 指定获取后#字节 -n #: 指定获取后#行 -#：同上 -f: 跟踪显示文件fd新追加的内容,常用日志监控 相当于--follow=descriptor -F: 跟踪文件名，相当于--follow=name --retry tailf类似tail –f，当文件不增长时并不访问文件 按列抽取文本cut和合并文件paste*CUTcut [OPTION]… [FILE]…123456cut-d DELIMITER: 指明分隔符，默认tab -f FILEDS: #: 第#个字段 #,#[,#]：离散的多个字段，例如1,3,6 #-#：连续的多个字段, 例如1-6 混合使用：1-3,7-c按字符切割–output-delimiter=STRING指定输出分隔符cut和paste显示文件或STDIN数据的指定列123cut -d:-f1 /etc/passwd cat /etc/passwd|cut -d: -f7 cut -c2-5/usr/share/dict/words paste 合并两个文件同行号的列到一行123456paste [OPTION]... [FILE]... -d 分隔符：指定分隔符，默认用TAB -s : 所有行合成一行显示 示例： paste f1 f2 paste -s f1 f2 收集文本统计数据wc*WC计数单词总数、行总数、字节总数和字符总数可以对文件或STDIN中的数据运行wcstory.txt392371901story.txt行数字数字节数常用选项123456wc-l 只计数行数 -w 只计数单词总数 -c 只计数字节总数 -m 只计数字符总数 -L 显示文件中最长行的长度 文本排序sort把整理过的文本显示在STDOUT，不改变原始文件sort[options]file(s)常用选项12345678sort-r执行反方向（由上至下）整理-R随机排序 -n执行按数字大小整理 -f选项忽略（fold）字符串中的字符大小写 -u选项（独特，unique）删除输出中的重复行 -t c选项使用c做为字段界定符 -k X选项按照使用c字符分隔的X列来整理能够使用多次 uniquniq命令：从输入中删除前后相接的重复的行uniq[OPTION]… [FILE]…1234567uniq-c: 显示每行重复出现的次数 -d: 仅显示重复过的行 -u: 仅显示不曾重复的行 注：连续且完全相同方为重复 常和sort 命令一起配合使用： sort userlist.txt | uniq -c 比较文件比较两个文件之间的区别1234difffoo.conffoo2.conf 5c5 &lt; use_widgets=no&gt;use_widgets=yes #注明第5行有区别（改变） 取出IP地址的几种方法**（重点）1234567ifconfig | sed -r '2!d;s/.*inet (addr:)?//;s/ .*//' #6和7通用的取出IP地址 ifconfig eth0 | head -2|tail -1| tr -dc '[0-9]. ' |tr -s ' ' |cut -d" " -f2 #centos6系统上 ifconfig eth0|sed -n '2p'|sed 's@.*inet @@'|sed 's@ netmask.$@@' #提取出7上的IP地址，其中@@为分隔符 ifconfig ens33|sed -nr '2s/.*t (.*) net.*/\1/gp' #扩展的正则表达式取出IP，（）为分组，只有一个括号，所以后面写1 ifconfig ens33|sed -nr '2s/（.*t) (.*)( net.*)/\2/gp' #扩展的正则表达式取出IP，（）为分组，有三个括号，所以后面写2留第二个 ifconfig | sed -nr "s/.inet (.*) netmask.*/\1/p" | head -n 1 #取出7的IP ifconfig | sed -nr "s/.inet (.*) netmask.*/\1/p" #取出7的三个网卡IP 查询系统信息 *重点1234567891011#RED is content color RED="\033[1;31m" COLOREND="\033[0m" echo -e "OS version is $RED`cat /etc/centos-release`$COLOREND" #显示系统版本 echo -e "kernel version $RED`uname -r`$COLOREND" #显示内核版本 echo -e "The cpu type is $RED`lscpu |egrep -i 'model name'|tr -s ' '|cut -d: -f2`$COLOREND" #显示CPU型号 echo -e "The memory is $RED`free -h|egrep Mem|tr -s ' ' ':' |cut -d: -f2`$COLOREND" #取出内存大小 echo -e "The max disk used is $RED`df |grep /dev/sd|tr -s " " ":"|cut -d: -f5|sort -nr|head -1`$COLOREND" #取出最大磁盘利用率echo -e "The hostname is $RED$(hostname)$COLOREND" #取出hostname echo -e "The ipaddr is $RED`ifconfig|head -2|tail -1|tr -s " " ":"|cut -d: -f3`$COLOREND" #取出IP地址unset RED COLOREND #不使用颜色 Linux文本处理三剑客 grep：文本过滤(模式：pattern)工具grep, egrep, fgrep（不支持正则表达式搜索）sed：stream editor，文本编辑工具awk：Linux上的实现gawk，文本报告生成器 grep**(重点)grep: Global search REgularexpression and Print out the line作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行模式：由正则表达式字符及文本字符所编写的过滤条件12345grep [OPTIONS] PATTERN [FILE...] grep root /etc/passwd grep "$USER" /etc/passwd grep '$USER' /etc/passwd grep `whoami` /etc/passwd grep命令选项1234567891011121314151617grep--color=auto: 对匹配到的文本着色显示 -v: 显示不被pattern匹配到的行 -i: 忽略字符大小写 -n：显示匹配的行号 -c: 统计匹配的行数 -o: 仅显示匹配到的字符串 -q: 静默模式，不输出任何信息 -A #: after, 后#行 -B #: before, 前#行 -C #：context, 前后各#行 -e：实现多个选项间的逻辑or关系 grep –e ‘cat ’ -e ‘dog’ file -w：匹配整个单词 -E：使用ERE -F：相当于fgrep，不支持正则表达式 -ffile: 根据模式文件处理 正则表达式*重点REGEXP：Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能程序支持：grep,sed,awk,vim, less,nginx,varnish等分两类：基本正则表达式：BRE扩展正则表达式：EREgrep -E, egrep正则表达式引擎：采用不同算法，检查处理正则表达式的软件模块PCRE（Perl Compatible Regular Expressions）元字符分类：字符匹配、匹配次数、位置锚定、分组man 7 regex 基本正则表达式元字符字符匹配: . 匹配任意单个字符[] 匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z][^] 匹配指定范围外的任意单个字符[:alnum:] 字母和数字[:alpha:] 代表任何英文大小写字符，亦即A-Z, a-z[:lower:] 小写字母[:upper:] 大写字母[:blank:] 空白字符（空格和制表符）[:space:]水平和垂直的空白字符（比[:blank:]包含的范围广）[:cntrl:] 不可打印的控制字符（退格、删除、警铃…）[:digit:] 十进制数字[:xdigit:]十六进制数字[:graph:] 可打印的非空白字符[:print:] 可打印字符[:punct:] 标点符号 通配符是通配的文件名正则表达式是配的字符串，文件的内容【wang】 匹配这四个字符其中的一个123grep "[123]" /etc/passwd #查询passwd文件夹里包含123中一个数字的文件 grep -v "[123]" /etc/passwd #查询passwd文件夹里不包含123中一个数字的文件 grep "[^123]" /etc/passwd #查询passwd文件夹里除了123中一个数字的文件 匹配次数：用在要指定次数的字符后面，用于指定前面的字符要出现的次数123456789* 匹配前面的字符任意次，包括0次 贪婪模式：尽可能长的匹配 .*任意长度的任意字符 \?匹配其前面的字符0或1次 \+匹配其前面的字符至少1次 \&#123;n\&#125;匹配前面的字符n次 \&#123;m,n\&#125;匹配前面的字符至少m次，至多n次 \&#123;,n\&#125;匹配前面的字符至多n次 \&#123;n,\&#125;匹配前面的字符至少n次 位置锚定：定位出现的位置^ 行首锚定，用于模式的最左侧 grep “^bash” /etc/passwd$ 行尾锚定，用于模式的最右侧 grep “bash$” /etc/passwd^PATTERN$ 用于模式匹配整行^$ 空行^[[:space:]]$ 空白行\&lt; 或\b词首锚定，用于单词模式的左侧(单词不能包含数字、_、其他字母开头)> 或\b词尾锚定，用于单词模式的右侧\&lt;PATTERN>匹配整个单词** 正则表达式分组：() 将一个或多个字符捆绑在一起，当作一个整体处理，如：(root)+分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为: \1, \2, \3, …\1表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符示例：(string1+(string2))\1 ：string1+(string2)\2 ：string2后向引用：引用前面的分组括号中的模式所匹配字符，而非模式本身或者：|示例：a|b: a或b C|cat: C或cat (C|c)at:Cat或cat元字符 ^ 行首$行尾.任意单一字符[][]内任意单一字符[^]除[]内任意单一字符*前面字符重复不确定次数++前面字符重复一次以上不确定次数\?？前面字符重复0或1次\转义符.任意长度字符{n}前面字符重复n次{n,}前面字符重复n次以上{m,n}前面字符重复m次和n次之间[:alnum:]字母和数字[:alpha:]代表任何英文大小写字符，亦即A-Z, a-z[:lower:]小写字母[:upper:]大写字母[:blank:]水平空白字符（空格和制表符）[:space:]所有水平和垂直的空白字符（比[:blank:]包含的范围广）[:cntrl:]不可打印的控制字符（退格、删除、警铃…）[:digit:]十进制数字[:graph:]可打印的非空白字符[:print:]可打印字符[:punct:]标点符号[:xdigit:]十六进制数字 egrep及扩展的正则表达式egrep= grep -Eegrep[OPTIONS] PATTERN [FILE…]扩展正则表达式的元字符：字符匹配： . 任意单个字符[] 指定范围的字符[^] 不在指定范围的字符次数匹配：*匹配前面字符任意次?0或1次+1次或多次{m}匹配m次{m,n}至少m，至多n次位置锚定：^行首$行尾\&lt;, \b语首>, \b语尾分组：()后向引用：\1, \2, …或者：a|ba或bC|catC或cat(C|c)atCat或cat vim简介*重点见PDF6中第32，68，69页图片vi: Visual Interface，文本编辑器文本：ASCII, Unicode文本编辑种类：行编辑器: sed全屏编辑器：nano, vivim-Vi Improved其他编辑器：gedit一个简单的图形编辑器gvim一个Vim编辑器的图形版本 打开文件1234567891011121314151617vim [OPTION]... FILE... +#打开文件后，让光标处于第#行的行首，+默认行尾 +/PATTERN打开文件后，直接让光标处于第一个被PATTERN匹配到的行的行首 –b file 二进制方式打开文件 –d file1 file2… 比较多个文件 -m file 只读打开文件 ex file 或vim –e 直接进入ex模式 如果该文件存在，文件被打开并显示内容 如果该文件不存在，当编辑后第一次存盘时创建它 模式转换 命令模式--&gt; 插入模式 iinsert, 在光标所在处输入 I在当前光标所在行的行首输入 aappend, 在光标所在处后面输入 A在当前光标所在行的行尾输入 o在当前光标所在行的下方打开一个新行 O在当前光标所在行的上方打开一个新行 VIM模式的切换插入模式——–&gt; 命令模式ESC命令模式——–&gt; 扩展命令模式:扩展命令模式——–&gt; 命令模式ESC,enter 扩展命令模式： :q退出:q!强制退出，丢弃做出的修改:wq保存退出:x保存退出命令模式ZZ保存退出ZQ不保存退出命令模式光标跳转字符间跳转：h: 左l: 右j: 下k: 上.#COMMAND：跳转由#指定的个数的字符** 单词间跳转： w：下一个单词的词首e：当前或下一单词的词尾b：当前或前一个单词的词首。#COMMAND：由#指定一次跳转的单词数当前页跳转：H：页首M：页中间行L:页底zt：将光标所在当前行移到屏幕顶端zz：将光标所在当前行移到屏幕中间zb：将光标所在当前行移到屏幕底端行首行尾跳转：^: 跳转至行首的第一个非空白字符0: 跳转至行首$: 跳转至行尾行间移动：.#G、扩展命令模式下：# 跳转至由#指定行G：最后一行1G, gg: 第一行句间移动：)：下一句(：上一句段落间移动：}:下一段{：上一段命令模式翻屏操作Ctrl+f: 向文件尾部翻一屏Ctrl+b: 向文件首部翻一屏Ctrl+d: 向文件尾部翻半屏Ctrl+u：向文件首部翻半屏 命令模式操作**重点123456789101112131415161718192021222324删除命令： d: 删除命令，可结合光标跳转字符，实现范围删除 d`$`: 删除到行尾 d^:删除到非空行首 d0:删除到行首 dw: de: db: .#COMMAND dd: 删除光标所在的行 .#dd：多行删除 D：从当前光标位置一直删除到行尾，等同于d$ 复制命令(y, yank)： y: 复制，行为相似于d命令y$ y0 y^ ye yw yb .#COMMAND yy：复制行 .#yy: 复制多行 Y: 复制整行 命令模式123456di" 光标在”“之间，则删除”“之间的内容 yi( 光标在()之间，则复制()之间的内容 vi[ 光标在[]之间，则选中[]之间的内容 dtx删除字符直到遇见光标之后的第一个x 字符 ytx复制字符直到遇见光标之后的第一个x 字符 扩展命令模式：地址定界********************按ESC进入命令模式，再按：进入扩展命令模式 ###地址定界 :start_pos,end_pos# 具体第#行，例如2表示第2行#,# 从左侧#表示起始行，到右侧#表示结尾行#,+# 从左侧#表示的起始行，加上右侧#表示的行数 ：2,+3 表示2到5行 . 当前行$最后一行 .,$`-1 当前行到倒数第二行% 全文, 相当于1,$/pat1/,/pat2/从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束 #,/pat//pat/,$使用方式：后跟一个编辑命令dyw file: 将范围内的行另存至指定文件中r file：在指定位置插入指定文件中的所有内容/PATTERN：从当前光标所在处向文件尾部查找?PATTERN：从当前光标所在处向文件首部查找n：与命令同方向N：与命令反方向 s: 在扩展模式下完成查找替换操作**重点格式：s/要查找的内容/替换为的内容/修饰符要查找的内容：可使用模式替换为的内容：不能使用模式，但可以使用\1, \2, …等后向引用符号；还可以使用“&amp;”引用前面查找时查找到的整个内容修饰符：1234567s/要查找的内容/替换为的内容/修饰符 i: 忽略大小写 g: 全局替换；默认情况下，每一行只替换第一次出现 gc:全局替换，每次替换前询问 查找替换中的分隔符/可替换为其它字符，例如 s@/etc@/var@g s#/boot#/#i 命令模式：撤消更改u撤销最近的更改 #u撤销之前多次更改U撤消光标落在这行后所有此行的更改按Ctrl-r重做最后的“撤消”更改. 重复前一个操作n.重复前一个操作n次多文件模式12345678vim FILE1 FILE2 FILE3 ... :next 下一个 :prev前一个 :first 第一个 :last 最后一个 :wall 保存所有 :qall退出所有 :wqall 定制vim的工作特性配置文件：永久有效全局：/etc/vimrc*个人：~/.vimrc扩展模式：当前vim进程有效 (1) 行号显示：set number, 简写为set nu取消显示：set nonumber, 简写为set nonu**(2) 忽略字符的大小写启用：set ic不忽略：set noic(3) 自动缩进启用：set ai禁用：set noai(4) 智能缩进启用：smartindent简写set si禁用：set nosi(5) 高亮搜索启用：set hlsearch禁用：set nohlsearch(6) 语法高亮启用：syntax on禁用：syntax off(7) 显示Tab和换行符^I 和$显示启用：set list禁用：set nolist(8) 文件格式启用windows格式：set fileformat=dos启用unix格式：set fileformat=unix简写：set ff=dos|unix(9) 设置文本宽度set textwidth=65 (vimonly)set wrapmargin=15(10) 设置光标所在行的标识线启用：set cursorline，简写cul禁用：set no cursorline(11) 复制保留格式启用：set paste禁用：set nopaste]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户、组和权限]]></title>
    <url>%2F2018%2F09%2F29%2F%E7%94%A8%E6%88%B7%E3%80%81%E7%BB%84%E5%92%8C%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[用户、组和权限用户和组的配置文件Linux用户和组的主要配置文件： /etc/passwd：用户及其属性信息(名称、UID、主组ID等）/etc/group：组及其属性信息/etc/shadow：用户密码及其相关属性/etc/gshadow：组密码及其相关属性 passwd文件格式 login name：登录用名（luhao）passwd：密码(x)UID：用户身份编号(1000)GID：登录默认所在组编号(1000)GECOS：用户全名或注释home directory：用户主目录(/home/luhao)shell：用户默认使用shell (/bin/bash) shadow文件格式登录用名用户密码:一般用sha512加密从1970年1月1日起到密码最近一次被更改的时间密码再过几天可以被变更（0表示随时可被变更）密码再过几天必须被变更（99999表示永不过期）密码过期前几天系统提醒用户（默认为一周）密码过期几天后帐号会被锁定从1970年1月1日算起，多少天后帐号失效 用户创建：useradduseradd[options] LOGIN123456789101112useradd-u UID -o 配合-u 选项，不检查UID的唯一性 -g GID：指明用户所属基本组，可为组名，也可以GID -c &apos;COMMENT&apos;：用户的注释信息 -d HOME_DIR: 以指定的路径(不存在)为家目录 -s SHELL: 指明用户的默认shell程序，可用列表在/etc/shells文件中 -G GROUP1[,GROUP2,...]：为用户指明附加组，组须事先存在 -N 不创建私用组做主组，使用users组做主组 -r: 创建系统用户CentOS 6: ID&lt;500，CentOS 7: ID&lt;1000 -m 创建家目录，用于系统用户 -M 不创建家目录，用于非系统用户 新建用户的相关文件和命令 /etc/default/useradd/etc/skel/*/etc/login.defsnewusers passwd格式文件批量创建用户chpasswd 批量修改用户口令 用户属性修改usermod[OPTION] login1234567891011121314usermod-u UID: 新UID -g GID: 新主组 -G GROUP1[,GROUP2,...[,GROUPN]]]：新附加组，原来的附加组将会被覆盖；若保留原有，则要同时使用-a选项 -s SHELL：新的默认SHELL -c COMMENT：新的注释信息 -d HOME: 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项 -l login_name: 新的名字； -L: lock指定用户,在/etc/shadow 密码栏的增加! -U: unlock指定用户,将/etc/shadow 密码栏的! 拿掉 -e YYYY-MM-DD: 指明用户账号过期日期 -f INACTIVE: 设定非活动期限 userdel[OPTION]... login 删除用户 -r 删除用户家目录 查看用户相关的ID信息12345id [OPTION]... [USER] -u: 显示UID -g: 显示GID -G: 显示用户所属的组的ID -n: 显示名称，需配合ugG使用 切换用户或以其他用户身份执行命令su[options…] [-] [user [args…]]切换用户的方式： suUserName：非登录式切换，即不会读取目标用户的配置文件，不改变当前工作目录su-UserName：登录式切换，会读取目标用户的配置文件，切换至家目录，完全切换root su至其他用户无须密码；非root用户切换时需要密码换个身份执行命令：su[-] UserName-c ‘COMMAND’选项：-l –loginsu-l UserName相当于su-UserName 设置密码passwd[OPTIONS] UserName: 修改指定用户的密码常用选项：123456789101112passwd-d：删除指定用户密码 -l：锁定指定用户 -u：解锁指定用户 -e：强制用户下次登录修改密码 -f：强制操作 -n mindays：指定最短使用期限 -x maxdays：最大使用期限 -w warndays：提前多少天开始警告 -iinactivedays：非活动期限 --stdin：从标准输入接收用户密码 echo &apos;PASSWORD&apos; | passwd--stdinUSERNAME 修改用户密码策略12345678chage[OPTION]... LOGIN -d LAST_DAY -E --expiredateEXPIRE_DATE -I --inactive INACTIVE -m --mindaysMIN_DAYS -M --maxdaysMAX_DAYS -W --warndaysWARN_DAYS –l 显示密码策略 示例：123chage-d 0 tom #让tom下一次登录强制重设密码 chage-m 0 –M 42 –W 14 –I 7 tom 让tom多少天之后重设密码chage-E 2016-09-10 tom #让tom在2016-09-10重设密码 创建组groupadd[OPTION]… group_name123groupadd-g GID: 指明GID号；[GID_MIN, GID_MAX] -r: 创建系统组 系统组ID范围CentOS 6: ID&lt;500CentOS 7: ID&lt;1000修改和删除组组属性修改groupmod[OPTION]… group123groupmod -n group_name: 新名字 -g GID: 新的GID 组删除12groupdel groupdelGROUP 更改组密码组密码：gpasswdgpasswd[OPTION] GROUP-a user 将user添加至指定组中-d user 从指定组中移除用户user-A user1,user2,… 设置有管理权限的用户列表newgrp命令：临时切换主组如果用户本不属于此组，则需要组密码 更改和查看组成员groupmems[options] [action]12345678groupmems -g, --group groupname更改为指定组(只有root) Actions: -a, --add username 指定用户加入组 -d, --delete username 从组中删除用户 -p, --purge 从组中清除所有成员 -l, --list 显示组成员列表 groups [OPTION].[USERNAME]... 查看用户所属组列表 修改文件的属主和属组 修改文件的属主：chownchown[OPTION]… [OWNER][:[GROUP]] FILE…用法：chownOWNEROWNER:GROUPGROUP命令中的冒号可用.替换-R: 递归chown[OPTION]… –reference=RFILE FILE…修改文件的属组：chgrpchgrp[OPTION]… GROUP FILE…chgrp[OPTION]… –reference=RFILE FILE…-R 递归 文件权限文件的权限主要针对三类对象进行定义owner: 属主, ugroup: 属组, gother: 其他, o每个文件针对每类访问者都定义了三种权限r: Readablew: Writablex: eXcutable 修改文件权限 ***重点chmod[OPTION]… OCTAL-MODE FILE…-R: 递归修改权限chmod[OPTION]… MODE[,MODE]… FILE…MODE：修改一类用户的所有权限：u= g= o= ug= a= u=,g=修改一类用户某位或某些位权限u+ u-g+ g-o+ o-a+ a-+ -chmod[OPTION]… –reference=RFILE FILE…参考RFILE文件的权限，将FILE的修改为同RFILE 新建文件和目录的默认权限umask值可以用来保留在创建文件权限新建FILE权限: 666-umask如果所得结果某位存在执行（奇数）权限，则将其权限+1新建DIR权限: 777-umask非特权用户umask是002root的umask是022umask: 查看umask#: 设定umask002umask–S 模式方式显示umask–p 输出可被调用全局设置：/etc/bashrc用户设置：~/.bashrc 可执行文件上SUID权限任何一个可执行程序文件能不能启动为进程：取决发起者对程序文件是否拥有执行权限启动为进程之后，其进程的属主为原程序文件的属主SUID只对二进制可执行程序有效SUID设置在目录上无意义权限设定：1234chmodu+sFILE... chmodu-s FILE... chmodg+sDIR... chmodg-s DIR... Sticky 位具有写权限的目录通常用户可以删除该目录中的任何文件，无论该文件的权限或拥有权在目录设置Sticky 位，只有文件的所有者或root可以删除该文件sticky 设置在文件上无意义权限设定：chmodo+tDIR…chmodo-t DIR… 访问控制列表***重点ACL：Access Control List，实现灵活的权限管理除了文件的所有者，所属组和其它人，可以对更多的用户设置权限CentOS7默认创建的xfs和ext4文件系统具有ACL功能CentOS7之前版本，默认手工创建的ext4文件系统无ACL功能,需手动增加tune2fs –o acl/dev/sdb1mount –o acl/dev/sdb1 /mnt/testACL生效顺序：所有者，自定义用户，自定义组，其他人 为多用户或者组的文件和目录赋予访问权限rwx123456789mount -o acl/directory getfaclfile |directory setfacl-m u:wang:rwx file|directory setfacl-Rm g:sales:rwX directory setfacl-M file.aclfile|directory setfacl-m g:salesgroup:rw file| directory setfacl-m d:u:wang:rx directory setfacl-x u:wang file |directory setfacl-X file.acldirectory group权限ACL文件上的group权限是mask 值（自定义用户，自定义组，拥有组的最大权限）,而非传统的组权限123456getfacl可看到特殊权限：flags 通过ACL赋予目录默认x权限，目录内文件也不会继承x权限 base ACL 不能删除 setfacl-k dir 删除默认ACL权限 setfacl–b file1清除所有ACL权限 getfaclfile1 | setfacl--set-file=-file2 复制file1的acl权限给file2 mask只影响除所有者和other的之外的人和组的最大权限Mask需要与用户的权限进行逻辑与运算后，才能变成有限的权限(Effective Permission)用户或组的设置必须存在于mask权限设定范围内才会生效setfacl-m mask::rxfile–set选项会把原有的ACL项都删除，用新的替代，需要注意的是一定要包含UGO的设置，不能象-m一样只是添加ACL就可以示例：setfacl –set u::rw,u:wang:rw,g::r,o::-file1 备份和恢ACL**重点主要的文件操作命令cp和mv都支持ACL，只是cp命令需要加上-p 参数。但是tar等常见的备份工具是不会保留目录和文件的ACL信息12345getfacl-R /tmp/dir1 &gt; acl.txt setfacl -R -b /tmp/dir1 setfacl-R --set-file=acl.txt/tmp/dir1 setfacl--restore acl.txt getfacl -R /tmp/dir1]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[epel源安装（Centos6.10和Centos7.5）]]></title>
    <url>%2F2018%2F09%2F28%2Fepel%E6%BA%90%E5%AE%89%E8%A3%85%EF%BC%88Centos6.10%E5%92%8CCentos7.5%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Centos6.10123456rpm -e epel-release #首先卸载以前装的epel 以免影响wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-6.repo #下载阿里提供的epelyum clean all #清理缓存yum makecache #生成缓存rm -rf /etc/yum.repos.d/* # 删除原来的epel源配置wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-6.repo http://mirrors.aliyun.com/repo/Centos-6.repo # 修改为阿里云的源 Centos7.5123456rpm -e epel-release #首先卸载以前装的epel 以免影响wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo #下载阿里提供的epelyum clean all #清理缓存yum makecache #生成缓存rm -rf /etc/yum.repos.d/* #删除原来的epel源配置wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo http://mirrors.aliyun.com/repo/Centos-7.repo 修改为阿里云的源]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件包管理]]></title>
    <url>%2F2018%2F09%2F27%2F%E8%BD%AF%E4%BB%B6%E5%8C%85%E5%8F%8Ayum%E4%BB%93%E5%BA%93%E5%BB%BA%E8%AE%BE%2F</url>
    <content type="text"><![CDATA[软件包管理程序包的来源获取程序包的途径：(1) 系统发版的光盘或官方的服务器CentOS镜像：https://www.centos.org/download/http://mirrors.aliyun.comhttp://mirrors.sohu.comhttp://mirrors.163.com(2) 项目官方站点(3) 第三方组织：Fedora-EPEL：Extra Packages for Enterprise LinuxRpmforge:RHEL推荐，包很全搜索引擎：http://pkgs.orghttp://rpmfind.nethttp://rpm.pbone.nethttps://sourceforge.net/(4) 自己制作注意：第三方包建议要检查其合法性来源合法性,程序包的完整性1234567891011[install-options]--test: 测试安装，但不真正执行安装，即dry run模式--nodeps：忽略依赖关系--replacepkgs| replacefiles--nosignature: 不检查来源合法性--nodigest：不检查包完整性--noscripts：不执行程序包脚本%pre: 安装前脚本--nopre%post: 安装后脚本--nopost%preun: 卸载前脚本--nopreun%postun: 卸载后脚本--nopostun 救援模式进入getent +命令或者文件或者用户 看是否存在例子 getent f1.txt 看f1是否存在12345678910rpm -qpi 查询还未安装的包内的文件rpm -qi 查询包的说信息rpm -q +命令名字 查询命令版本号 rpm -ql +tree 查询tree包里有什么文件rpm -q tree &amp;&gt; /dev/null ||rpm -ivh /cdrom/Package/tree-1.6.0-10.el7.x86_64.rpm 查询tree软件是否安装，如果没有安装则安装文件 rpm -e +软件名 卸载该软件rpm -upgrade 升级，一般情况下不用升级，直接卸载老版本安装新版本rpm --oldpackage 降级rpm -ivh +软件 + --force 强制安装 rpm -qa | wc -l 查询有多少个包 包校验 包来源合法性验正及完整性验证完整性验证：SHA256来源合法性验证：RSA公钥加密对称加密：加密、解密使用同一密钥非对称加密：密钥是成对儿的public key: 公钥，公开所有人secret key: 私钥, 不能公开导入所需要公钥1234rpm -K|checksigrpmfile检查包的完整性和签名rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7CentOS 7发行版光盘提供：RPM-GPG-KEY-CentOS-7rpm -qa“gpg-pubkey*” 查询CentOS-7的完整性和签名123cat /misc/cd/RPM-GPG-KEY-CentOS-7 获取centos7公钥rpm --import /misc/cd/RPM-GPG-KEY-CentOS-7 导入公钥到系统rpm -K +软件包 显示出pgp md5 ok 查询完整性和签名 YUM常用命令12yum install remove list info search groupinstall grouplist groupremove history yum clean all yum serveryum repo 仓库包含*.rpm 包和 matadata 源数据（.rpm包需要的数据）安装文件 yum install +包的名字，不用补全 yum仓库建设**基于httpd服务的客户端仓库新建一台虚拟机作为仓库进入虚拟机输入1234567891011121314151617cd /etc/yum.repo.d/df #查询光盘挂载位置ls /misc/ls /misc/cd #触发光盘挂载到/misc/cd(神奇目录)df mkdir bak mv *.repo bak/ 备份原来的repols 然后看文件夹repodata在哪个目录，就将其所在的目录作为repo的路径ls /misc/cd 看到repodata在这个路径，就将/misc/cd作为repo的路径vim base.repo写入[base]name=aliyun 或者bendiyuan 名字随便baseurl=file:///misc/cd/ (http:// https:// ftp:// file://)网络源用http，（如阿里 https://mirrors.aliyun.com/centos/7/os/x86_64/）（6.7通用版本阿里源https://mirrors.aliyun.com/centos/$releasever/$basearch ）本地源用file (******$releasever/$basearch***********$代表系统版本和架构）gpgcheck=0 忽略完整性检查wq保存repo本地包 yum仓库建设***基于httpd服务的服务器仓库1234567891011121314151617181920212223242526272829yum install httpdcd /var/www/htmlyum -ql httpd|grep servicesystemctl start httpd #浏览器输入虚拟机IP地址测试服务器是否运行 http://192.168.221.129/pwd 查询是否在/var/www/htmlecho 浩哥在此！ &gt; index.html # http://192.168.221.129/ https://mirrors.tuna.tsinghua.edu.cn/centos/7/os/x86_64/ #使用清华源镜像/var/www/html/var/www/html/centos/7/os/x86_64//var/www/html/centos/6/os/x86_64/mkdir -pv centos/&#123;6,7&#125;/os/x86_64/ #创建目录 #在浏览器输入http://192.168.221.129/centos/ 即可看到和清华源镜像一样的目录结构mount /dev/sr0 /var/www/html/centos/7/os/x86_64/进入http://192.168.221.129/centos/7/os/x86_64/ #可看到光盘镜像已上传vim /etc/yum.repos.d/base.repo写入[base]name=centosbaseurl=file:///misc/cd/#baseurl=http://192.168.221.129/centos/7/os/x86_6 IP地址非固定gpgcheck=0[epel]name=EPELbaseurl=https://mirrors.aliyun.com/centos/$releasever/$basearchlgpgcheck=0enabled=0输入wq保存yum repolistyum clean allsystemctl start httpd 启动服务 yum remove + 安装包的名称 卸载包yum repolist 列出仓库列表yum grouplist 查询包组常用包组Development toolsyum groupinstall “Development tools”安装包组卸载多余网卡]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统及文件权限]]></title>
    <url>%2F2018%2F09%2F26%2F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8F%8A%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[文件系统及文件权限命令帮助–help和-h选项显示用法总结和参数列表使用的大多数，但并非所有的示例： date–helpUsage:date[OPTION]…[+FORMAT]or: date[-u|–utc|–universal][MMDDhhmm[[CC]YY][.ss]][]表示可选项CAPS或&lt;&gt;表示变化的数据…表示一个列表x |y| z的意思是“x或y或z“-abc的意思是-a -b –c{ } 表示分组 man命令man命令的操作方法：1234567891011使用less命令实现 space, ^v, ^f, ^F: 向文件尾翻屏 b, ^b: 向文件首部翻屏 d, ^d: 向文件尾部翻半屏 u, ^u: 向文件首部翻半屏 RETURN, ^N, e, ^E or j or ^J: 向文件尾部翻一行 y or ^Y or ^P or k or ^K：向文件首部翻一行 q: 退出 #：跳转至第#行 1G: 回到文件首部 G：翻至文件尾部 man搜索/KEYWORD:以KEYWORD指定的字符串为关键字，从当前位置向文件尾部搜索；不区分字符大小写；n: 下一个N：上一个KEYWORD:以KEYWORD指定的字符串为关键字，从当前位置向文件首部搜索；不区分字符大小写；n: 跟搜索命令同方向，下一个N：跟搜索命令反方向，上一个 infoman常用于命令参考，GNU工具info适合通用文档参考没有参数,列出所有的页面info 页面的结构就像一个网站每一页分为“节点”链接节点之前*info [命令]方向键，PgUp，PgDn导航Tab键移动到下一个链接d 显示主题目录Home 显示主题首部Enter进入选定链接n/p/u/l进入下/前/上一层/最后一个链接s文字文本搜索q退出info 文件系统文件名规则 boot 文件夹装的是引导文件etc文件夹装的是各种设置，配置文件等，等价于注册表home文件夹存放用户数据bin（binary）二进制，装的是普通用户可执行的二进制程序sbin是系统管理员常用的工具，tem文件夹装的是临时数据var文件夹装的是可变内容，系统日志（/var/log内）等proc（process）进程，正在内存中运行的程序，该文件夹不在硬盘上mount /dev/硬盘号/ 挂载硬盘 文件命名Linux系统对大小写不敏感，常用的Linux文件系统（xfs；ext4）对大小写敏感而Linux系统识别fat文件格式时对大小写不敏感文件名最长255个字节包括路径在内文件名称最长4095个字节蓝色–&gt;目录绿色–&gt;可执行文件红色–&gt;压缩文件浅蓝色–&gt;链接文件灰色–&gt;其他文件除了斜杠和NUL,所有字符都有效.但使用特殊字符的目录名和文件不推荐使用，有些字符需要用引号来引用它们标准Linux文件系统（如ext4），文件名称大小写敏感例如：MAIL,Mail,mail, mAiL 文件系统结构 /boot：引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录/bin：供所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序/sbin：管理类的基本命令；不能关联至独立分区，OS启动即会用到的程序/lib：启动时程序依赖的基本共享库文件以及内核模块文件(/lib/modules)/lib64：专用于x86_64系统上的辅助共享库文件存放位置/etc：配置文件目录/home/USERNAME：普通用户家目录/root：管理员的家目录/media：便携式移动设备挂载点/mnt：临时文件系统挂载点/dev：设备文件及特殊文件存储位置b: block device，随机访问c: character device，线性访问/opt：第三方应用程序的安装位置/srv：系统上运行的服务用到的数据/tmp：临时文件存储位置/usr: universal shared, read-only databin: 保证系统拥有完整功能而提供的应用程序sbin:lib：32位使用lib64：只存在64位系统include: C程序的头文件(header files)share：结构化独立的数据，例如doc, man等local：第三方应用程序的安装位置bin, sbin, lib, lib64, etc, share/var: variable data filescache: 应用程序缓存数据目录lib: 应用程序状态信息数据local：专用于为/usr/local下的应用程序存储可变数据；lock: 锁文件log: 日志目录及文件opt: 专用于为/opt下的应用程序存储可变数据；run: 运行中的进程相关数据,通常用于存储进程pid文件spool: 应用程序数据池tmp: 保存系统两次重启之间产生的临时数据/proc: 用于输出内核与进程信息相关的虚拟文件系统/sys：用于输出当前系统上硬件设备相关信息虚拟文件系统/selinux: security enhanced Linux，selinux相关的安全策略等信息的存储位置 本节笔记 ls -R 列出当前文件夹的目录及子目录（所以文件和目录）ls -r 反转顺序文件有三个时间属性，修改时间mtime（modify time）读取时间atime（access time）ll –time=atime 查询文件读取的时间元数据的更改时间 ctime （change time）stat +文件名 查询文件的三个时间 绝对和相对路径 （重点） 绝对路径：以正斜杠开始完整的文件的位置路径可用于任何想指定一个文件名的时候相对路径名不以斜线开始指定相对于当前工作目录或某目录的位置可以作为一个简短的形式指定一个文件名基名：basename +文件可以取文件的基名目录名：dirname +文件可以取文件的目录名 列出目录内容列出当前目录的内容或指定目录用法：ls [options] [files_or_dirs]示例:123456789101112ls -a包含隐藏文件 ls -l显示额外的信息 ls -R目录递归通过 ls -ld目录和符号链接信息 ls -1 文件分行显示 ls –S 按从大到小排序 ls –t 按mtime排序 ls –u 配合-t选项，显示并按atime从新到旧排序 ls –U 按目录存放顺序显示 ls –X 按文件后缀排序 ls /var l&#123;0...9&#125; ls /etc rc&#123;0...6&#125;* .&gt;boot/111 快速清空文件111touch ＋文件名创建空文件，若该文件已存在，就刷新文件的时间. &gt;&gt; ＋文件名 创建空文件，若存在，不刷新文件时间，追加，重定向rename +conf conf.bak *.conf 可以批量修改多个后缀为conf的文件名字~或者-开头的文件，要创建或者删除是只需在~或者-前加./就可以了123456789date 0921221392018直接改时间 （重点） data +%w -d &apos;-2 day&apos;显示两天前是星期几 data +%F 显示年月日 data +&apos;%F %T&apos; 显示年月日和时间 data +%Y 显示年 data +%Y%M%D 显示年月日 whatis +命令 查询该命令作用=man -f mandb 生成whatis数据库 centos6 makewhatis 生成whatis数据库 centos7 安装命令工具 （重点）df查找sr0挂载光盘，若无挂载光盘则创建挂载点12345df -h #查看光盘是否已挂载mkdir /data/cdrom #新建挂载目录mount /dev/sr0/data/cdrom #挂载光盘到目录，然后执行下一步 df #查找sr0挂载路径rpm -ivh +挂载光盘目录（右键复制media），再输入工具首字母补全，回车安装 filefile content 文件内容file metadata 文件元数据 inode number 文件节点1ls -i 查询文件节点编号 节点编号存放在/boot，节点编号用完后无法存放文件 （面试）12ls -di +文件夹 查询挂载节点位置 ls -di /data /boot / centos6 这三个节点为2 centos7上着三个节点为64 移动复制的区别（重点）原理层面12cp /dir1/f1 /dir2/f2 mv /dir1/f1 /dir2/f2 相对路径（重点） 硬链接和软链接的区别？通俗来说：硬链接：对一个文件，起多个文件名软连接：原始文件一般路径用相对路劲， 相对路径一定相对于软连接文件的路径 ** (重点 看录屏) 1.是否是同一个文件 硬链接是同一个文件，软链接不上是同一个2.是否跨分区3.链接数增长？4.inode number 是否相同？5.原始文件删除，链接文件可否访问？6.大小？7.支持目录？8.相对路径节点表 例子：1ln -s ../../dev/zero d1/d2/zero-link 0输入1输出2错误命令+ &amp;&gt; /dev/null 将输出结果直接扔进null（垃圾箱），不在屏幕显示 文件通配符 （重点） *匹配零个或多个字符?匹配任何单个字符~ 当前用户家目录~mage 用户mage家目录~+ 当前工作目录~-前一个工作目录[0-9]匹配数字范围[a-z]：字母[A-Z]：字母[wang]匹配列表中的任何的一个字符[^wang]匹配列表中的所有字符以外的字符预定义的字符类：man 7 glob[:digit:]：任意数字，相当于0-9[:lower:]：任意小写字母[:upper:]: 任意大写字母[:alpha:]: 任意大小写字母[:alnum:]：任意数字或字母[:blank:]：水平空白字符[:space:]：水平或垂直空白字符[:punct:]：标点符号[:print:]：可打印字符[:cntrl:]：控制（非打印）字符[:graph:]：图形字符[:xdigit:]：十六进制字符创建空文件和刷新时间 touch命令： （重点）touch [OPTION]… FILE…1234-a #仅改变atime和ctime -m #仅改变mtime和ctime -t [[CC]YY]MMDDhhmm[.ss] #指定atime和mtime的时间戳 -c #如果文件不存在，则不予创建 例子： 复制文件和目录cp （重点）cp[OPTION]… [-T] SOURCE DESTcp[OPTION]… SOURCE… DIRECTORYcp[OPTION]… -t DIRECTORY SOURCE…cpSRC DESTSRC是文件：如果目标不存在：新建DEST，并将SRC中内容填充至DEST中如果目标存在：如果DEST是文件：将SRC中的内容覆盖至DEST中基于安全，建议为cp命令使用-i选项如果DEST是目录：在DEST下新建与原文件同名的文件，并将SRC中内容填充至新文件中cpSRC… DESTSRC…：多个文件DEST必须存在，且为目录，其它情形均会出错cpSRC DESTSRC是目录：此时使用选项：-r如果DEST不存在：则创建指定目录，复制SRC目录中所有文件至DEST中如果DEST存在：如果DEST是文件：报错如果DEST是目录： cp常用选项123456cp-i：覆盖前提示–n:不覆盖，注意两者顺序 -r, -R: 递归复制目录及内部的所有内容 -a: 归档，相当于-dR--preserv=all -d：--no-dereference --preserv=links 不复制原文件，只复制链接名 --preserv[=ATTR_LIST] mode: 权限ownership: 属主属组timestamp:linksxattrcontextall-p: 等同–preserv=mode,ownership,timestamp-v: –verbose-f: –force-u:–update 只复制源比目标更新文件或目标不存在的文件-b:目标存在，覆盖前先备份–backup=numbered 目标存在，覆盖前先备份加数字后缀 本节笔记快捷键123456789101112cp +文件路径/a文件名 文件路径/a新文件名 #将a文件复制到另一文件夹并改名 cp +r +a目录 +b目录 将a目录复制到b目录，成为b目录的子目录 cp -a 常用来备份，保留复制文件的所有属性 cp file1 file1.bak 将file1文件备份为file1.bak 等同于cp file1&#123;，.bak&#125; mv +a文件 +b文件 将文件a改名为文件b mv +a文件 +文件夹 移动a文件到文件夹 mv -t +文件夹+多个文件 把多个文件移动到目标文件夹 移动和重命名文件 mv [OPTION]... [-T] SOURCE DEST mv [OPTION]... SOURCE... DIRECTORY mv [OPTION]... -t DIRECTORY SOURCE... 常用选项：1234mv-i: 交互式 -f: 强制 -b: 目标存在，覆盖前先备份 删除12345678910111213rm[OPTION]... FILE... 常用选项： -i交互式 -f强制删除 -r递归 --no-preserve-root 删除/ 示例： rm-rf/ 慎用 目录操作 tree 显示目录树 -d: 只显示目录 -L level：指定显示的层级数目 -P pattern: 只显示由指定pattern匹配到的路径 mkdir创建目录 练习 mkdir-p: 存在于不报错，且可自动创建所需的各目录-v: 显示详细信息-m MODE: 创建目录时直接指定权限rmdir删除空目录-p: 递归删除父空目录-v: 显示详细信息rm-r递归删除目录树标准输入和输出程序：指令+数据读入数据：Input输出数据：Output打开的文件都有一个fd: file descriptor (文件描述符)Linux给程序提供三种I/O设备标准输入（STDIN）－0默认接受来自键盘的输入标准输出（STDOUT）－1默认输出到终端窗口标准错误（STDERR）－2默认输出到终端窗口 I/O重定向：改变默认位置把输出和错误重新定向到文件 （重点）STDOUT和STDERR可以被重定向到文件命令操作符号文件名支持的操作符号包括：_&gt; 把STDOUT重定向到文件2&gt;把STDERR重定向到文件&amp;&gt;把所有输出重定向到文件_&gt; 文件内容会被覆盖set –C 禁止将内容覆盖已有文件,但可追加_&gt;| file 强制覆盖set +C 允许覆盖_&gt;&gt; 原有内容基础上，追加内容2&gt;覆盖重定向错误输出数据流2&gt;&gt; 追加重定向错误输出数据流标准输出和错误输出各自定向至不同位置COMMAND &gt; /path/to/file.out2&gt; /path/to/error.out合并标准输出和错误输出为同一个数据流进行重定向&amp;&gt;覆盖重定向&amp;&gt;&gt; 追加重定向COMMAND &gt; /path/to/file.out2&gt;&amp;1 （顺序很重要）COMMAND &gt;&gt; /path/to/file.out2&gt;&amp;1()：合并多个程序的STDOUT(cal2007;cal2008)&gt; all.txt 本节笔记重定向.&gt; 覆盖.&gt;&gt;追加不覆盖原文件内容2&gt;将错误信息重定向到文件中1+到100 echo {1..100} | tr ‘ ‘ + |bc命令（mail） &lt;&lt; EOF 写一封信，直到输入EOF结束 文件权限rwxr–4 读取权限w–2 写入权限x–1 执行权限-rwxrwxrwx -为文件类型 777-rw-rw-rw- 只有读写权限，没有执行权限666$ chgrp +组+用户 将此用户改为此组cat与tac相反12345abcd dcba head +命令 默认显示该文件的前十行 head -n +数字 显示文件的前几行 tail +f跟踪文件号，文件被删除就失效 tail +F跟踪文件名，文件被删除后再新建的同名文件继续跟踪 tr命令 （重点）tr转换和删除字符tr[OPTION]… SET1 [SET2]选项：12345678910111213141516tr-c–C --complement：取字符集的补集 -d--delete：删除所有属于第一字符集的字符 -s--squeeze-repeats：把连续重复的字符以单独一个字符表示 -t--truncate-set1：将第一个字符集对应字符转化为第二字符集对应的字符 [:alnum:]：字母和数字 [:alpha:]：字母 [:cntrl:]：控制（非打印）字符 [:digit:]：数字 [:graph:]：图形字符 [:lower:]：小写字母 [:print:]：可打印字符 [:punct:]：标点符号 [:space:]：空白字符 [:upper:]：大写字母 [:xdigit:]：十六进制字符 从文件中导入STDIN …………………………………………….（重点）（重点）使用&lt;来重定向标准输入某些命令能够接受从文件中导入的STDINtr‘a-z’‘A-Z’&lt;/etc/issue该命令会把/etc/issue中的小写字符都转换成写写字符tr–d abc&lt; /etc/fstab删除fstab文件中的所有abc中任意字符cat &gt; filemagewangxiaochun按ctrl+d离开，可以使用文件来代替键盘的输入Cat &gt; filea&lt; fileb 把多行发送给STDIN …………………………….. （重点）（重点）练习使用“&lt;&lt;终止词”命令从键盘把多行重导向给STDIN直到终止词位置的所有文本都发送给STDIN有时被称为就地文本（heretext）例如：123456789&apos;mail-s&apos;PleaseCall&apos;admin@magedu.com&lt;&lt;END &gt;HiWang, &gt; &gt;Pleasegivemeacallwhenyougetin.Wemayneed &gt;todosomemaintenanceonserver1. &gt; &gt;Detailswhenyou&apos;reon-site &gt;Zhang &gt;END 例子：1234567891011121314cat &gt;f1 回车 aa bb cc #回车一次输出aa，再回车，输出bb，再回车，输出cc,此为单行重定向 cat &gt;f1 &lt;&lt;b #回车，以b结尾，（常用EOF结尾） &gt;aa &gt;bb &gt;cc &gt;b 以b结尾，输出： aa bb cc #此为多行重定向 管道 ………………. （重点）练习管道（使用符号“|”表示）用来连接命令命令1 | 命令2 | 命令3 | …将命令1的STDOUT发送给命令2的STDIN，命令2的STDOUT发送到命令3的STDINSTDERR默认不能通过管道转发，可利用2&gt;&amp;1 或|&amp; 实现最后一个命令会在当前shell进程的子shell进程中执行用来组合多种工具的功能1ls| tr‘a-z&apos; ‘A-Z&apos; less ：一页一页地查看输入1ls-l/etc|less mail：通过电子邮件发送输入1echo&apos;testemail&apos;|mail-s &apos;test&apos;user@example.com lpr：把输入发送给打印机echo’testprint’|lpr-Pprinter_name示例:将/home 里面的文件打包，但打包的数据不是记录到文件，而是传送到stdout，经过管道后，将tar -cvf-/home 传送给后面的tar -xvf-,后面的这个-则是取前一个命令的stdout，因此，就不需要使用临时file了tar -cvf-/home | tar -xvf-]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机基础]]></title>
    <url>%2F2018%2F09%2F25%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[计算机基础服务器服务器按应用功能可分为： Web服务器、数据库服务器、文件服务器、中间件应用服务器、日志服务器、监控服务器，程序版本控制服务器、虚拟机服务器、邮件服务器、打印服务器、域控制服务器、多媒体服务器、通讯服务器、ERP服务器等。服务器按外形分类：塔式服务器、刀片式服务器、机架式服务器。 服务器的尺寸服务器宽度标准为19英寸（48.26cm），高度（厚度）为1U=1.75英寸=44.45毫米服务器一般有1U,2U,4U…深度为600mm，800mm，900mm，1000mm服务器机柜通常为42U约两米高。放服务器机柜一般用600mm,深1000mm，高2000mm；放网络设备机柜一般用深度为800mm。 服务器常用CPUIntel： Xeon 志强 Itanium 安腾 AMD： ALthionIBM： power CPU频率 主频： 主频是CPU的时钟频率(CPU Clock Speed)，是CPU运算时的工作的频率（1秒内发生的同步脉冲数）的简称。单位是Hz。 外频： 系统总线的工作频率， CPU与外部（主板芯片组）交换数据、指令的工作时钟频率。 倍频： 倍频则是指CPU外频与主频相差的倍数。 三者关系是：主频=外频x倍频 常见的热插拔设备：硬盘，电源，PCI设备，风扇等 裸漏在机箱外的设备一般都支持热插拔。 服务器内存内存带宽是内存与北桥芯片之间的数据传输率内存断电后数据丢失外存断电后数据可以保存内存带宽=内存总线频率X数据总线位数/81Byte（字节）=8bit（位）100Mbps 1G bit s100Mbps带宽=12.8MB/s 下载速度1B=8b Byte bit 硬盘硬盘接口类型： IDE接口：硬盘接口规范，采用ATA技术规范SCSI接口：应用于小型机上的高速数据传输技术SATA接口： Serial ATA，提高传输速率，支持热插拔SAS接口： Serial Attached SCSI，兼容SATA 目前主流的硬盘接口为SATA和SAS接口 存储基础知识–存储网络DAS—–直接连接存储(Direct Attached Storage)数据块 磁盘和服务器可以分离，易于管理，但数据较为分散，连接距离短 NAS—–网络连接存储(Network Attached Storage)文件 不占用应用服务器资源，即插即用，用于文件服务器，不适合存储量大的设备 SAN—–存储区域网络(Storage Area Networks)数据块 高扩展性，数据集中易于管理，贵且安装和升级复杂 操作系统OS分类： 服务器OS：RHEL, CentOS,Windows Server,AIX 桌面OS：Windows 10,Windows 7,Mac OS，Fedora 移动设备OS：Andriod,IOS,YunOS 开发接口标准ABI接口：应用程序与OS之间的底层接口，允许编译好的目标代码在使用兼容ABI的系统中无需改动就能运行 API接口：API定义了源代码和库之间的接口，因此同样的源代码可以在支持这个API的任何系统中编译 Linux哲学思想 一切都是一个文件（包括硬件）小型，单一用途的程序链接程序，共同完成复杂的任务避免令人困惑的用户界面配置数据存储在文本中 终端terminal设备终端键盘鼠标显示器 物理终端（/dev/console ）控制台console 虚拟终端(tty：teletypewriters，/dev/tty# #为[1-6])tty可有n个，Ctrl+Alt+F[1-6] 图形终端/dev/tty7 ）startx, xwindowsCentOS 6: Ctrl + Alt + F7CentOS 7: 在哪个终端启动，即位于哪个虚拟终端 串行终端（/dev/ttyS# ）ttyS 伪终端（pty：pseudo-tty，/dev/pts/# ）pty, SSH远程连接 查看当前的终端设备：tty 交互式接口交互式接口：启动终端后，在终端设备附加一个交互式应用程序GUI：Graphic User InterfaceX protocol, window manager, desktopDesktop:GNOME (C, 图形库gtk)，KDE (C++,图形库qt)XFCE (轻量级桌面) CLI：Command Line Interface shell程序：sh(bourn 史蒂夫·伯恩)cshtcshksh(korn)bash (bourn again shell)GPL zsh 命令提示符命令提示符：prompt[root@localhost~]# #管理员$ 普通用户显示提示符格式[root@localhost~]#echo $PS1修改提示符格式PS1=”[\e[1;5;41;33m][\u@\h \W]\$[\e[0m]“ \e \033 …… \u 当前用户\h 主机名简称 …… \H 主机名\w 当前工作目录 …… \W 当前工作目录基名\t 24小时时间格式 …… \T 12小时时间格式! 命令历史数 …… # 开机后命令历史数 常见命令及使用内部命令内部命令：由shell自带的，而且通过某命令形式提供 123456help或者enable #查询全部内部命令 type+命令 #查询命令是否为内部命令，是则显示builtin，不是则显示路径 enable -n cmd #禁用内部命令 enable -n+命令 #禁用命令 enable -n #查询被禁用的命令 内部命令执行速度快 优先找内部命令，如果没有再去外部找外部命令 外部命令外部命令：在文件系统路径下有对应的可执行程序文件查看路径： which -a |–skip-alias; whereiswhich+命令查询命令路径whereis+命令 查询命令路径及其配置文件，更详细 执行外部命令Hash缓存表系统初始hash表为空，当外部命令执行时，默认会从PATH路径下寻找该命令，找到后会将这条命令的路径记录到hash表中，当再次使用该命令时，shell解释器首先会查看hash表，存在将执行之，如果不存在，将会去PATH路径下寻找。利用hash缓存表可大大提高命令的调用速率长命令 hash常见用法123456hash 显示hash缓存 hash –l 显示hash缓存，可作为输入使用 hash –p path name 将命令全路径path起别名为name hash –t name 打印缓存中name的路径 hash –d name 清除name缓存 hash –r 清除缓存 命令别名alias +自定义名字=一长串命令，输入自定义名字可以代替在命令行中定义的别名，仅对当前shell进程有效如果想永久有效，要定义在配置文件中仅对当前用户：~/.bashrc对所有用户有效：/etc/bashrcunalias+自定义命令 取消这个别名 命令格式 -n 短选项 例如：-l, -h–n长选项 例如：–all, –human-readable-e加\ 解释功能 日期和时间Linux的两种时钟系统时钟：由Linux内核通过CPU的工作频率进行的硬件时钟：主板相关命令 12345678date 显示和设置系统时间 date +%s date -d @1509536033 hwclock，clock: 显示硬件时钟 -s, --hctosys以硬件时钟为准，校正系统时钟 -w, --systohc以系统时钟为准，校正硬件时钟 时区：/etc/localtime 显示日历：cal–y 简单命令1234567891011121314151617181920关机：halt, poweroff 重启：reboot -f: 强制，不调用shutdown -p: 切断电源 关机或重启：shutdown shutdown [OPTION]... [TIME] [MESSAGE] -r: reboot -h: halt -c：cancel TIME：无指定，默认相当于+1（CentOS7） now: 立刻,相当于+0 +m: 相对时间表示法，几分钟之后；例如+3 hh:mm: 绝对时间表示，指明具体时间 例如：shutdown +5 -h 5分钟后关机 shutdown +5 -r 5分钟后重启 shutdown -c 取消关机 用户登录信息查看命令：whoami: 显示当前登录有效用户who: 系统当前所有的登录会话w: 系统当前所有的登录会话及所做的操作 screen命令（重点） 创建新screen会话screen –S [SESSION]加入screen会话screen –x [SESSION]退出并关闭screen会话exit剥离当前screen会话Ctrl+a+d显示所有已经打开的screen会话screen -ls恢复某screen会话screen -r [SESSION] 例如：1234screen -S help 创建一个名为help的会话 screen -ls 查看其他人创建的会话 screen -x help 加入名为help的会话，两个终端可以同步操作 screen 可以单独开一个终端，在开的临时会话中做任务，即使此时网络或者系统出现问题，也不会丢失任务 echo命令功能：显示字符语法：echo [-neE][字符串]说明：echo会将输入的字符串送往标准输出。输出的字符串间以空白字符隔开, 并在最后加上换行号选项： -E （默认）不支持\解释功能-n 不自动换行-e 启用\字符的解释功能 显示变量echo “$VAR_NAME” 变量会替换，弱引用echo ‘$VAR_NAME’ 变量不会替换，强引用例如：1234567891011echo &#123;1,2,3&#125; 1 2 3 echo 1 2 3 1 2 3 echo file &#123;1,2,3&#125; file1 file2 file3 echo file &#123;1,2,3&#125; echo file &#123;1,2,3&#125;.&#123;txt&#125; file1.txt file2.txt file3.txt echo file &#123;1,2,3&#125;.&#123;txt,log&#125; file1.txt file1.log file2.txt file2.log file3.txt file3.log 启用命令选项-e 若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出1234567891011echo&gt;\a 发出警告声 \b 退格键 \c 最后不加上换行符号 \n 换行且光标移至行首 \r 回车，即光标移至行首，但不换行 \t 插入tab \\插入\字符 \0nnn 插入nnn（八进制）所代表的ASCII字符 echo -e &apos;\033[43;31;5mmagedu\033[0m&apos; \xHH插入HH（十六进制）所代表的ASCII数字（man 7 ascii） 命令行历史保存你输入的命令历史。可以用它来重复执行命令登录shell时，会读取命令历史文件中记录下的命令~/.bash_history登录进shell后新执行的命令只会记录在缓存中；这些命令会用户退出时“追加”至命令历史文件中重复前一个命令，有4种方法 重复前一个命令使用上方向键，并回车执行按!! 并回车执行输入!-1 并回车执行按Ctrl+p并回车执行12345678910111213!:0 执行前一条命令（去除参数） Ctrl + n 显示当前历史中的下一条命令，但不执行 Ctrl + j 执行当前命令 !n 执行history命令输出对应序号n的命令 !-n 执行history历史中倒数第n个命令 !string 重复前一个以“string”开头的命令 !?string 重复前一个包含string的命令 !string:p仅打印命令历史，而不执行 !$:p 打印输出!$ （上一条命令的最后一个参数）的内容 !*:p打印输出!*（上一条命令的所有参数）的内容 ^string删除上一条命令中的第一个string ^string1 ^string2将上一条命令中的第一个string1替换为string2 !:gs/string1/string2将上一条命令中所有的string1都替换为string2 使用up（向上）和down（向下）键来上下浏览从前输入的命令ctrl-r来在命令历史中搜索命令（reverse-i-search）`’：Ctrl+g：从历史搜索模式退出要重新调用前一个命令中最后一个参数!$ 表示Esc, .（点击Esc键后松开，然后点击. 键）Alt+ .（按住Alt键的同时点击. 键） command !^ 利用上一个命令的第一个参数做cmd的参数command !$ 利用上一个命令的最后一个参数做cmd的参数command !n: 调用第n条命令的所有参数command !string:^ 从命令历史中搜索以string 开头的命令，并获取它的第一个参数command !string:$ 从命令历史中搜索以string 开头的命令,并获取它的最后一个参数command !string:n 从命令历史中搜索以string 开头的命令，并获取它的第n个参数command !string: 从命令历史中搜索以string 开头的命令，并获取它的所有参数 命令history12345HISTSIZE：命令历史记录的条数 HISTFILE：指定历史文件，默认为~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数 HISTTIMEFORMAT=“%F %T “ 显示时间 HISTIGNORE=“str1:str2*:… “ 忽略str1命令，str2开头的历史 控制命令历史的记录方式：环境变量：HISTCONTROL123ignoredups默认，忽略重复的命令，连续且相同为“重复” ignorespace忽略所有以空白开头的命令 ignoreboth相当于ignoredups, ignorespace的组合 erasedups删除重复命令export 变量名=”值“存放在/etc/profile 或~/.bash_profile bash的快捷键(重点)123456789101112131415161718192021222324252627Ctrl + l清屏，相当于clear命令 Ctrl + o执行当前命令，并重新显示本命令 Ctrl + s阻止屏幕输出，锁定 Ctrl + q允许屏幕输出 Ctrl + c终止命令 Ctrl + z挂起命令 Ctrl + a光标移到命令行首，相当于Home Ctrl + e光标移到命令行尾，相当于End Ctrl + f光标向右移动一个字符 Ctrl + b光标向左移动一个字符 Alt + f光标向右移动一个单词尾 Alt + b光标向左移动一个单词首 Ctrl + xx光标在命令行首和光标之间移动 Ctrl + u从光标处删除至命令行首 Ctrl + k从光标处删除至命令行尾 Alt + r 删除当前整行 Ctrl + w从光标处向左删除至单词首 Alt + d从光标处向右删除至单词尾 Ctrl + d删除光标处的一个字符 Ctrl + h删除光标前的一个字符 Ctrl + y将删除的字符粘贴至光标后 Alt + c从光标处开始向右更改为首字母大写的单词 Alt + u从光标处开始，将右边一个单词更改为大写 Alt + l从光标处开始，将右边一个单词更改为小写 Ctrl + t交换光标处和之前的字符位置 Alt + t交换光标处和之前的单词位置 Alt + N提示输入指定字符后，重复显示该字符N次 注意：Alt组合快捷键经常和其它软件冲突 whatiswhatis +命令 查询命令功能鼠标左键选择命令，右键可以直接粘贴该命令makewhatis安装whatis数据库 8.163.128 在伪终端直接输入用户名和密码登录终端 好玩的欢迎界面！nano /etc/motd 将下面图案写入motd，按ctrl+x，然后按enter保存，形成开机欢迎界面 _.._ ,------------. ,&apos; `. ( I want you! ) / __) __` \ `-,----------&apos; ( (`-`(-&apos;) ) _.-&apos; /) \ = / ( /&apos; |--&apos; . \ ( ,---| `-.)__` )( `-.,--&apos; _`-. &apos;/,&apos; ( Uu&quot;, (_ , `/,-&apos; ) `.__, : `-&apos;/ /`--&apos; | `--&apos; | ` `-._ / \ ( /\ . \. / |` \ ,-\ / \| .) / \ ( ,&apos;|\ ,&apos; : | \,`.`--&quot;/ } `,&apos; \ |,&apos; / / &quot;-._ `-/ | &quot;-. &quot;-.,&apos;| ; / _/[&quot;---&apos;&quot;&quot;] : / |&quot;- &apos; &apos; | / ` |]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown写作格式]]></title>
    <url>%2F2018%2F09%2F24%2FMarkdown%E5%86%99%E4%BD%9C%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Markdown写作格式你好！ 这是你第一次使用 Markdown编辑器 所展示的欢迎页。如果你想学习如何使用Markdown编辑器, 可以仔细阅读这篇文章，了解一下Markdown的基本语法知识。 新的改变我们对Markdown编辑器进行了一些功能拓展与语法支持，除了标准的Markdown编辑器功能，我们增加了如下几点新功能，帮助你用它写博客： 全新的界面设计 ，将会带来全新的写作体验； 在创作中心设置你喜爱的代码高亮样式，Markdown 将代码片显示选择的高亮样式 进行展示； 增加了 图片拖拽 功能，你可以将本地的图片直接拖拽到编辑区域直接展示； 全新的 KaTeX数学公式 语法； 增加了支持甘特图的mermaid语法^1 功能； 增加了 多屏幕编辑 Markdown文章功能； 增加了 焦点写作模式、预览模式、简洁写作模式、左右区域同步滚轮设置 等功能，功能按钮位于编辑区域与预览区域中间； 增加了 检查列表 功能。 功能快捷键撤销：Ctrl/Command + Z重做：Ctrl/Command + Y加粗：Ctrl/Command + B斜体：Ctrl/Command + I标题：Ctrl/Command + Shift + H无序列表：Ctrl/Command + Shift + U有序列表：Ctrl/Command + Shift + O检查列表：Ctrl/Command + Shift + C插入代码：Ctrl/Command + Shift + K插入链接：Ctrl/Command + Shift + L插入图片：Ctrl/Command + Shift + G 合理的创建标题，有助于目录的生成直接输入1次#，并按下space后，将生成1级标题。输入2次#，并按下space后，将生成2级标题。以此类推，我们支持6级标题。有助于使用TOC语法后生成一个完美的目录。 如何改变文本的样式强调文本 强调文本 加粗文本 加粗文本 ==标记文本== 删除文本 引用文本 H~2~O is是液体。 2^10^ 运算结果是 1024. 插入链接与图片链接: link. 图片: 带尺寸的图片: 当然，我们为了让用户更加便捷，我们增加了图片拖拽功能。 如何插入一段漂亮的代码片去博客设置页面，选择一款你喜欢的代码片高亮样式，下面展示同样高亮的 代码片.12// An highlighted blockvar foo = &apos;bar&apos;; 生成一个适合你的列表 项目 项目 项目 项目1 项目2 项目3 计划任务 完成任务 创建一个表格一个简单的表格是这么创建的：项目 | Value——– | —–电脑 | $1600手机 | $12导管 | $1 设定内容居中、居左、居右使用:---------:居中使用:----------居左使用----------:居右| 第一列 | 第二列 | 第三列 ||:———–:| ————-:|:————-|| 第一列文本居中 | 第二列文本居右 | 第三列文本居左 | SmartyPantsSmartyPants将ASCII标点字符转换为“智能”印刷标点HTML实体。例如：| TYPE |ASCII |HTML|—————-|——————————-|—————————–||Single backticks|&#39;Isn&#39;t this fun?&#39; |’Isn’t this fun?’ ||Quotes |&quot;Isn&#39;t this fun?&quot; |”Isn’t this fun?” ||Dashes |-- is en-dash, --- is em-dash|– is en-dash, — is em-dash| 创建一个自定义列表Markdown: Text-to-HTML conversion tool Authors: John: Luke 如何创建一个注脚一个具有注脚的文本。^2 注释也是必不可少的Markdown将文本转换为 HTML。 *[HTML]: 超文本标记语言 KaTeX数学公式您可以使用渲染LaTeX数学表达式 KaTeX: Gamma公式展示 $\Gamma(n) = (n-1)!\quad\foralln\in\mathbb N$ 是通过欧拉积分 $$\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,.$$ 你可以找到更多关于的信息 LaTeX 数学表达式here. 新的甘特图功能，丰富你的文章12345678gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section 现有任务 已完成 :done, des1, 2014-01-06,2014-01-08 进行中 :active, des2, 2014-01-09, 3d 计划一 : des3, after des2, 5d 计划二 : des4, after des3, 5d 关于 甘特图 语法，参考 这儿, UML 图表可以使用UML图表进行渲染。 Mermaid. 例如下面产生的一个序列图：: 123456789sequenceDiagram张三 -&gt;&gt; 李四: 你好！李四, 最近怎么样?李四--&gt;&gt;王五: 你最近怎么样，王五？李四--x 张三: 我很好，谢谢!李四-x 王五: 我很好，谢谢!Note right of 王五: 李四想了很长时间, 文字太长了&lt;br/&gt;不适合放在一行.李四--&gt;&gt;张三: 打量着王五...张三-&gt;&gt;王五: 很好... 王五, 你怎么样? 这将产生一个流程图。: 12345graph LRA[长方形] -- 链接 --&gt; B((圆))A --&gt; C(圆角长方形)B --&gt; D&#123;菱形&#125;C --&gt; D 关于 Mermaid 语法，参考 这儿, FLowchart流程图我们依旧会支持flowchart的流程图：123456789flowchatst=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 关于 Flowchart流程图 语法，参考 这儿. 导出与导入导出如果你想尝试使用此编辑器, 你可以在此篇文章任意编辑。当你完成了一篇文章的写作, 在上方工具栏找到 文章导出 ，生成一个.md文件或者.html文件进行本地保存。 导入如果你想加载一篇你写过的.md文件或者.html文件，在上方工具栏可以选择导入功能进行对应扩展名的文件导入，继续你的创作。]]></content>
      <tags>
        <tag>L·H</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible]]></title>
    <url>%2F2018%2F09%2F18%2Fansible%2F</url>
    <content type="text"><![CDATA[运维自动化管理工具之Ansible 内容：1.软件发布环境机制优势对比 和 2.ansible的应用ansible的相关的文档ansible的中文权威指南：ansible中文指南Github上的ansible-galaxy示例：ansible-galaxy 其他相关运维管理工具使用方法：pssh的使用方法参照链接文章：psshsaltstack介绍及使用参照链接文章：saltstackpuppet介绍及使用参照链接文章：puppet 当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric 常用自动化运维工具 PSSH：适用于主机数量很少的环境(基础ssh的key验证) Ansible:python,Agentless,中小型应用环境(自带代理功能) Saltstack:python，一般需部署agent，执行效率更高 Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境 Fabric：python，agentless Chef: ruby,国内应用少 Cfengine func 发布更新环境灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径 如： 软件路径为:/data/app 正在用的软件版本V1.0：/data/app1.0 更新的软件版本V2.0：/data/app2.0 则需要把删除原来的软链接：/data/app1.0---&gt;/data/app 创建新的软链接：/data/app2.0---&gt;/data/app 10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线 发布步骤： 1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。 2.从负载均衡列表中移除掉「金丝雀」服务器。 3.升级「金丝雀」应用（排掉原有流量并进行部署）。 4.对应用进行自动化测试。 5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。 6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。 A/B Testing A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。 优势与不足： 优势：用户体验影响小，灰度发布过程出现问题只影响少量用户 不足：发布自动化程度不够，发布期间可引发服务中断 预发布验证： 新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器 灰度发布： 可以基于主机，用户或者业务，又细分为地区，VIP和普通用户 蓝绿发布：核心：主备两套环境定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同 时也升级到新版本 主：绿色环境-活动环境：负责对外提供服务，版本：v1.0 备：绿色环境-非活动环境：版本：v2.0 工作机制： 先把备环境升级v1.0---&gt;v2.0版本，然后上线 把主环境的v1.0版本下线，已经升级的备环境进行替换 特点： 蓝绿部署无需停机，并且风险较小. 注意事项： 1.需要提前考虑数据库与应用部署同步迁移/回滚的问题 2.蓝绿部署需要有基础设施支持 3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境 和绿色环境有被摧毁的风险. 优势与不足： 优势：升级切换和回退速度非常快 不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响 滚动发布：在灰度发布的基础上进行进一步优化定义： 一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式. 特点： 1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数. 可以部分部署，例如每次只取出集群的20%进行升级。 2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出 优势和不足: 优势：用户体验影响小，体验较平滑 不足：发布和回退时间比较缓慢。 发布工具比较复杂，LB需要平滑的流量摘除和拉入能力 滚动发布目前成熟型技术组织所采用的主流发布方式 Ansible ansible特性：-最多管理500台主机，更多效率会降低1.模块化：调用特定的模块，完成特定任务 -类似linux中的小命令 2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块 3.支持自定义模块 4.基于Python语言实现 5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务) 6.安全，基于OpenSSH 7.支持playbook编排任务 -类似于脚本功能，多个脚本的集合成为Roles 8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 9.无需代理不依赖PKI（无需ssl） 10.可使用任何编程语言写模块 11.YAML格式，编排任务，支持丰富的数据结构 12.较强大的多层解决方案 Ansible的学习过程：1.ansible基本命令使用 2.ansible常用模块详解，介绍ansible单个命令的使用 3.YAML语法介绍 4.ansible playbook基础：剧本初体验，类似于写脚本 5.playbook中的变量：tags，handlers使用 6.plsybook模板：templates 7.playbook的条件判断：when 8.playbook的字典：with_items 9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合 会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。 ansible命令执行过程ansible命令执行过程 1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程 服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态：(颜色定义在/etc/ansible/ansible.cfg中) 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 CMDB作用介绍:CMDB:Configuration Management Database 配置管理数据库 将服务器的配置，网络配置写到数据库里 CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不 断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管 理等流程提供准确的配置信息. 了解更多CMDB可参照文章：CMDB 1.ansible基本命令使用ansible软件安装：多种安装方法1.基于epel源安装： yum install ansible,非服务，只是一个管理工具 2.编译安装： 3.Github方式安装：可以同步安装 4.pip安装：pip是安装Python包的管理器，类似yum ansible的重要&amp;主要文件配置文件： /etc/ansible/ansible.cfg 配置ansible的工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles 存放的角色目录 程序文件： /usr/bin/ansible ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)支持不分组，分组，等方式 如： 192.168.34.100 [webservers] 192.168.34.101 192.168.34.102 [dbservers] 192.168.34.[1:6]7 (17,27..67) db[01:100].cenntos.com ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）配置文件只提供默认值，但可以通过playbook的设置进行覆盖 配置文件可以放在/etc/ansible/ansible.cfg中 也可以放到一个工作目录下命名为.ansible.cfg [defaults] inventory = /etc/ansible/hosts - 主机列表配置文件 library = /usr/share/my_modules/ - 库文件存放目录 remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录 local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录 forks = 5 - 默认并发数 sudo_user = root - 默认sudo 用户 ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 [color] 定义ansible命令的执行结果颜色的 配置文件说明和建议修改的项：local_tmp和remote_tmp： 本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地 家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除. host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 module_name = command -默认使用的命令模块，可以修改成shell module_name = shell 2.ansible常用模块详解，介绍ansible单个命令的使用ansible模块的使用查询方法ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet显示指定模块的playbook片段 示例： ansible-doc –l 列出所有功能模块 ansible-doc ping 查看ansible中的ping用法 ansible-doc -s shell 查看shell模块的使用方法 ansible的常用基本选项ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible 端能基于密钥认证的方式联系各被管理节点 ansible语法： ansible &lt;host-pattern&gt; [-m module_name] [-a args] --version 显示版本 -m module 指定模块，默认为command，主要使用选项 -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码，默认Key验证 -K, --ask-become-pass 提示输入sudo时的口令 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo 切换 ansible的主机清单表示方法:Host-pattern1.All ：表示所有Inventory中的所有主机 如：ansible all -m ping ansible all --list-hosts列出所有主机清单 ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP 2.* :通配符 如：ansible &quot;*&quot; = ansible all ansible 192.168.34.* 表示34网段的所有IP 3.或的关系 如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作 ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作 4.与的关系(且) 如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机 5.非，取反 如：ansible &apos;websrvs:!dbsrvs&apos; 在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号 6.正则表达式 如：ansible &quot;~(web|db).*\.centos\.com&quot; ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项1.Command：在远程主机执行命令，默认模块，可忽略-m选项 可以在ansible.cfg中修改默认模块项 支持：chdir(切换目录) command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现 使用示例： ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh ansible all -a &apos;useradd test&apos; 所有主机上创建test用户 2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项 支持功能：支持$ &lt; &gt; | ; &amp; 等 chdir 执行前，先切换到该文件夹 示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos; 显示appsrvs组的主机名 ansible all -m shell -a &apos;chdir=/data rm -rf *&apos; 先切换到/data目录下，再执行删除命令 3.Script: 批量运行脚本 可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理 功能：creates:远程主机的文件存在，则不运行 removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令 示例：ansible all -m script -a &quot;/data/test.sh&quot; ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot; 因为fstab文件存在，则不执行rm -rf /data/*命令 ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot; 因为fstab文件存在，则执行rm -rf /data/*命令 4.Copy:从服务器复制文件到目标主机 src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户 2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos; 根据自己写的字符串生成文件 5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取 src，dest(抓取到本机目录) 示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 将远程主机fstab2文件抓取到本机/data下 如果抓取的是目录，先打包再抓取 打包：ansible all -a &apos;tar cf /root/data.tar /data&apos; 抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 6.File：设置文件属性，创建/删除文件 src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos; 创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos; 删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos; 7.Hostname：管理主机名 可以通过后面的变量来实现 a.先在hosts后定义hostname变量名 [centos6] 192.168.34.106 hostname=mini6-2 192.168.34.101 hostname=node6-1 [centos7] 192.168.34.107 hostname=mini7-1 b.再通过hostname模块批量修改 ansible all -m hostname -a &apos;name={{hostname}}&apos; 8.Cron：计划任务 支持：minute，hour，day，month，weekday 示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务 ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名 ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名 9.Yum：管理包 支持：name,state=(started stopped reloaded restarted),absent 更新缓存：update_cache=yes， 示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包 ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包 10.Service：管理服务(同一systemctl&amp;service) name，state(stopped,started,reloaded,restarted) enable(设置开启启动) 示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务 ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务 ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务 ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动 11.User：管理用户 name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录) 示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos; 创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户 ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录 12.Group：管理组 支持：group,name,gid,system,state=(absent) 示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组 ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 ansible系列的一些模块(用的不多)简单介绍与了解： ansible-galaxy 互联网上的角色分享 ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 Ansible-vault管理yaml文件 功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 Ansible-console ansible重要知识之playbook(上面的各种模块的组合) YAML语言（编写playbook的专门语言）YAML语法： 在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三 个点号( ... )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过 缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 k/v的值可同行写也可换行写。同行使用:分隔 v可是个字符串，也可是另一个列表 一个完整的代码块功能需最少元素需包括 name: task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml List：列表，其所有元素均使用“-”打头 Dictionary：字典，通常由多个key与value构成 Playbook中的核心元素:1.Hosts 执行的远程主机列表 2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远 程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使 用sudo_user指定sudo时切换的用户 3.Tasks 任务集 4.Varniables 内置变量或自定义变量在playbook中调用 5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否 则不执行 7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible 具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其 确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可 以通过tags跳过此些代码片断 8.handlers和notify 运行playbook运行playbook的方式 ansible-playbook &lt;filename.yml&gt; ... [options] 常见选项 -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测 --list-hosts 列出运行任务的主机 --limit 主机列表 只针对主机列表中的主机执行 -v 显示过程 -vv -vvv 更详细 备注： 执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误 ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行 执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验将centos7的httpd.conf复制到centos7主机，6上的配置文件不同示例1：写一个安装启动httpd的playbook:install_httpd.yml 包括创建用户，安装httpd包，开启服务，并设置开机启动 - hosts: all remote_user: root tasks: - name: creat user user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd - name: copy config copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: install package yum: name=httpd - name: service service: name=httpd state=started enabled=yes 备注： 执行完通过以下命令判断每个任务都否都执行成功了 1.ansible all -a &apos;getent passwd httpd&apos; 2.ansible all -a &apos;rpm -q httpd&apos; 3..ansible all -a &apos;ss -ntlp|grep 80&apos; 示例2：写一个删除上面的playbook:remove_httpd.yml 包括：删除用户，卸载httpd包 - hosts: all remote_user: root tasks: - name: del user user: name=httpd state=absent remove=yes - name: remove package yum: name=httpd state=absent 备注： 如果只删除特定主机的httpd，而不是全部，需要加--limit选项 ansible-playbook --limit 192.168.34.105 remove_httpd.yml 只限制在192.168.34.105的主机执行 上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。Handlers: 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生 变化时，才会采取一定的操作 Notify: 此action可用于在每个play的最后被触发，这样可避免多次有改变发生 时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 示例：示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200） - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted 备注：停止并删除用户和安装包 ansible all -a &apos;service memcached stop&apos; ansible all -a &apos;ss -ntl&apos; ansible all -a &apos;rpm -q memcached&apos; ansible all -a &apos;getent passwd memcached&apos; 可以多个notify对应一个handlers，也可以多个motify对应多个handlers示例4：多个notify对应一个handlers - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd 第一个notify - name: ensure apache is running service: name=httpd state=started enabled=yes notify: restart httpd 第二个notify handlers: - name: restart httpd 对应一个handlers service: name=httpd status=restarted 示例5：多个notify对应多个handlers- hosts: websrvs remote_user: root tasks: - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process 多个notify的写法 handlers: - name: Restart Nginx 对应写多个handlers service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log tags的用法：作用：挑选某一段的task来执行将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行 然后执行：ansible-plsybook -t ceshi install_memcached.yml 只会触发拷贝文件和handlers的动作 --- #test yaml file - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 tags: ceshi 对拷贝动作加一个标签 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted Playbook中变量使用:可以多出定义，但是存在优先级优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的 代码块，然后用代码块当变量 比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的 ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的 2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高 可以对单个变量赋值：ansible-playbook –e varname=value 也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot; 4 在playbook中定义 vars: - var1: value1 - var2: value2 5 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件 很适合在roles中进行单独定义 6 在role中定义（下文中有介绍） 从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作 ansible_fqdn 主机名的变量 ansible_hostname 主机名 ansible_distribution_major_version: “6” 版本名变量 ansible_processor_vcpus 虚拟cpu个数变量 ansible_memtotal_mb 内存的变量 示例： ansible all -m setup -a “filter=ansible_memtotal_mb” 用此命令来查看系统内变量的值 调用不同变量来源的示例：得出变量的优先级顺序示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml - hosts: all remote_user: root tasks: - name: touch file file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量 /etc/ansible/hosts：中定义的变量： [websrvs] 192.168.34.105 port1=80 192.168.34.106 port1=90 -普通变量 [websrvs:vars] -公共组变量 mark=&quot;-&quot; [appsrvs] 192.168.34.101 port1=100 [appsrvs:vars] mark=&quot;=&quot; vars.yml中书写格式： - hosts: all remote_user: root tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 最后生成的文件为： app=100.log，app-80.logapp-90.log 示例3：在示例1的基础上，再通过命令行中定义变量: 在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果： ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml 可以看出，最后新建的文件名为hahaha.log 示例4：在playbook中定义变量 - hosts: all remote_user: root vars: - port1: 200 - mark: +++ tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 生成的文件： app+++200.log 示例5：先写在var.yml中定义变量， 1.先准备cat vars.yml:文件内容格式 var1: httpd var2: nginx 2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义 - hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/{{ var1 }}.log state=touch - name: create nginx log file: name=/app/{{ var2 }}.log state=touch 模板templates，作用：文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：{key1:value1, key2:value2, ...} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and, or, not 流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为 .j2 结尾 yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 示例1：通过templates模板nginx1.先生成nginx.conf.j2模板 cp /etc/nginx/nginx.conf templates/nginx.conf.j2 2.创建playbook - hosts: all remote_user: root tasks: - name: inastll nginx yum: name=nginx - name: template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: service - name: start service service: name=nginx state=started handlers: - name: service service: name=nginx state=restarted when配合templates实现根据不同版本执行不同的功能条件测试: 如果需要根据变量、facts或此前任务的执行结果来做为某task执行与 否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法 格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例： tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值 示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when步骤：涉及到多个notify对应一个handlers,定义端口变量 1.hosts文件配置：修改了4台主机httpd的端口 [centos6] 192.168.34.105 http_port=86 192.168.34.106 http_port=87 192.168.34.101 http_port=88 [centos7] 192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件 httpd_6.conf.j2 httpd_7.conf.j2 3.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的 Listen {{http_port}} 调用hosts列表中的端口变量 4.plsybook如下： --- - hosts: all remote_user: root tasks: - name: install httpd yum: name=httpd - name: templates 6 template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service when: ansible_distribution_major_version == &quot;6&quot; - name: templates 7 template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version == &quot;7&quot; notify: restart service - name: service service: name=httpd state=started handlers: - name: restart service service: name=httpd state=restarted 迭代：with_items，类似于shell中的for循环迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item“ 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 字典构成一个键值对{key:vavul},如示例3 迭代的示例：示例1：比如创建user1.user2.user3个用户 - hosts: all remote_user: root tasks: - name: touch users user: name={{item}} with_items: - haha1 - haha2 - haha3 示例2：拷贝3个文件，file1 file2 file3 - hosts: all remote_user: root tasks: - name: copy files copy: src=/data/playbook/{{item}} dest=/data/ with_items: - file1 - file2 - file3 迭代嵌套子变量:涉及到多个键值对的表达方式示例3：创建3个组，再创建3个用户，指定加入一一对应的组 - hosts: all remote_user: root tasks: - name: creat groups group: name={{item}} with_items: - group1 - group2 - group3 - name: creat users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;haha1&apos;, group: &apos;group1&apos; } - { name: &apos;haha2&apos;, group: &apos;group2&apos; } - { name: &apos;haha3&apos;, group: &apos;group3&apos; } 备注：注意创建用户时，键值对的表达和使用方法 上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3; Playbook中template结合for循环生成具有重复性的代码段语法: for的写法： {% for vhost in nginx_vhosts %} server { listen {{ vhost.listen | default('80 default_server') }} ### Playbook中template结合for循环生成具有重复性的代码段 if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用 如果没定义，则不执行接下来的代码：示例2 {% if vhost.server_name is defined %} server_name {{ vhost.server_name }}; {% endif %} {% if vhost.root is defined %} root {{ vhost.root }}; {% endif %} ### for和if的示例，帮助理解其要执行语句的含义 示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成 先创建for.j2文件： {% for i in ports %} server{ listen {{i.listen}} name {{i.name}} root {{i.root}} } {% endfor %} 创建playbook:再其中调用for.j2文件 - hosts: all remote_user: root vars: ports: - web1: listen: 81 name: www.baidu.com root: /data/web1 - web2: listen: 82 name: www.baidu1.com root: /data/web2 tasks: - name: test for template: src=for.j2 dest=/data/for1.conf 效果为： server{ listen 81 name www.baidu.com root /data/web1 } server{ listen 82 name www.baidu1.com root /data/web2 } 示例2：template配合if的涵义： 在示例1中的playbook中，把name注释掉，即不定义name的值 - web1: listen: 81 # name: www.baidu.com root: /data/web1 然后playbook:再调用for.j2文件 {% for i in ports %} server{ listen {{i.listen}} {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用 name {{i.name}} {% endif %} root {{i.root}} } {% endfor %} 结果：则web1没有name的值，即可以理解if的用法 server{ listen 81 root /data/web1 少了web1的name的值 } server{ listen 82 name www.baidu1.com root /data/web2 } Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？ansible重要内容之Roles；playbook的集合和拆分 ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需 要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、 文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一 种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程 等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过Includes即可实现 roles的意义和适用场景：角色(roles)：角色集合 适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把 同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了， 当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。 如系统内会存在如下的各类服务，可以先编排好角色 roles/ ├── httpd/ ├── memcached/ ├── mysql/ └── nginx/ roles的目录结构（一般分成以下目录进行存放一类的文件）Roles各目录作用： /roles/project/ :项目名称,有以下子目录 如创建http，memcached，nginx等目录 files/ ：存放由copy或script模块等调用的文件 保存需要拷贝的配置文件 templates/：template模块查找所需要模板文件的目录 保存通过template的jinja2模板调用的配置文件 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此 文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要 在此文件中通过include进行包含，可以单独定义变量的目录 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为 main.yml的文件，其它文件需在此文件中通过include进行包含 tasks目录下，组合任务顺序的文件 default/：设定默认变量时使用此目录中的main.yml文件 roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.- hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量方法一：把需要调用的角色写在一个playbook里 - hosts: all remote_user: root roles: - role: httpd - role: memcached - role: nginx 弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活 方法二；可以把变量在角色中定义 传递变量给角色 - hosts: remote_user: roles: - mysql - { role: nginx, username: nginx } 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 方法三：还可基于条件测试实现角色调用 roles: - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ } roles示例：以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.ymlroles的目录结构下的httpd&amp;nginxmemcachedroles ├── httpd │ ├── files │ │ ├── index_6.html │ │ └── index_7.html │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── copyhtml_6.yml │ │ ├── copyhtml_7.yml │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig_6.yml │ │ ├── tempconfig_7.yml │ │ └── user.yml │ ├── templates │ │ ├── httpd_6.conf.j2 │ │ └── httpd_7.conf.j2 │ └── vars ├── memcached │ ├── files │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig.yml │ │ └── user.yml │ ├── templates │ │ └── memcached.j2 │ └── vars └── nginx ├── files │ ├── index_6.html │ └── index_7.html ├── handlers │ └── main.yml ├── tasks │ ├── copyhtml_6.yml │ ├── copyhtml_7.yml │ ├── group.yml │ ├── main.yml │ ├── package.yml │ ├── service.yml │ ├── tempconfig.yml │ └── user.yml ├── templates │ └── nginx.conf.j2 └── vars └── main.yml 调用角色的playbook:roles.yml可以通过加变量和标签和条件测试调用更灵活的调用各种角色) vim /data/roles.yml - hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} 比如： 1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法 2.ansible-playbook -t httpd roles.yml 只选择安装httpd 3.ansible-playbook -t nginx roles.yml 只选择安装nginx 4.ansible-playbook -t web roles.yml 安装httpd和memcached 5.ansible-playbook -t web1 roles.yml 只选择安装nginx 下图为每个role的各个文件内容：图一：参照roles的httpd的目录各个文件内容 图二：参照roles的nginx的目录各个文件内容涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有 跨角色调用配置文件写法： - name: copy index6 copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html 图三：参照roles的memcached的目录各个文件内容]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>运维，数据库，编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之awk]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[文本处理三剑客之Awk Awk的用户使用指南awk用户指南 相关链接文章：正则表达式： 正则表达式grep文本编辑： grep用法sed文本编辑： sed用法 总结对比一下这三个剑客的特长之处grep、sed、awk被称为linux中的三剑客 grep更适合单纯的查找或匹配文件.sed更适合编辑皮匹配到的文本awk更适合格式化文本，对文本进行比较复杂格式处理 文本三剑客都是默认逐行处理，自带循环sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改 awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’关于awk中的单引号和双引号的问题参照：awk中的输入分隔符单引号&amp;双引号 学习awk的一个重要知识点 先举两个例子： awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法 数组中的例子 awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0} 学习中遇到的混淆的问题：&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理 Awk基本用法和功能以及各个功能示例：awk介绍awk基本用法awk变量awk格式化-printfawk操作符awk条件判断awk循环awk数组awk函数调用系统命令 awk介绍：whatis awk？ awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式 linux上默认使用 GNU awk(gawk) [root@centos7 data]which awk /usr/bin/awk [root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawk which awk=/usr/bin/awk 是gawk的软链接 awk基本用法awk [options] &apos;program&apos; var=value file… awk [options] -f programfile var=value file… awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ... awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句 块，共3部分组成 program 通常是被放在单引号中 选项： -F “分隔符” 指明输入时用到的字段分隔符 -v var=value 变量赋值 基本格式：awk [options] &apos;program&apos; file… Program：pattern{action statements;..} 也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file… pattern和action • pattern部分决定动作语句何时触发及触发事件 BEGIN,END • action statements对数据进行处理，放在{}内指明 print, printf 分割符、域和记录 • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0 为所有域，注意：此时和shell中变量$符含义不同 • 文件的每一行称为记录 • 省略action，则默认执行 print $0 的操作 print格式：print item1, item2, ... 要点： (1) 逗号分隔符 (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式 (3) 如省略item，相当于print $0 用法解析及示例：$0=代表处理的整行的内容 $1,$2,$3..代表每一列，也就域 BEGIN，END是为生成一个报表的头和尾准备的，用法通常为： BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总 awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos; 注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头 END{print xxx},处理文本后，打印一遍xxx的内容作为表尾 BEGIN&amp;ENDBEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。 END：让用户在最后一条输入记录被读取之后发生的动作。 分隔符：awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n 也可以自定义-F&quot;分隔符&quot;自定义分隔符 print&amp;printf的区别：print命令只是单纯的把特定的内容进行打印，默认换行 printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐 示例1.awk支持标准输入输出，后面可以不跟文件 [root@centos7 ~]#awk &apos;{print $0}&apos; aaaa aaaa abcabc abcabc 2.打印/etc/passwd：对比几个输出结果 awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来 awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd 读入的是passwd文件所有行，打印的是abc awk -v abc=1 &apos;{print abc}&apos; /etc/passwd 读入的是passwd文件所有行，打印的都是1 awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出 所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值 如果只是想输出abc字符串，需要加双引号 3.awk{}中支持数字运算 awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值 awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+2 4.取分区利用率df, df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos; 5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UID awk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwd cat /etc/passwd | awk -F: &apos;{print $1,$3}&apos; awk -F: &apos;{print $1：$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 awk -F: &apos;{print $1、$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行 cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开 备注：多行输出时，可以在双引号之间加自定义的分隔符 格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos; /etc/passwd Awk中的变量：变量分为：内置变量和自定义变量awk中的内置变量除了$0,$1,$2等，还有以下几种； 如果要使用这些变量需要加-v 选项先进行定义 FS：输入字段分隔符，默认为空白字符 =filed separator=域或列的分隔符 等于-F的选项，-F是选项，而FS是变量，实际作用是相等的 与-F的区别在于：可以下次调用FS变量 awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd = awk -F:&apos;{print $1,$3}&apos; /etc/passwd awk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd 两列输出时以：做分隔符，调用变量FS awk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd 两列输出时以：：做分隔符，调用2次变量FS 以空格隔开 可以先定义shell中的变量fs=:,awk再进行调用 fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwd OFS：输出字段分隔符，默认为空白字符 =output filed separator 定义输出分隔符，不指定默认空空格做分隔符 awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwd fs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd 调用shell变量做输出分隔符 RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录 默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符 awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos; aa;xxx bb;bzzzz cc dd eex;zccc xxxx 以RS=：冒号自定义行的分隔符，输出结果如上 [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos; aa bb cc dd eex xxxx 自定义FS&amp;RS，输出结果如上 ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos; aa==bb==cc dd==eex==xxxx == 自定义FS,RS,ORS结果很明显 接下来是一个比较重要的变量 NF：字段数量,也就是域或列的总数量 awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量 awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型 awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段 统计光盘中所有安装包适用的cpu架构类型 root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c 1371 noarch 2600 x86_64 NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行 awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号 awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0 awk还没开始处理行，所以记录为0 awk END&apos;{print NR}&apos; /etc/fstab 输出结果为12 可以看出END是统计,awk处理的行数 1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的 [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print NR$0}&apos; 1aa;xxx 2bb;bzzzz 3cc dd 4eex;zccc 5xxxx 2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息 如果需要分开显示统计，则用FNR [root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 4 adm FNR：各文件分别计数,记录号 1.FNR:多个文件，每个分别统计显示第一个字段并列出来 awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab [root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 48 quagga 49 httpd 1 root 2 bin FILENAME：当前文件名 1.统计时，加上变量可以显示文件名 awk &apos;{print FILENAME}&apos; /etc/fstab [root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root /etc/passwd 2 bin /etc/passwd 3 daemon ARGC：命令行参数的个数 awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来 ARGV：数组，保存的是命令行所给定的各参数 1.显示awk的每个参数分别是哪个 [root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittab awk [root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab /etc/fstab 示例：1.统计当前网络连接情况的ip地址是 ss -nt ss -nt | awk &apos;{print $5}&apos; 2.取/var/log/httpd/access_log的时间如下： root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取： cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos; 一步取： cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos; 原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系， 而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$5 3.取出磁盘分区利用率 -这次只取出利用率 两步取出： df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos; 一步取出： df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式 面试题：3-1,取出fstab中挂载的目录 [root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap 或者 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap 4.面试题：将文件f3中的第一个点前的字符串取出再写进去 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn [root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn test music sports news 4-1,扩展 前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？ 答案：不可以！ 原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！ 所以是不可以的，那么如何写？ 如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%， 但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义 如下： 此处用3个反斜线转义 [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos; test music sports news 那如果文本中的第一个点是$呢？ 此处是4个反斜线进行转义 [root@centos7 ~]cat f2 1 test$sina.com.cn 2 music$sina.com.cn 3 sports$sina.com.cn 4 news$sina.com.cn [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos; test music sports news [root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos; test music sports news 当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的 AWK中自定义变量自定义变量(区分字符大小写) (1) -v var=value (2) 在program中直接定义 (2-1)program可以放到一个文本里,awk -f 直接调用即可 示例：自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用 awk -F: &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwd awk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd 例如 cat awk.txt {print $1,$2,$6} awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd Awk中的格式化在介绍printf前，先对其进行总结：1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应 printf命令-类似于shell里的printfprintf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐 格式化输出：printf &quot;FORMAT&quot;, item1, item2, ... (1) 必须指定FORMAT (2) 不会自动换行，需要显式给出换行控制符，\n (3) FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 %c：显示字符的ASCII码 %d, %i：显示十进制整数 -用的比较多 %e, %E：显示科学计数法数值 %f：显示为浮点数 %g, %G：以科学计数法或浮点形式显示数值 %s：显示字符串 -用的比较多 %u：无符号整数 -用的比较多 %%：显示%自身 修饰符 #[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f + 左对齐（默认右对齐） %-15s * 显示数值的正负符号 %+d printf示例：1.设置对齐格式以及字符数 [root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwd root 0 bin 1 pulse 171 gdm 42 gnome-initial-setup 990 $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符 printf默认不换行，所以需要加一个换行符 2.打印一个完整的报表格式 root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username |uid\n--------&quot;} {printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwd username |uid ----------------------- root |0 bin |1 daemon |2 memcached |987 ceshi |1009 quagga |92 httpd |80 ------------------------- awk生成报表格式大概就是这个样子，所以awk称为报表生成器 3. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root,UID:0 Username: bin,UID:1 Username: daemon,UID:2 Username: adm,UID:3 4. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root ,UID:0 Username: bin ,UID:1 Username: daemon ,UID:2 awk操作符a.算术操作符： x+y, x-y, x*y, x/y, x^y, x%y - x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^=，++, --, b.比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配 c.逻辑操作符：与&amp;&amp;，或||，非! d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y 操作符用法示例：1.下面两语句有何不同 • awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1 • awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1 实际上AWK的语法是采用VC语言风格的 2.示例： awk中~&amp;!~是否包含的用法： [root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwd root operator 意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名 用到下文提到的patter模式，在这里是匹配是否包含root字符串 [root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwd root operator 区别上面的这个写法，在这里是包含/root字符串的行 [root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwd bin daemon adm 和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名 [root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断UID是否等于0，是则打印该行，判断是否为管理员 [root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断该行是不是以root开头的行，是则打印 3.awk中的与&amp;&amp;，或|| 非!的使用示例： 示例： • awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd 如果0&lt;=UID&lt;=1000，则打印出该用户 • awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd 打印出UID等于0和UID&gt;=1000的用户名和他的UID • awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号 打印出UID不等于0的用户名 • awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd 如果UID&lt;=500,时，打印出该用户的UID 4.AWK中的条件判断表达式 即三目表达式 相当于把shell中的if;then,else,fi的放到awk中 • 示例： [root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd sys root 0 sys bin 1 sys tcpdump 72 common test 1000 common nginx 1008 判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys awk中的PATTERN和action模式匹配和处理动作=sed的地址定界+修饰符功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界 PATTERN:根据pattern条件，过滤匹配的行，再做处理(1)如果未指定：空模式，匹配每一行 (2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 awk &apos;/^UUID/{print $1}&apos; /etc/fstab awk &apos;!/^UUID/{print $1}&apos; /etc/fstab awk的匹配模式支持的是扩展的正则表达式 注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例 (3) relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值都是假 字符串为空或者0为假 (4) line ranges：行范围 startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式 awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwd awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwd NR表示行 (5) BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 模式：指定一个行的范围。该语法不能包括BEGIN和END模式。BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。 patter用法示例：先写一个特殊的用法 1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot; 2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项 备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的 awk是是支持posix字符集的 [root@centos7 ~]cat f3 seex sex seeex seeeeex [root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk --re-interval &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3|grep -E &quot;se{2,3}x&quot; seex seeex [root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos; seex seeex 1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤) [root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos; /dev/sda2 8 /dev/sda3 1 /dev/sda1 17 2.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤) [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos; 192.168.34.1 192.168.34.105 或者用NF的表达方式 [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos; 192.168.34.1 192.168.34.105 3.取登录当前系统失败（lastb）用户的IP [root@centos7 ~]#lastb root ssh:notty 192.168.34.105 Sun Nov 11 17:25 - 17:25 (00:00) root23 ssh:notty 192.168.34.1 Mon Nov 5 15:43 - 15:43 (00:00) btmp begins Fri Nov 2 09:58:52 2018 [root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c 3 192.168.34.1 1 192.168.34.101 因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行 如果要取失败连接次数大于3的扔到防火墙，可以先取出来 root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos; 192.168.34.1 4.patter中为关系表达式的示例 空字符串或0值都是假，其他为真 awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空 awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空 awk &apos;1{print $0}&apos; /etc/passwd -1为真 awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真 awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真 awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假 5.awk中patter的地址定界 root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin 打印以root开头的行到以adm开头的行之间的所有行 等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd 6.如何打印从多少行到多少行之间的行？？ [root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 通过变量NR变向的打印出行 7.取出/etc/fstab配置文件中以UUID开头的行 [root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos; UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 效果等于 grep &quot;^UUID&quot; /etc/fstab 效果等于 sed -n &apos;/^UUID/p&apos; /etc/fstab 8. awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法 结果为真，即打印全部行 root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 1 1 bin:x:1:1:bin:/bin:/sbin/nologin 1 1 ？？？ [root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwd root /bin/bash test /bin/bash 判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现 效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd 9.打印奇数行和偶数行 [root@centos7 ~]#seq 6 | awk &apos;i=!i&apos; 打印奇数行 1 3 5 原理：i初始值为空，为假，取反时，则打印第一行，此时i=1 i=1时，为真，取反为假，所以第二行不打印，然后i=0 依次类推所以只打印奇数行 [root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行 2 4 6 效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos; 原理：同上，只要先定义i=1，为真，第一行就不打印了 或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行 awk actionaction除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能• (1) Expressions:算术，比较表达式等 • (2) Control statements：if, while等 • (3) Compound statements：组合语句 • (4) input statements • (5) output statements：print等 下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句awk中if-else控制语句的语法及用法语法： 双分支if if(condition){statement;…}(多条语句用;隔开)[else statement] 多分支if if(condition1){statement1}else if(condition2){statement2}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 if-else示例：如判断考试分数，写法如下 [root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;} else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos; soso awk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd 判断UID是否大于1000，是则打印用户名和UID awk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd 判断用户shell是否为/bin/bash,是则打印用户名 awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab 判断域或列个数是否大于5，是则打印该行 awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root or Sysuser: %s\n&quot;,$1}}&apos; /etc/passwd 等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理awk中while循环控制语句的语法及用法语法：while(condition){statement;…} 条件“真”，进入循环；条件“假”，退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 此时涉及到系统自带的一个函数length(函数在下面会有介绍) 示例： 1.统计每一行第一个字段的长度 root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd 4 root 3 bin 6 daemon 3 adm 2.统计/etc/passwd第一行的每个字段的长度 [root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwd root 4 x 1 0 1 0 1 root 4 /root 5 /bin/bash 9 3.统计grub2.cfg文件中linux16那行的每个字段的长度 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfg linux16 7 /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 LANG=en_US.UTF-8 16 linux16 7 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 4.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环 root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10) {print $i,length($i)};i++}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 5.面试题 用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中 如何做？ 1.不用awk，可以通过脚本实现最大值和最小值 2.用awk如何来做？？ 先生成1000个随机数 [root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5; else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done 生成了1000随机数，如何取最大值最小值？ [root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i} else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5 max=32643 min=60 awk中do-while循环控制语句语法：do {statement;…}while(condition) 意义：无论真假，至少执行一次循环体 do-while使用示例：求1-100正整数的和 [root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos; 5050 awk中for循环控制语句语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} for循环使用示例：1.求1-100正整数的和： [root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos; 5050 2.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 awk中的switch控制语句类似于shell中的case语句 语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn} awk中的continue,break，next控制语句break和continuenext:提前结束对本行处理而直接进入下一行处理（awk自身循环） continue的示例求1000以内偶数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos; 2500 求1000以内奇数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos; 2550 求1000以内除了66的所有数字的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos; 4984 break的示例：求1000数字中，当大于100时，跳出循环，即求100以内的和 [root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos; 5050 next的示例：因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例 打印/etc/passwd下的奇数行 [root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd 1 root:x:0:0:root:/root:/bin/bash 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd awk数组-一个非常使用的功能awk的数组全都是关联数组关联数组：array[index-expression] index-expression: • (1) 可使用任意字符串；字符串要使用双引号括起来 • (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值 初始化为“空串” • (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 数组的去重的效果示例：awk &apos;!arr[$0]++&apos; dupfile awk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfile echo abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt awk关联数组的遍历：若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性 for(var in array) {for-body} 注意：var会遍历array的每个索引 数组的使用示例：示例1.定义awk数组 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;; title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos; zhang 可以用for循环把每一个数组的值都表示出来 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]; for(i in title){print i,title[i]}}&apos; zhang coo liu ceo zhang cto wang 但输出时数组元素时，是无序的，这就是关联数组的特性 示例2.awk数组中的重要功能 [root@centos7 ~]cat f6 abc abc ddd ccc aaa ccc ccc [root@centos7 ~]awk &apos;!line[$0]++&apos; f6 abc ddd ccc aaa 问题：为什么执行结果是这个？？ 原因： awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！， 但是要和后面patter中的空模式区别开 &apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理 这两个写法是不一样的，别混淆了 分析： 基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos; 当读取文本f6的第一行时=abc !line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真 所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1 当读取文本f6的第二行时=abc !line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假 所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2 以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的 而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印 所以，命令执行结果为去重的效果 从这个命令执行结果也可以明显看到上述的分析结果 可以看出abc的值是递增的，也就是abc出现的次数 [root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6 abc 1 abc 2 ddd 1 ccc 1 aaa 1 ccc 2 awk数组中的重要功能之for循环遍历数组，很具有实用性在后面的统计服务的一些日志文件很有作用如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的 但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的 若要遍历数组中的每个元素，要使用for循环for(var in array) {for-body} 注意：var会遍历array的每个索引 为什么要通过特殊写法去遍历awk中的数组？如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定 所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素 取其下标，相当于每次循环var的值是等于array数组的下标的 注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot; for循环遍历数组使用示例：示例1： [root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos; 1 第一次输出为空，第二次自动加1 示例2： 1. [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos; liu zhang wang 分析： for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印 示例3： [root@centos7 ~]netstat -tan Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN tcp 0 0 192.168.122.1:53 0.0.0.0:* ESTABLISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED tcp6 0 0 :::111 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:631 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos; LISTEN 8 ESTABLISHED 3 分析： state[$NF]++以空白做分隔符，统计同一类型的状态有多少个 for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数 不明白的可以看上文中的示例2：awk数组中的重要功能 当然，看懂这个命令，需要知道两个知识点 1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0} 2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式 下面再一次对空模式中的处理过程，做详细的描述 空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标， 所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后 state[&quot;LISTEN&quot;]的值已经被赋值为1了。 这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;] 所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同 直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加 直到处理完所有的行，开始执行END模式中的动作。 而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。 此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数， 最终，我们统计出每个状态出现的次数。 3.统计/var/log/httpd/access_log，每个IP链接的次数 root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; [root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 ::1 4 192.168.34.1 88 效果等于： [root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c 4 ::1 88 192.168.34.1 9 192.168.34.101 13 192.168.34.103 4.统计ss -nt ip链接次数 [root@centos7 ~]ss -nt State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 52 192.168.34.103:22 192.168.34.1:8816 ESTAB 0 0 192.168.34.103:22 192.168.34.105:49746 [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 效果等于： [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c 1 192.168.34.1 1 192.168.34.105 5.统计/etc/fstab文件系统类型分别有多少个 [root@centos7 ~]cat /etc/fstab # /etc/fstab # Created by anaconda on Wed Sep 19 11:44:48 2018 UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 6.求下表中的男生和女生的平均成绩 [root@centos7 ~]cat f9 name sex score a m 90 b f 80 c f 99 d m 88 e m 80 如何利用awk的数组功能来求？ 思路先求男的和和女的和？ 利用两个数组？ [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和 m 258 f 179 [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos; m 86 f 89.5 7.统计下面每个名字出现的次数 [root@centos7 ~]cat f1 Allen Phillips Green Lee William Aiden Janmes Lee Angel Jack Jack Thomas Lucas Kevin Tyler Lee William Allen [root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos; Tyler Angel Lucas William Thomas Green Jack Phillips Kevin awk函数awk也包括内置函数和自定义函数内置函数包括 rand,length，sub,gsub,split，system数值处理： rand(i)：返回0和1之间一个随机数 awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos; 字符串处理： • length([s])：返回指定字符串的长度 • sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos; • gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表 示的内容 echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; • split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所 表示的数组中，第一个索引值为1,第二个索引值为2,… netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos; END{for (i in count) {print i,count[i]} awk内置函数之sub、gsub、split实现搜索替换切割的用法示例1： sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s gsub(r,s,[t])表示全局替换 sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos; 2008-08:08 08:08:08 只替换$1 root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos; 2008-08-08 08:08:08 全局替换$0 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; 2008-08-08 08-08-08 示例2： 统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示) awk内置函数split的切割功能示例1: 统计链接本机的IP和端口号 [root@centos7 ~]#netstat -tn Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos; 8816 1 49746 1 分析： split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号 count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数 count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数 awk中的自定义函数格式：awk自定义函数是用正规开发语言的函数格式 function name ( parameter, parameter, ... ) { statements return expression } awk自定义函数的用法：cat fun.awk,把函数写到文件中 function max(x,y) { x&gt;y?var=x:var=y return var } BEGIN{print max(i,j)} awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似 awk中很实用的内置函数system命令system函数作用：在awk可以反过来调用linux里的命令示例： 空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用 空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来 示例1: 显示/boot/grub2下的文件列表；调用命令时要加双引号 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 或者这么写，先定义变量等于路径，再调用变量 [root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 调用hostname命令，显示主机名 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos; centos7.localdomain 示例2： 之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里， 当时是先取出IP放到文件里，然后iptables再禁用； 现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中 具体实现？ awk脚本将awk程序写成脚本，直接调用或执行 awk脚本使用示例： 1.先写文本再调用 cat f1.awk {if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd 2.也可以写成脚本形式 先写再调用 [root@centos7 ~]vim f2.awk #!/bin/awk -f {if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwd nfsnobody 65534 test 1000 gentoo 1007 nginx 1008 ceshi 1009 向awk脚本传递参数格式： awkfile var=value var2=value2... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通 过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变 量都需要一个-v参数 awk脚本传参使用示例：cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3} chmod +x test.awk test.awk -F: min=100 max=200 /etc/passwd 工作中遇到的常用awk文本解决案例：Linux Web服务器网站故障分析常用的命令系统连接状态篇： 1.查看TCP连接状态 netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn 每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引； netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或 netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos; netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos; netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rn netstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c 2.查找请求数请20个IP（常用于查找攻来源）： 方法一： netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20 方法二： netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n20 3.用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -20 4.查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20 5.找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more 6.根据端口列进程 netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1 网站日志分析篇1（Apache）：1.获得访问前10位的ip地址 cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2.访问次数最多的文件或页面,取前20 cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20 3.列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -20 4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -100 6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7.列出传输时间超过 30 秒的文件 cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8.统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’ 9.统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort 10. 统计http status cat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos; cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn 10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。 /usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos; 网站日分析2(Squid篇）按域统计流量cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos; 安全篇：(ssh lastb)ssh日志中失败登录的IP，取出来 /var/log/secure awk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure 1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写 入到回到该文件中 1 blog.magedu.com 2 www.magedu.com … 999 study.magedu.com 2、统计/etc/fstab文件中每个文件系统类型出现的次数 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr 3 xfs 1 swap [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 3、统计/etc/fstab文件中每个单词出现的次数 root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos; man 1 4、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos; 05973 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot; 05973 5、有一文件记录了1-100000之间随机的整数共5000个，存储的格式 100,50,35,89…请取出其中最大和最小的整数 6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP 并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频 率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT [root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 只过滤出IP，监控任务可以写到计划任务里， 或者用内置函数system[&quot;iptables&quot;]调用？ 7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html [root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com [root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com 8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出 同一inode中，beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 106|3363120000|3368579999|30000| awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4} END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file [解析] 第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。 这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。 9.统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 下面的写法在双引号前一定要加一个空格才能匹配出来 或者用单引号，但是也需要在前面几个空格 [root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3 此处一定有个空格 b 3 c 3 d 3 或者用单引号，但是也需要在前面几个空格 [root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 2 b 3 c 3 d 2 root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c 3 a 3 b 3 c 3 d 10.面试题：取出/etc/fstab中的挂载目录 [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap AWK中的输入分隔符我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义 $、^、(、)、[、]、?、.、| 示例1： [root@node7-1 data]cat b.txt ssh:user1@192.168.1.10 ssh:user2@192.168.1.11 ssh:user3@192.168.1.12 1.取user和IP [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 2.上面b.txt中的：和@换成^和|，又该怎么取？ [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 示例2： 示例1： george[walker]bush william[jefferson]clinton 如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示 方法一： awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 方法二： awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章 [root@node7-1 data]cat a.txt xiaoming\t20\thttp://sougou.com xiaohua\t25\thttp://www.baidu.com xiaodong\t30\thttp://www.jidong.com 方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊 root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t 方法二：用awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 12.扩展11题的内容把t换成$,又该如何取？ [root@node7-1 data]cat a.txt xiaoming\$20\$http://sougou.com xiaohua\$25\$http://www.baidu.com xiaodong\$30\$http://www.jidong.com 方法一：还是只用awk来取 [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 1.\\$是转义$的 2.前四个\\\\是转义\的 方法二：awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义]]></content>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
</search>
